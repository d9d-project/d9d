<!DOCTYPE html>
<html lang="en">

<head>
    <script>
        // for search plugin notably
        const base_url = "https://d9d-project.github.io/d9d/";
    </script>
    <script>
    const darkTheme = window.matchMedia("(prefers-color-scheme: dark)");
    darkTheme.onchange = (e) => {
        if (e.matches) {
            document.documentElement.classList.add("dark")
            localStorage.theme = 'dark';
        } else {
            document.documentElement.classList.remove("dark")
            localStorage.removeItem("theme")
        }
    };

    // On page load. Priotiry to lcaolStorage
    if (localStorage.theme === "dark") {
        document.documentElement.classList.add("dark")
    } else if (localStorage.theme === "light") {
        document.documentElement.classList.remove("dark")
    } else if (darkTheme.matches) {
        document.documentElement.classList.add("dark")
    } else {
        document.documentElement.classList.remove("dark")
    }

    // set the layout based on localStorage
    document.documentElement.classList.add(localStorage.getItem("html-layout") || "layout-fixed");
</script>


    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Pipelining Internals - d9d</title>
    


<title>Pipelining Internals</title>









<link rel="canonical" href="https://d9d-project.github.io/d9d/internals/pipelining/">


<!-- Open Graph (Facebook, LinkedIn) -->

<meta property="og:title" content="Pipelining Internals">





<meta property="og:url" content="https://d9d-project.github.io/d9d/internals/pipelining/">






<!-- Twitter Card -->

<meta name="twitter:title" content="Pipelining Internals">






<!-- JSON-LD Structured Data -->



    <link rel="icon" href="../../img/favicon.ico">

    <link href="../../css/base.css" rel="stylesheet">
    <link href="../../css/geist.css" rel="stylesheet">

    
    

<link id="pygments-light" rel="stylesheet"
    href="../../css/pygments/a11y-light.css">
<link id="pygments-dark" rel="stylesheet"
    href="../../css/pygments/a11y-dark.css"
    media="(prefers-color-scheme: dark)">


    
    <link href="../../assets/_mkdocstrings.css" rel="stylesheet">
    <link href="../../style/style.css" rel="stylesheet">

    

    <script src="../../js/callbacks.js"></script>

    
    <!-- katex -->
<link rel="stylesheet" href="../../css/katex.min.css">
<!-- The loading of KaTeX is deferred to speed up page rendering -->
<script defer src="../../js/katex.min.js"></script>
<!-- To automatically render math in text elements, include the auto-render extension: -->
<script defer src="../../js/auto-render.min.js"
    onload='renderMathInElement(document.body, "{}");'></script>
    

    

    

</head>

<body
    class="text-foreground group/body overscroll-none font-sans antialiased [--footer-height:calc(var(--spacing)*14)] [--header-height:calc(var(--spacing)*14)] xl:[--footer-height:calc(var(--spacing)*24)] theme-default">
    <div id="inner-body" class="bg-background relative z-10 flex min-h-svh flex-col">
        <header class="bg-background sticky top-0 z-50 w-full" view-transition-name="header">
    <div class="container-wrapper 3xl:fixed:px-0 px-6">
        <div class="3xl:fixed:container flex h-(--header-height) items-center gap-2 **:data-[slot=separator]:!h-4">
            <button id="menu-button" data-slot="popover-trigger" onclick="onMobileMenuButtonClick(event)"
                class="group whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*='size-'])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive hover:text-accent-foreground px-4 py-2 has-[&gt;svg]:px-3 extend-touch-target h-8 touch-manipulation items-center justify-start gap-2.5 !p-0 hover:bg-transparent focus-visible:bg-transparent focus-visible:ring-0 active:bg-transparent dark:hover:bg-transparent flex lg:hidden"
                type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-«Rmplb»"
                data-state="closed">
                <div class="relative flex h-8 w-4 items-center justify-center">
                    <div class="relative size-4">
                        <!-- 16px x 16px -->
                        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" fill="none" stroke="currentColor"
                            stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                            <line x1="0" x2="16" y1="5" y2="5"
                                class="group-data-[state=open]:translate-y-[2.25px] group-data-[state=open]:-translate-x-[2.25px] group-data-[state=open]:rotate-45 transition-all duration-300 origin-center" />
                            <line x1="0" x2="16" y1="11" y2="11"
                                class="group-data-[state=open]:-translate-y-[2.25px] group-data-[state=open]:-translate-x-[2.25px] group-data-[state=open]:-rotate-45 transition-all duration-300 origin-center" />
                        </svg>
                    </div>

                    <span class="sr-only">Toggle Menu</span>
                </div>
                <span class="flex h-8 items-center text-lg leading-none font-medium">Menu</span>
            </button>
            <a data-slot="button"
                class="items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg:not([class*='size-'])]:size-5 shrink-0 [&_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive hover:bg-accent hover:text-accent-foreground dark:hover:bg-accent/50 hidden h-8 lg:flex"
                href="https://d9d-project.github.io/d9d/">
                <span class="size-8 flex flex-row justify-center items-center">
                    

<img class="size-5" src="https://avatars.githubusercontent.com/u/248787421" alt="icon">


                </span>

                
                <h1 class="pr-2">d9d</h1>
                
            </a>
            
            <div class="ml-auto flex items-center gap-2 md:flex-1 md:justify-end">
                <div class="hidden w-full flex-1 md:flex md:w-auto md:flex-none">
                    <button data-slot="dialog-trigger" onclick="onSearchBarClick(event)"
    class="inline-flex items-center gap-2 whitespace-nowrap rounded-md text-sm transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*='size-'])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive hover:bg-secondary/80 px-4 py-2 has-[&gt;svg]:px-3 bg-surface text-surface-foreground/60 dark:bg-card relative h-8 w-full justify-start pl-2.5 font-normal shadow-none sm:pr-12 md:w-40 lg:w-56 xl:w-64"
    type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-«R66plb»" data-state="closed">
    <span class="text-muted-foreground hidden lg:inline-flex">Search documentation...</span>
    <span class="text-muted-foreground inline-flex lg:hidden">Search...</span>
    <div class="absolute top-1.5 right-1.5 hidden gap-1 sm:flex">
        <kbd
            class="bg-background text-muted-foreground pointer-events-none flex h-5 items-center justify-center gap-1 rounded border px-1 font-sans text-[0.7rem] font-medium select-none [&amp;_svg:not([class*='size-'])]:size-3">Ctrl</kbd><kbd
            class="bg-background text-muted-foreground pointer-events-none flex h-5 items-center justify-center gap-1 rounded border px-1 font-sans text-[0.7rem] font-medium select-none [&amp;_svg:not([class*='size-'])]:size-3 aspect-square">K</kbd>
    </div>
</button>
<dialog id="search-dialog" onclick="onSearchDialogClick(event)"
    class="fixed top-1/2 left-1/2 -translate-x-1/2 -translate-y-1/2 bg-background rounded-lg shadow-lg border overflow-hidden p-0">
    <div class="w-lg gap-4">
        <div class="flex h-full w-full flex-col overflow-hidden rounded-md bg-popover text-popover-foreground">
            <div data-slot="command-input-wrapper" class="flex h-9 items-center gap-2 border-b px-3"><svg
                    xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
                    stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
                    class="lucide lucide-search size-4 shrink-0 opacity-50">
                    <circle cx="11" cy="11" r="8"></circle>
                    <path d="m21 21-4.3-4.3"></path>
                </svg>
                <input data-slot="command-input"
                    class="placeholder:text-muted-foreground flex h-10 w-full rounded-md bg-transparent py-3 text-sm outline-hidden disabled:cursor-not-allowed disabled:opacity-50"
                    placeholder="Search documentation..." cmdk-input="" autocomplete="off" autocorrect="off"
                    spellcheck="false" aria-autocomplete="list" role="combobox" aria-expanded="true"
                    aria-controls="radix-«r1t6»" aria-labelledby="radix-«r1t7»" id="radix-«r1t8»" type="text" value=""
                    aria-activedescendant="radix-«r1th»" oninput="onInputHandler(event)">
            </div>
        </div>
        <div id="mkdocs-search-results">
            <!-- search results go there -->
        </div>
    </div>
</dialog>
<script>
    document.removeEventListener("keydown", searchShortcutHandler);
    document.addEventListener("keydown", searchShortcutHandler);
</script>
                </div>
                <div data-orientation="vertical" role="none" data-slot="separator"
                    class="bg-border shrink-0 data-[orientation=horizontal]:h-px data-[orientation=horizontal]:w-full data-[orientation=vertical]:h-full data-[orientation=vertical]:w-px ml-2 hidden lg:block">
                </div>
                <a target="_blank" rel="noreferrer" data-slot="button"
                    class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*='size-'])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive hover:bg-accent hover:text-accent-foreground dark:hover:bg-accent/50 rounded-md gap-1.5 px-3 has-[&gt;svg]:px-2.5 h-8 shadow-none"
                    href="https://github.com/d9d-project/d9d">
                    <svg viewBox="0 0 438.549 438.549">
                        <path fill="currentColor"
                            d="M409.132 114.573c-19.608-33.596-46.205-60.194-79.798-79.8-33.598-19.607-70.277-29.408-110.063-29.408-39.781 0-76.472 9.804-110.063 29.408-33.596 19.605-60.192 46.204-79.8 79.8C9.803 148.168 0 184.854 0 224.63c0 47.78 13.94 90.745 41.827 128.906 27.884 38.164 63.906 64.572 108.063 79.227 5.14.954 8.945.283 11.419-1.996 2.475-2.282 3.711-5.14 3.711-8.562 0-.571-.049-5.708-.144-15.417a2549.81 2549.81 0 01-.144-25.406l-6.567 1.136c-4.187.767-9.469 1.092-15.846 1-6.374-.089-12.991-.757-19.842-1.999-6.854-1.231-13.229-4.086-19.13-8.559-5.898-4.473-10.085-10.328-12.56-17.556l-2.855-6.57c-1.903-4.374-4.899-9.233-8.992-14.559-4.093-5.331-8.232-8.945-12.419-10.848l-1.999-1.431c-1.332-.951-2.568-2.098-3.711-3.429-1.142-1.331-1.997-2.663-2.568-3.997-.572-1.335-.098-2.43 1.427-3.289 1.525-.859 4.281-1.276 8.28-1.276l5.708.853c3.807.763 8.516 3.042 14.133 6.851 5.614 3.806 10.229 8.754 13.846 14.842 4.38 7.806 9.657 13.754 15.846 17.847 6.184 4.093 12.419 6.136 18.699 6.136 6.28 0 11.704-.476 16.274-1.423 4.565-.952 8.848-2.383 12.847-4.285 1.713-12.758 6.377-22.559 13.988-29.41-10.848-1.14-20.601-2.857-29.264-5.14-8.658-2.286-17.605-5.996-26.835-11.14-9.235-5.137-16.896-11.516-22.985-19.126-6.09-7.614-11.088-17.61-14.987-29.979-3.901-12.374-5.852-26.648-5.852-42.826 0-23.035 7.52-42.637 22.557-58.817-7.044-17.318-6.379-36.732 1.997-58.24 5.52-1.715 13.706-.428 24.554 3.853 10.85 4.283 18.794 7.952 23.84 10.994 5.046 3.041 9.089 5.618 12.135 7.708 17.705-4.947 35.976-7.421 54.818-7.421s37.117 2.474 54.823 7.421l10.849-6.849c7.419-4.57 16.18-8.758 26.262-12.565 10.088-3.805 17.802-4.853 23.134-3.138 8.562 21.509 9.325 40.922 2.279 58.24 15.036 16.18 22.559 35.787 22.559 58.817 0 16.178-1.958 30.497-5.853 42.966-3.9 12.471-8.941 22.457-15.125 29.979-6.191 7.521-13.901 13.85-23.131 18.986-9.232 5.14-18.182 8.85-26.84 11.136-8.662 2.286-18.415 4.004-29.263 5.146 9.894 8.562 14.842 22.077 14.842 40.539v60.237c0 3.422 1.19 6.279 3.572 8.562 2.379 2.279 6.136 2.95 11.276 1.995 44.163-14.653 80.185-41.062 108.068-79.226 27.88-38.161 41.825-81.126 41.825-128.906-.01-39.771-9.818-76.454-29.414-110.049z">
                        </path>
                    </svg>
                    
                    <span id="stargazers" class="text-muted-foreground w-8 text-xs tabular-nums" onload="test()">
                    </span>
                    
                </a>
                <div data-orientation="vertical" role="none" data-slot="separator"
                    class="bg-border shrink-0 data-[orientation=horizontal]:h-px data-[orientation=horizontal]:w-full data-[orientation=vertical]:h-full data-[orientation=vertical]:w-px 3xl:flex hidden">
                </div>
                <button data-slot="button"
                    class="items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*='size-'])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive hover:bg-accent hover:text-accent-foreground dark:hover:bg-accent/50 size-8 3xl:flex hidden"
                    title="Toggle layout" onclick="toggleLayout(event)">
                    <span class="sr-only">Toggle layout</span>
                    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
                        stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
                        class="lucide lucide-gallery-horizontal">
                        <path d="M2 3v18"></path>
                        <rect width="12" height="18" x="6" y="3" rx="2"></rect>
                        <path d="M22 3v18"></path>
                    </svg>
                </button>
                <div data-orientation="vertical" role="none" data-slot="separator"
                    class="bg-border shrink-0 data-[orientation=horizontal]:h-px data-[orientation=horizontal]:w-full data-[orientation=vertical]:h-full data-[orientation=vertical]:w-px">
                </div>
                <button data-slot="button"
                    class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*='size-'])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive hover:bg-accent hover:text-accent-foreground dark:hover:bg-accent/50 group/toggle extend-touch-target size-8"
                    title="Toggle theme" onclick="onThemeSwitch(event)">
                    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
                        stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
                        class="size-4.5">
                        <path stroke="none" d="M0 0h24v24H0z" fill="none"></path>
                        <path d="M12 12m-9 0a9 9 0 1 0 18 0a9 9 0 1 0 -18 0"></path>
                        <path d="M12 3l0 18"></path>
                        <path d="M12 9l4.65 -4.65"></path>
                        <path d="M12 14.3l7.37 -7.37"></path>
                        <path d="M12 19.6l8.85 -8.85"></path>
                    </svg>
                    <span class="sr-only">Toggle theme</span>
                </button>
            </div>
        </div>
    </div>
</header>
        <main class="flex flex-1 flex-col">
            <div class="container-wrapper flex flex-1 flex-col px-2">
                <div data-slot="sidebar-wrapper" style="--sidebar-width: 16rem; --sidebar-width-icon: 3rem;"
                    class="group/sidebar-wrapper has-data-[variant=inset]:bg-sidebar flex w-full 3xl:fixed:container 3xl:fixed:px-3 min-h-min flex-1 items-start px-0 [--sidebar-width:220px] [--top-spacing:0] lg:grid lg:grid-cols-[var(--sidebar-width)_minmax(0,1fr)] lg:[--sidebar-width:240px] lg:[--top-spacing:calc(var(--spacing)*4)]">
                    <div data-slot="sidebar"
                        class="text-sidebar-foreground w-(--sidebar-width) flex-col sticky top-[calc(var(--header-height)+1px)] z-30 hidden h-[calc(100svh-var(--header-height)-var(--footer-height))] bg-transparent lg:flex">
                        <div data-slot="sidebar-content" data-sidebar="content"
                            class="flex min-h-0 flex-1 flex-col gap-2 overflow-auto group-data-[collapsible=icon]:overflow-hidden no-scrollbar px-2 pb-12">
                            <div class="h-(--top-spacing) shrink-0"></div>
                            <div view-transition-name="sidebar" data-slot="sidebar-group" data-sidebar="group"
    class="relative flex w-full min-w-0 flex-col p-2 no-scrollbar">
    

    
    
    

    

    
    

    
    <div data-slot="sidebar-group" data-sidebar="group" class="relative flex w-full min-w-0 flex-col p-2">
        <div data-slot="sidebar-group-content" data-sidebar="group-content" class="w-full text-sm">
            <ul data-slot="sidebar-menu" data-sidebar="menu" class="flex w-full min-w-0 flex-col gap-0.5">
                
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Home
        

        

        

        
    </a>
</li>
                
                
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/toc/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Table of Contents
        

        

        

        
    </a>
</li>
                
                
            </ul>
        </div>
    </div>
    

    
    
    <div data-slot="sidebar-group" data-sidebar="group" class="relative flex w-full min-w-0 flex-col p-2">
        <div data-slot="sidebar-group-label" data-sidebar="group-label"
            class="ring-sidebar-ring flex h-8 shrink-0 items-center rounded-md px-2 text-xs outline-hidden transition-[margin,opacity] duration-200 ease-linear focus-visible:ring-2 [&amp;&gt;svg]:size-4 [&amp;&gt;svg]:shrink-0 group-data-[collapsible=icon]:-mt-8 group-data-[collapsible=icon]:opacity-0 text-muted-foreground font-medium">
            Loop</div>
        <div data-slot="sidebar-group-content" data-sidebar="group-content" class="w-full text-sm">
            <ul data-slot="sidebar-menu" data-sidebar="menu" class="flex w-full min-w-0 flex-col gap-0.5">
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/0_loop/0_index/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Training Loop
        

        

        

        
    </a>
</li>
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/0_loop/1_inference_loop/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Inference Loop
        

        

        

        
    </a>
</li>
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/0_loop/config/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Configuration
        

        

        

        
    </a>
</li>
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/0_loop/interfaces/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Interfaces & Logic
        

        

        

        
    </a>
</li>
                
            </ul>
        </div>
    </div>
    
    
    
    <div data-slot="sidebar-group" data-sidebar="group" class="relative flex w-full min-w-0 flex-col p-2">
        <div data-slot="sidebar-group-label" data-sidebar="group-label"
            class="ring-sidebar-ring flex h-8 shrink-0 items-center rounded-md px-2 text-xs outline-hidden transition-[margin,opacity] duration-200 ease-linear focus-visible:ring-2 [&amp;&gt;svg]:size-4 [&amp;&gt;svg]:shrink-0 group-data-[collapsible=icon]:-mt-8 group-data-[collapsible=icon]:opacity-0 text-muted-foreground font-medium">
            Core</div>
        <div data-slot="sidebar-group-content" data-sidebar="group-content" class="w-full text-sm">
            <ul data-slot="sidebar-menu" data-sidebar="menu" class="flex w-full min-w-0 flex-col gap-0.5">
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/core/autograd_extensions/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Autograd Extensions
        

        

        

        
    </a>
</li>
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/core/dist_context/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Distributed Context
        

        

        

        
    </a>
</li>
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/core/dist_ops/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Distributed Operations
        

        

        

        
    </a>
</li>
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/core/sharding/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        PyTree Sharding
        

        

        

        
    </a>
</li>
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/core/types/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Typing Extensions
        

        

        

        
    </a>
</li>
                
            </ul>
        </div>
    </div>
    
    
    
    <div data-slot="sidebar-group" data-sidebar="group" class="relative flex w-full min-w-0 flex-col p-2">
        <div data-slot="sidebar-group-label" data-sidebar="group-label"
            class="ring-sidebar-ring flex h-8 shrink-0 items-center rounded-md px-2 text-xs outline-hidden transition-[margin,opacity] duration-200 ease-linear focus-visible:ring-2 [&amp;&gt;svg]:size-4 [&amp;&gt;svg]:shrink-0 group-data-[collapsible=icon]:-mt-8 group-data-[collapsible=icon]:opacity-0 text-muted-foreground font-medium">
            Dataset</div>
        <div data-slot="sidebar-group-content" data-sidebar="group-content" class="w-full text-sm">
            <ul data-slot="sidebar-menu" data-sidebar="menu" class="flex w-full min-w-0 flex-col gap-0.5">
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/dataset/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Datasets
        

        

        

        
    </a>
</li>
                
            </ul>
        </div>
    </div>
    
    
    
    <div data-slot="sidebar-group" data-sidebar="group" class="relative flex w-full min-w-0 flex-col p-2">
        <div data-slot="sidebar-group-label" data-sidebar="group-label"
            class="ring-sidebar-ring flex h-8 shrink-0 items-center rounded-md px-2 text-xs outline-hidden transition-[margin,opacity] duration-200 ease-linear focus-visible:ring-2 [&amp;&gt;svg]:size-4 [&amp;&gt;svg]:shrink-0 group-data-[collapsible=icon]:-mt-8 group-data-[collapsible=icon]:opacity-0 text-muted-foreground font-medium">
            Internals</div>
        <div data-slot="sidebar-group-content" data-sidebar="group-content" class="w-full text-sm">
            <ul data-slot="sidebar-menu" data-sidebar="menu" class="flex w-full min-w-0 flex-col gap-0.5">
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/internals/determinism/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Determinism
        

        

        

        
    </a>
</li>
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/internals/grad_norm/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Gradient Norm & Clipping
        

        

        

        
    </a>
</li>
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/internals/grad_sync/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Gradient Synchronization
        

        

        

        
    </a>
</li>
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/internals/metric_collector/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Metric Collection
        

        

        

        
    </a>
</li>
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/internals/pipeline_state/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Pipeline State Management
        

        

        

        
    </a>
</li>
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="true" data-sidebar="menu-button"
        data-size="default" href="/d9d/internals/pipelining/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Pipelining Internals
        

        

        

        
    </a>
</li>
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/internals/profiling/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Distributed Profiling
        

        

        

        
    </a>
</li>
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/internals/tracker_integration/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Experiment Tracking
        

        

        

        
    </a>
</li>
                
            </ul>
        </div>
    </div>
    
    
    
    <div data-slot="sidebar-group" data-sidebar="group" class="relative flex w-full min-w-0 flex-col p-2">
        <div data-slot="sidebar-group-label" data-sidebar="group-label"
            class="ring-sidebar-ring flex h-8 shrink-0 items-center rounded-md px-2 text-xs outline-hidden transition-[margin,opacity] duration-200 ease-linear focus-visible:ring-2 [&amp;&gt;svg]:size-4 [&amp;&gt;svg]:shrink-0 group-data-[collapsible=icon]:-mt-8 group-data-[collapsible=icon]:opacity-0 text-muted-foreground font-medium">
            Lr scheduler</div>
        <div data-slot="sidebar-group-content" data-sidebar="group-content" class="w-full text-sm">
            <ul data-slot="sidebar-menu" data-sidebar="menu" class="flex w-full min-w-0 flex-col gap-0.5">
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/lr_scheduler/piecewise/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Piecewise Scheduler
        

        

        

        
    </a>
</li>
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/lr_scheduler/visualization/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Visualization
        

        

        

        
    </a>
</li>
                
            </ul>
        </div>
    </div>
    
    
    
    <div data-slot="sidebar-group" data-sidebar="group" class="relative flex w-full min-w-0 flex-col p-2">
        <div data-slot="sidebar-group-label" data-sidebar="group-label"
            class="ring-sidebar-ring flex h-8 shrink-0 items-center rounded-md px-2 text-xs outline-hidden transition-[margin,opacity] duration-200 ease-linear focus-visible:ring-2 [&amp;&gt;svg]:size-4 [&amp;&gt;svg]:shrink-0 group-data-[collapsible=icon]:-mt-8 group-data-[collapsible=icon]:opacity-0 text-muted-foreground font-medium">
            Metric</div>
        <div data-slot="sidebar-group-content" data-sidebar="group-content" class="w-full text-sm">
            <ul data-slot="sidebar-menu" data-sidebar="menu" class="flex w-full min-w-0 flex-col gap-0.5">
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/metric/0_index/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Metrics
        

        

        

        
    </a>
</li>
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/metric/custom/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Custom Metrics
        

        

        

        
    </a>
</li>
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/metric/implemented/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Implemented Metrics
        

        

        

        
    </a>
</li>
                
            </ul>
        </div>
    </div>
    
    
    
    <div data-slot="sidebar-group" data-sidebar="group" class="relative flex w-full min-w-0 flex-col p-2">
        <div data-slot="sidebar-group-label" data-sidebar="group-label"
            class="ring-sidebar-ring flex h-8 shrink-0 items-center rounded-md px-2 text-xs outline-hidden transition-[margin,opacity] duration-200 ease-linear focus-visible:ring-2 [&amp;&gt;svg]:size-4 [&amp;&gt;svg]:shrink-0 group-data-[collapsible=icon]:-mt-8 group-data-[collapsible=icon]:opacity-0 text-muted-foreground font-medium">
            Model states</div>
        <div data-slot="sidebar-group-content" data-sidebar="group-content" class="w-full text-sm">
            <ul data-slot="sidebar-menu" data-sidebar="menu" class="flex w-full min-w-0 flex-col gap-0.5">
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/model_states/io/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Model State I/O
        

        

        

        
    </a>
</li>
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/model_states/mapper/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Model State Mapper
        

        

        

        
    </a>
</li>
                
            </ul>
        </div>
    </div>
    
    
    
    <div data-slot="sidebar-group" data-sidebar="group" class="relative flex w-full min-w-0 flex-col p-2">
        <div data-slot="sidebar-group-label" data-sidebar="group-label"
            class="ring-sidebar-ring flex h-8 shrink-0 items-center rounded-md px-2 text-xs outline-hidden transition-[margin,opacity] duration-200 ease-linear focus-visible:ring-2 [&amp;&gt;svg]:size-4 [&amp;&gt;svg]:shrink-0 group-data-[collapsible=icon]:-mt-8 group-data-[collapsible=icon]:opacity-0 text-muted-foreground font-medium">
            Models</div>
        <div data-slot="sidebar-group-content" data-sidebar="group-content" class="w-full text-sm">
            <ul data-slot="sidebar-menu" data-sidebar="menu" class="flex w-full min-w-0 flex-col gap-0.5">
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/models/1_model_design/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Model Design
        

        

        

        
    </a>
</li>
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/models/2_horizontal_parallelism/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Horizontal Parallelism
        

        

        

        
    </a>
</li>
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/models/3_pipeline_parallelism/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Pipeline Parallelism
        

        

        

        
    </a>
</li>
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/models/4_model_catalogue/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Model Catalogue
        

        

        

        
    </a>
</li>
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/models/qwen3_moe/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Qwen3 MoE
        

        

        

        
    </a>
</li>
                
            </ul>
        </div>
    </div>
    
    
    
    <div data-slot="sidebar-group" data-sidebar="group" class="relative flex w-full min-w-0 flex-col p-2">
        <div data-slot="sidebar-group-label" data-sidebar="group-label"
            class="ring-sidebar-ring flex h-8 shrink-0 items-center rounded-md px-2 text-xs outline-hidden transition-[margin,opacity] duration-200 ease-linear focus-visible:ring-2 [&amp;&gt;svg]:size-4 [&amp;&gt;svg]:shrink-0 group-data-[collapsible=icon]:-mt-8 group-data-[collapsible=icon]:opacity-0 text-muted-foreground font-medium">
            Modules</div>
        <div data-slot="sidebar-group-content" data-sidebar="group-content" class="w-full text-sm">
            <ul data-slot="sidebar-menu" data-sidebar="menu" class="flex w-full min-w-0 flex-col gap-0.5">
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/modules/attention/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Attention Layers
        

        

        

        
    </a>
</li>
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/modules/embedding/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Embeddings
        

        

        

        
    </a>
</li>
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/modules/ffn/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Feed Forward Networks (FFN)
        

        

        

        
    </a>
</li>
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/modules/head/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Model Heads
        

        

        

        
    </a>
</li>
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/modules/hidden_states_aggregator/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Hidden States Aggregation
        

        

        

        
    </a>
</li>
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/modules/moe/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Mixture of Experts (MoE)
        

        

        

        
    </a>
</li>
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/modules/positional/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Positional Embeddings
        

        

        

        
    </a>
</li>
                
            </ul>
        </div>
    </div>
    
    
    
    <div data-slot="sidebar-group" data-sidebar="group" class="relative flex w-full min-w-0 flex-col p-2">
        <div data-slot="sidebar-group-label" data-sidebar="group-label"
            class="ring-sidebar-ring flex h-8 shrink-0 items-center rounded-md px-2 text-xs outline-hidden transition-[margin,opacity] duration-200 ease-linear focus-visible:ring-2 [&amp;&gt;svg]:size-4 [&amp;&gt;svg]:shrink-0 group-data-[collapsible=icon]:-mt-8 group-data-[collapsible=icon]:opacity-0 text-muted-foreground font-medium">
            Optimizer</div>
        <div data-slot="sidebar-group-content" data-sidebar="group-content" class="w-full text-sm">
            <ul data-slot="sidebar-menu" data-sidebar="menu" class="flex w-full min-w-0 flex-col gap-0.5">
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/optimizer/stochastic/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Stochastic Optimizers
        

        

        

        
    </a>
</li>
                
            </ul>
        </div>
    </div>
    
    
    
    <div data-slot="sidebar-group" data-sidebar="group" class="relative flex w-full min-w-0 flex-col p-2">
        <div data-slot="sidebar-group-label" data-sidebar="group-label"
            class="ring-sidebar-ring flex h-8 shrink-0 items-center rounded-md px-2 text-xs outline-hidden transition-[margin,opacity] duration-200 ease-linear focus-visible:ring-2 [&amp;&gt;svg]:size-4 [&amp;&gt;svg]:shrink-0 group-data-[collapsible=icon]:-mt-8 group-data-[collapsible=icon]:opacity-0 text-muted-foreground font-medium">
            Peft</div>
        <div data-slot="sidebar-group-content" data-sidebar="group-content" class="w-full text-sm">
            <ul data-slot="sidebar-menu" data-sidebar="menu" class="flex w-full min-w-0 flex-col gap-0.5">
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/peft/0_index/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        PEFT Overview
        

        

        

        
    </a>
</li>
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/peft/full_tune/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Full Fine-Tuning
        

        

        

        
    </a>
</li>
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/peft/lora/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        LoRA
        

        

        

        
    </a>
</li>
                
                <li data-slot="sidebar-menu-item" data-sidebar="menu-item" class="group/menu-item relative">
    <a data-slot="sidebar-menu-button" data-active="false" data-sidebar="menu-button"
        data-size="default" href="/d9d/peft/stack/"
        class="hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer/menu-button flex items-center gap-2 rounded-md p-2 text-left outline-hidden ring-sidebar-ring transition-[width,height,padding] focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0 data-[active=true]:bg-accent data-[active=true]:border-accent 3xl:fixed:w-full 3xl:fixed:max-w-48 relative h-[30px] w-fit overflow-visible border border-transparent text-[0.8rem] font-medium after:absolute after:inset-x-0 after:-inset-y-1 after:z-0 after:rounded-md">

        
        Method Stacking
        

        

        

        
    </a>
</li>
                
            </ul>
        </div>
    </div>
    
    


    
</div>
                        </div>
                    </div>
                    <div class="h-full w-full">
                        <div data-slot="docs" class="flex items-stretch text-[1.05rem] sm:text-[15px] xl:w-full">
                            <div class="flex min-w-0 flex-1 flex-col">
                                <div class="h-(--top-spacing) shrink-0"></div>
                                <article class="w-full" view-transition-name="page">
  <div class="flex flex-col gap-2">
    <div class="flex flex-col gap-2">
      <div id="page-header" class="flex items-start justify-between">
        <h1
          class="scroll-m-20 text-4xl font-semibold tracking-tight sm:text-3xl xl:text-4xl"
        >
          Pipelining Internals
        </h1>

        <div class="flex items-center gap-2 pt-1.5">
          
<button onclick="fetch(`https://d9d-project.github.io/d9d/internals/pipelining.md`).then((r) => r.blob()).then((blob) => navigator.clipboard.write([new ClipboardItem({ 'text/plain': blob })]))" 
        data-slot="button" 
        class="cursor-pointer inline-flex items-center justify-center whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg:not([class*='size-'])]:size-4 shrink-0 [&_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive bg-secondary text-secondary-foreground hover:bg-secondary/80 rounded-md gap-1.5 px-3 has-[&>svg]:px-2.5 h-8 shadow-none md:h-7 md:text-[0.8rem]">
<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="tabler-icon tabler-icon-copy ">
    <path d="M7 7m0 2.667a2.667 2.667 0 0 1 2.667 -2.667h8.666a2.667 2.667 0 0 1 2.667 2.667v8.666a2.667 2.667 0 0 1 -2.667 2.667h-8.666a2.667 2.667 0 0 1 -2.667 -2.667z"></path><path d="M4.012 16.737a2.005 2.005 0 0 1 -1.012 -1.737v-10c0 -1.1 .9 -2 2 -2h10c.75 0 1.158 .385 1.5 1"></path>
</svg>
<span class="max-md:hidden">Copy Page</span>
</button> 
          
          <a
            data-slot="button"
            id="previous-button"
            class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*='size-'])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive bg-secondary text-secondary-foreground hover:bg-secondary/80 extend-touch-target size-8 shadow-none md:size-7"
            href="/d9d/internals/pipeline_state/"
          >
            <svg
              xmlns="http://www.w3.org/2000/svg"
              width="24"
              height="24"
              viewBox="0 0 24 24"
              fill="none"
              stroke="currentColor"
              stroke-width="2"
              stroke-linecap="round"
              stroke-linejoin="round"
              class="tabler-icon tabler-icon-arrow-left"
            >
              <path d="M5 12l14 0"></path>
              <path d="M5 12l6 6"></path>
              <path d="M5 12l6 -6"></path>
            </svg>
            <span class="sr-only">Previous</span>
          </a>
           
          
          <a
            data-slot="button"
            id="next-button"
            class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*='size-'])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive bg-secondary text-secondary-foreground hover:bg-secondary/80 extend-touch-target size-8 shadow-none md:size-7"
            href="/d9d/internals/profiling/"
          >
            <span class="sr-only">Next</span>
            <svg
              xmlns="http://www.w3.org/2000/svg"
              width="24"
              height="24"
              viewBox="0 0 24 24"
              fill="none"
              stroke="currentColor"
              stroke-width="2"
              stroke-linecap="round"
              stroke-linejoin="round"
              class="tabler-icon tabler-icon-arrow-right"
            >
              <path d="M5 12l14 0"></path>
              <path d="M13 18l6 -6"></path>
              <path d="M13 6l6 6"></path>
            </svg>
          </a>
          
        </div>
      </div>
      
    </div>
    <div class="flex justify-end items-center">
        <div class="grow text-muted-foreground pt-4 flex flex-row justify-end items-center">
    <span id="updated_at" class="text-sm opacity-50 hover:opacity-100 transition-opacity duration-200"
        title="last update (local time)"></span>
</div>

<script>
    const updatedAt = document.getElementById("updated_at");
    if (updatedAt) {
        const date = new Date('2026-02-13T00:36:14+03:00');
        updatedAt.textContent = date.toLocaleDateString();
    }
</script>
 
    </div>
  </div>
  <div class="typography w-full flex-1 *:data-[slot=alert]:first:mt-0">
    <p>This section details the internals of the <code>d9d.pipelining</code> module. It is intended for those who wish to implement new layouts, schedules, or modify the execution engine.</p>
<h2 id="architecture">Architecture</h2>
<h3 id="the-idea">The Idea</h3>
<p>d9d decouples the <strong>Schedule Structure</strong> from the <strong>Runtime Execution</strong>.</p>
<ol>
<li>You write a builder (e.g., <code>1F1B</code>, <code>DualPipe</code>) that generates a linear list of logical <code>Actions</code> (e.g., <code>Forward(Stage=0, MB=1)</code>, <code>Backward(Stage=0, MB=0)</code>). If you want, d9d may automatically inject <code>Send</code>/<code>Recv</code> actions into your compute-only schedule based on data dependencies, preventing deadlocks.</li>
<li>You run a dumb virtual machine simply iterates the action list and executes them.</li>
</ol>
<p>This makes implementing complex research schedules (like Zero Bubble or DualPipeV) significantly easier than managing state machines or recursive calls.</p>
<h3 id="core-components">Core Components</h3>
<h4 id="pipelinestage-infrastagestagepy">PipelineStage (<code>infra/stage/stage.py</code>)</h4>
<p>Encapsulates a user <code>nn.Module</code>. It is <strong>not</strong> responsible for deciding <em>when</em> to run. Instead, it provides atomic pipeline stage capabilities (such as forward and backward passes) to the actions and the executor.</p>
<p>Consists of:</p>
<ul>
<li><strong>Computation Handlers</strong>: <ul>
<li><code>ForwardComputeHandler</code>: Performs forward pass, caches inputs/outputs for backward passes.</li>
<li><code>BackwardComputeHandler</code>: Performs backward pass, capable of splitting backward passes into <code>backward_input</code> (dI) and <code>backward_weight</code> (dW) for advanced schedules.</li>
</ul>
</li>
<li><strong>Communication Handlers</strong>: Contain and manage the P2P buffers for both forward and backward passes.</li>
</ul>
<h4 id="actions-infraschedulecomponentruntimeactionpy">Actions (<code>infra/schedule/component/runtime/action.py</code>)</h4>
<p>The atomic instructions for the pipeline virtual machine.</p>
<ul>
<li><code>ForwardComputeAction</code>: Run forward on specific microbatch.</li>
<li><code>BackwardFullInputComputeAction</code>: Run backward. Can be configured to compute gradients for inputs-only or inputs+weights.</li>
<li><code>BackwardWeightComputeAction</code>: Compute gradients for weights (used in Zero Bubble schedules).</li>
<li><code>ForwardSendAction</code> / <code>ForwardReceiveAction</code> / <code>BackwardSendAction</code> / <code>BackwardReceiveAction</code>: Network IO.</li>
<li><code>ComposeAction</code>: Composes multiple actions into a single one. Used for Forward/Backward overlap in schedules such as DualPipeV.</li>
</ul>
<p>Actions are designed to be declarative and immutable.</p>
<h4 id="programs">Programs</h4>
<p>A <code>Program</code> is simply <code>dict[int, list[ActionBase]]</code> — a mapping of Rank ID to a sequential list of Actions.</p>
<h4 id="executor-infraschedulecomponentruntimeexecutorpy">Executor (<code>infra/schedule/component/runtime/executor.py</code>)</h4>
<p>The <code>PipelineScheduleExecutor</code> is the runtime engine. </p>
<p>It:</p>
<ol>
<li>Shards global inputs into microbatches.</li>
<li>Iterates through the <code>Program</code> action list.</li>
<li>Dispatches calls to <code>Action</code>s that perform computation or communication workload.</li>
</ol>
<h3 id="comparison-with-pytorch">Comparison with PyTorch</h3>
<p>The d9d pipelining implementation is heavily inspired by and borrows concepts from the <code>torch.distributed.pipelining</code> API (e.g., ZeroBubble implementation), but refactors the codebase significantly to improve clarity, type safety, and modularity.</p>
<p>The main architectural differences lie in the <strong>strict separation of concerns</strong> and <strong>composition over inheritance</strong>:</p>
<ol>
<li>
<p><strong>Decomposed Stage Logic</strong>:</p>
<ul>
<li><strong>PyTorch</strong>: Uses a monolithic <code>_PipelineStageBase</code> class that simultaneously manages P2P buffer allocation, gradient accumulation state, and forward/backward execution logic.</li>
<li><strong>d9d</strong>: Adopts a compositional approach. The <code>PipelineStage</code> class is a thin orchestrator that delegates responsibilities to dedicated handlers.</li>
</ul>
</li>
<li>
<p><strong>Polymorphic Actions vs Enumeration</strong>:</p>
<ul>
<li><strong>PyTorch</strong>: Represents schedule instructions using a single generic <code>_Action</code> NamedTuple combined with an Enum (<code>_ComputationType.FORWARD</code>, <code>_ComputationType.SEND_F</code>, etc.).</li>
<li><strong>d9d</strong>: Uses a class hierarchy for actions (<code>ForwardComputeAction</code>, <code>ForwardSendAction</code>, <code>ComposeAction</code>). This allows the runtime executor to use structural pattern matching (<code>match/case</code>) rather than large <code>if/elif</code> blocks checking enums, allows different actions to carry different metadata (e.g. <code>full_backward</code> flag), and improves static type checking.</li>
</ul>
</li>
<li>
<p><strong>Builder Pattern vs Schedule Classes</strong>:</p>
<ul>
<li><strong>PyTorch</strong>: Often couples the schedule definition with the runtime object (e.g., <code>Schedule1F1B</code> class contains both the logic to generate the ordering and the logic to execute it).</li>
<li><strong>d9d</strong>: Strictly separates the <strong>Program Builder</strong> (which generates the list of actions) from the <strong>Executor</strong> (which runs the actions). This makes it easier to inspect a schedule plan before execution or swap scheduling algorithms without changing the runtime driver.</li>
</ul>
</li>
</ol>
<h2 id="building-custom-schedules">Building Custom Schedules</h2>
<p>To build a new schedule, you create a <code>PipelineProgramBuilder</code>.</p>
<h3 id="implement-the-builder">Implement the Builder</h3>
<p>You must implement the pipeline program builder.</p>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">defaultdict</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">d9d.pipelining.infra.schedule.component.program</span><span class="w"> </span><span class="kn">import</span> <span class="n">PipelineProgramBuilder</span><span class="p">,</span> <span class="n">build_stage_to_host_rank_topology</span><span class="p">,</span> <span class="n">ScheduleStyle</span><span class="p">,</span> <span class="n">add_communication_ops</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">d9d.pipelining.infra.schedule.component.runtime</span><span class="w"> </span><span class="kn">import</span> <span class="n">ActionBase</span><span class="p">,</span> <span class="n">ForwardComputeAction</span>


<span class="k">class</span><span class="w"> </span><span class="nc">MyFancyScheduleBuilder</span><span class="p">(</span><span class="n">PipelineProgramBuilder</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stages_per_rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stages_per_rank</span> <span class="o">=</span> <span class="n">stages_per_rank</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">num_stages_per_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stages_per_rank</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">topology_style</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ScheduleStyle</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ScheduleStyle</span><span class="o">.</span><span class="n">loop</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">compose</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_microbatches</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">pp_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">ActionBase</span><span class="p">]]:</span>
        <span class="c1"># Map logical stages to ranks</span>
        <span class="n">stage_to_rank</span> <span class="o">=</span> <span class="n">build_stage_to_host_rank_topology</span><span class="p">(</span><span class="n">num_stages</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_stages_per_rank</span> <span class="o">*</span> <span class="n">pp_size</span><span class="p">,</span>
                                                          <span class="n">style</span><span class="o">=</span><span class="n">ScheduleStyle</span><span class="o">.</span><span class="n">loop</span><span class="p">,</span>
                                                          <span class="n">pp_size</span><span class="o">=</span><span class="n">pp_size</span><span class="p">)</span>

        <span class="n">actions</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>

        <span class="c1"># 1. Generate Compute Schedule</span>
        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">pp_size</span><span class="p">):</span>
            <span class="c1"># ... custom logic to decide order of Fwd/Bwd ...</span>
            <span class="n">actions</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ForwardComputeAction</span><span class="p">(</span><span class="n">stage_idx</span><span class="o">=...</span><span class="p">,</span> <span class="n">microbatch_idx</span><span class="o">=...</span><span class="p">))</span>

        <span class="c1"># 2. Inject Communications (Magic Pass)</span>
        <span class="c1"># This analyzes data dependencies between stages and inserts Send/Recvs</span>
        <span class="k">return</span> <span class="n">add_communication_ops</span><span class="p">(</span><span class="n">actions</span><span class="p">,</span> <span class="n">stage_to_rank</span><span class="p">,</span> <span class="n">num_stages</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_stages_per_rank</span> <span class="o">*</span> <span class="n">pp_size</span><span class="p">)</span>
</code></pre></div>

<h3 id="registering">Registering</h3>
<p>Add your configuration to <code>factory/config.py</code> and register the builder in <code>factory/factory.py</code>.</p>


<div class="doc doc-object doc-module">



<h2 id="d9d.pipelining.infra.stage" class="doc doc-heading">
            <code>d9d.pipelining.infra.stage</code>


</h2>

    <div class="doc doc-contents first">










<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="d9d.pipelining.infra.stage.PipelineStage" class="doc doc-heading">
            <code>PipelineStage</code>


</h3>


    <div class="doc doc-contents ">



        <p>Represents a single structural stage in a Pipelined Model.</p>
<p>This class acts as an orchestrator that combines <code>StageCommunicationHandler</code> (for I/O)
and <code>Forward/BackwardComputeHandler</code> (for execution). It abstracts away the complexity
of buffer management, distributed communication, and gradient calculation from the scheduler.</p>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>d9d/pipelining/infra/stage/stage.py</code></summary>
                <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 13</span>
<span class="normal"> 14</span>
<span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">PipelineStage</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Represents a single structural stage in a Pipelined Model.</span>

<span class="sd">    This class acts as an orchestrator that combines `StageCommunicationHandler` (for I/O)</span>
<span class="sd">    and `Forward/BackwardComputeHandler` (for execution). It abstracts away the complexity</span>
<span class="sd">    of buffer management, distributed communication, and gradient calculation from the scheduler.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">info</span><span class="p">:</span> <span class="n">PipelineStageInfo</span><span class="p">,</span>
        <span class="n">module</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">group</span><span class="p">:</span> <span class="n">dist</span><span class="o">.</span><span class="n">ProcessGroup</span><span class="p">,</span>
        <span class="n">stage_to_host_topology</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Constructs a PipelineStage object.</span>

<span class="sd">        Args:</span>
<span class="sd">            info: Metadata about the stage (index, total stages).</span>
<span class="sd">            module: The PyTorch module executed by this stage.</span>
<span class="sd">            group: The distributed process group for pipeline communications.</span>
<span class="sd">            stage_to_host_topology: Dict mapping stage ID to PP rank hosting it.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_info</span> <span class="o">=</span> <span class="n">info</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_module</span> <span class="o">=</span> <span class="n">module</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_group</span> <span class="o">=</span> <span class="n">group</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stage_to_host_topology</span> <span class="o">=</span> <span class="n">stage_to_host_topology</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_forward_comm</span><span class="p">:</span> <span class="n">StageCommunicationHandler</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comm</span><span class="p">:</span> <span class="n">StageCommunicationHandler</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_forward_comp</span> <span class="o">=</span> <span class="n">ForwardComputeHandler</span><span class="p">(</span><span class="n">stage_index</span><span class="o">=</span><span class="n">info</span><span class="o">.</span><span class="n">current_stage</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="n">module</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comp</span> <span class="o">=</span> <span class="n">BackwardComputeHandler</span><span class="p">(</span><span class="n">stage_index</span><span class="o">=</span><span class="n">info</span><span class="o">.</span><span class="n">current_stage</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="n">module</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">info</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">PipelineStageInfo</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">configure_buffers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_microbatches</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">has_backward</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">pipeline_inputs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes the communication handlers and buffers for the stage.</span>

<span class="sd">        This must be called before execution to establish P2P buffer sizes and directions.</span>

<span class="sd">        Args:</span>
<span class="sd">            num_microbatches: Total number of microbatches to process.</span>
<span class="sd">            has_backward: Does this pipeline stage should store info for a backward pass</span>
<span class="sd">            pipeline_inputs: Pipeline input data.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span> <span class="o">=</span> <span class="n">has_backward</span>

        <span class="n">prev_stage_idx</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">is_current_stage_first</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">current_stage</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="n">next_stage_idx</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">is_current_stage_last</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">current_stage</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;meta&quot;</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_module</span><span class="p">,</span> <span class="n">ModuleSupportsPipelining</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Module does not implement ModuleSupportsPipelining protocol&quot;</span><span class="p">)</span>
            <span class="n">inputs_meta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_module</span><span class="o">.</span><span class="n">infer_stage_inputs_from_pipeline_inputs</span><span class="p">(</span>
                <span class="n">inputs</span><span class="o">=</span><span class="n">pipeline_inputs</span><span class="p">,</span> <span class="n">n_microbatches</span><span class="o">=</span><span class="n">num_microbatches</span>
            <span class="p">)</span>
            <span class="n">outputs_meta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_module</span><span class="o">.</span><span class="n">infer_stage_outputs_from_pipeline_inputs</span><span class="p">(</span>
                <span class="n">inputs</span><span class="o">=</span><span class="n">pipeline_inputs</span><span class="p">,</span> <span class="n">n_microbatches</span><span class="o">=</span><span class="n">num_microbatches</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_forward_comm</span> <span class="o">=</span> <span class="n">StageCommunicationHandler</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;fwd&quot;</span><span class="p">,</span>
            <span class="n">stage_index</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">current_stage</span><span class="p">,</span>
            <span class="n">num_microbatches</span><span class="o">=</span><span class="n">num_microbatches</span><span class="p">,</span>
            <span class="n">input_stage_index</span><span class="o">=</span><span class="n">prev_stage_idx</span><span class="p">,</span>
            <span class="n">input_args</span><span class="o">=</span><span class="n">inputs_meta</span><span class="p">,</span>
            <span class="n">output_stage_index</span><span class="o">=</span><span class="n">next_stage_idx</span><span class="p">,</span>
            <span class="n">output_args</span><span class="o">=</span><span class="n">outputs_meta</span><span class="p">,</span>
            <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_group</span><span class="p">,</span>
            <span class="n">stage_idx_to_host_rank</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_stage_to_host_topology</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_forward_comm</span><span class="o">.</span><span class="n">set_input_requires_grad_</span><span class="p">(</span><span class="n">requires_grad</span><span class="o">=</span><span class="n">has_backward</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">has_backward</span><span class="p">:</span>
            <span class="c1"># for grad - current stage receives OUTPUTS as inputs and sends INPUTS as outputs</span>
            <span class="c1"># because it is reversed forward</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comm</span> <span class="o">=</span> <span class="n">StageCommunicationHandler</span><span class="p">(</span>
                <span class="n">name</span><span class="o">=</span><span class="s2">&quot;bwd&quot;</span><span class="p">,</span>
                <span class="n">stage_index</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">current_stage</span><span class="p">,</span>
                <span class="n">num_microbatches</span><span class="o">=</span><span class="n">num_microbatches</span><span class="p">,</span>
                <span class="n">input_stage_index</span><span class="o">=</span><span class="n">next_stage_idx</span><span class="p">,</span>
                <span class="n">input_args</span><span class="o">=</span><span class="n">outputs_meta</span><span class="p">,</span>
                <span class="n">output_stage_index</span><span class="o">=</span><span class="n">prev_stage_idx</span><span class="p">,</span>
                <span class="n">output_args</span><span class="o">=</span><span class="n">inputs_meta</span><span class="p">,</span>
                <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_group</span><span class="p">,</span>
                <span class="n">stage_idx_to_host_rank</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_stage_to_host_topology</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comm</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">set_local_fwd_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">microbatch_index</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets local forward inputs manually.</span>

<span class="sd">        Used for the V-shape schedulers.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_comm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You must configure stage buffers first&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_forward_comm</span><span class="o">.</span><span class="n">set_inputs_local</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_local_fwd_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_comp</span><span class="o">.</span><span class="n">get_outputs</span><span class="p">(</span><span class="n">microbatch_index</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">pop_local_bwd_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Retrieves local backward outputs (gradients).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">()</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comp</span><span class="o">.</span><span class="n">pop_for_sending</span><span class="p">(</span><span class="n">microbatch_index</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">set_local_bwd_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">microbatch_index</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets local backward inputs (output gradients) manually.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You must configure stage buffers first&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comm</span><span class="o">.</span><span class="n">set_inputs_local</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_fwd_recv_ops</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">dist</span><span class="o">.</span><span class="n">P2POp</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns P2P ops to receive forward inputs for the given microbatch.&quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_comm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You must configure stage buffers first&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_comm</span><span class="o">.</span><span class="n">create_receive_ops</span><span class="p">(</span><span class="n">microbatch_index</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_fwd_send_ops</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">dist</span><span class="o">.</span><span class="n">P2POp</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns P2P ops to send forward outputs for the given microbatch.&quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_comm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You must configure stage buffers first&quot;</span><span class="p">)</span>

        <span class="n">fwd_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_comp</span><span class="o">.</span><span class="n">get_outputs</span><span class="p">(</span><span class="n">microbatch_index</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_comm</span><span class="o">.</span><span class="n">create_send_ops</span><span class="p">(</span><span class="n">fwd_result</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_bwd_recv_ops</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">dist</span><span class="o">.</span><span class="n">P2POp</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns P2P ops to receive backward gradients for the given microbatch.&quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You must configure stage buffers first&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comm</span><span class="o">.</span><span class="n">create_receive_ops</span><span class="p">(</span><span class="n">microbatch_index</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_bwd_send_ops</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">dist</span><span class="o">.</span><span class="n">P2POp</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns P2P ops to send backward gradients for the given microbatch.&quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You must configure stage buffers first&quot;</span><span class="p">)</span>

        <span class="n">bwd_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comp</span><span class="o">.</span><span class="n">pop_for_sending</span><span class="p">(</span><span class="n">microbatch_index</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comm</span><span class="o">.</span><span class="n">create_send_ops</span><span class="p">(</span><span class="n">bwd_result</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward_one_chunk</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">microbatch_index</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">pipeline_inputs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
        <span class="n">pipeline_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Executes a forward pass for a single microbatch chunk.</span>

<span class="sd">        Fetches inputs from the communication buffer (or `pipeline_inputs` if first stage),</span>
<span class="sd">        runs the computation, and caches the result.</span>

<span class="sd">        Args:</span>
<span class="sd">            microbatch_index: The microbatch index.</span>
<span class="sd">            pipeline_inputs: Inputs provided locally (only used if this is the first stage).</span>
<span class="sd">            pipeline_kwargs: Additional arguments for the module.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The output tensors of the forward pass.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_comm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You must configure stage buffers first&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">is_current_stage_first</span><span class="p">:</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="n">pipeline_inputs</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_comm</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">(</span><span class="n">microbatch_index</span><span class="p">)</span>

        <span class="n">kwargs</span> <span class="o">=</span> <span class="n">pipeline_kwargs</span> <span class="ow">or</span> <span class="p">{}</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_forward_comp</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">microbatch_index</span><span class="o">=</span><span class="n">microbatch_index</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">kwargs</span><span class="o">=</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">backward_one_chunk</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">full_backward</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Executes a backward pass for a single microbatch chunk.</span>

<span class="sd">        Can perform either a full backward or just the input gradients (if `full_backward=False`).</span>
<span class="sd">        It fetches required data from forward cache and communication buffers.</span>

<span class="sd">        Args:</span>
<span class="sd">            microbatch_index: The microbatch index.</span>
<span class="sd">            loss: The loss tensor (only used if this is the last stage).</span>
<span class="sd">            full_backward: If True, computes grads for inputs and weights. If False, only for inputs.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You must configure stage buffers first&quot;</span><span class="p">)</span>

        <span class="n">inputs</span><span class="p">,</span> <span class="n">fwd_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_comp</span><span class="o">.</span><span class="n">pop_inputs_outputs</span><span class="p">(</span><span class="n">microbatch_index</span><span class="p">)</span>

        <span class="n">outputs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span>
        <span class="n">outputs_grad</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">is_current_stage_last</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">loss</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Cannot perform backward on last stage without loss specified&quot;</span><span class="p">)</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="n">loss</span><span class="p">}</span>
            <span class="n">outputs_grad</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">fwd_outputs</span>
            <span class="n">outputs_grad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comm</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">(</span><span class="n">microbatch_index</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">full_backward</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comp</span><span class="o">.</span><span class="n">backward_full</span><span class="p">(</span>
                <span class="n">microbatch_index</span><span class="o">=</span><span class="n">microbatch_index</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">outputs_grad</span><span class="o">=</span><span class="n">outputs_grad</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comp</span><span class="o">.</span><span class="n">backward_input</span><span class="p">(</span>
                <span class="n">microbatch_index</span><span class="o">=</span><span class="n">microbatch_index</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">outputs_grad</span><span class="o">=</span><span class="n">outputs_grad</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">is_current_stage_last</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">is_current_stage_first</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">fwd_outputs</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">t</span><span class="o">.</span><span class="n">_is_view</span><span class="p">():</span>  <span class="c1"># noqa: SLF001</span>
                    <span class="n">t</span><span class="o">.</span><span class="n">detach_</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">backward_weight_one_chunk</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Executes the weight gradient accumulation part of the backward pass.</span>

<span class="sd">        This assumes `backward_one_chunk(..., full_backward=False)` was already called</span>
<span class="sd">        for this microbatch.</span>

<span class="sd">        Args:</span>
<span class="sd">            microbatch_index: The microbatch index.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comp</span><span class="o">.</span><span class="n">backward_weight</span><span class="p">(</span><span class="n">microbatch_index</span><span class="o">=</span><span class="n">microbatch_index</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Resets the internal state of communication handlers, clearing gradients on buffers.&quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_forward_comm</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comm</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
</code></pre></div></td></tr></table></div></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="d9d.pipelining.infra.stage.PipelineStage.__init__" class="doc doc-heading">
            <code class=" language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">info</span><span class="p">,</span> <span class="n">module</span><span class="p">,</span> <span class="n">group</span><span class="p">,</span> <span class="n">stage_to_host_topology</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Constructs a PipelineStage object.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <div class="table-wrapper"><table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>info</code>
            </td>
            <td>
                  <code><a class="autorefs autorefs-internal" title="PipelineStageInfo


  
      dataclass
   (d9d.pipelining.api.PipelineStageInfo)" href="../../models/3_pipeline_parallelism/#d9d.pipelining.api.PipelineStageInfo">PipelineStageInfo</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Metadata about the stage (index, total stages).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>module</code>
            </td>
            <td>
                  <code><span title="torch.nn.Module">Module</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The PyTorch module executed by this stage.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>group</code>
            </td>
            <td>
                  <code><span title="torch.distributed.ProcessGroup">ProcessGroup</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The distributed process group for pipeline communications.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>stage_to_host_topology</code>
            </td>
            <td>
                  <code><span title="dict">dict</span>[<span title="int">int</span>, <span title="int">int</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dict mapping stage ID to PP rank hosting it.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>d9d/pipelining/infra/stage/stage.py</code></summary>
              <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">info</span><span class="p">:</span> <span class="n">PipelineStageInfo</span><span class="p">,</span>
    <span class="n">module</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">group</span><span class="p">:</span> <span class="n">dist</span><span class="o">.</span><span class="n">ProcessGroup</span><span class="p">,</span>
    <span class="n">stage_to_host_topology</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Constructs a PipelineStage object.</span>

<span class="sd">    Args:</span>
<span class="sd">        info: Metadata about the stage (index, total stages).</span>
<span class="sd">        module: The PyTorch module executed by this stage.</span>
<span class="sd">        group: The distributed process group for pipeline communications.</span>
<span class="sd">        stage_to_host_topology: Dict mapping stage ID to PP rank hosting it.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_info</span> <span class="o">=</span> <span class="n">info</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_module</span> <span class="o">=</span> <span class="n">module</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_group</span> <span class="o">=</span> <span class="n">group</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_stage_to_host_topology</span> <span class="o">=</span> <span class="n">stage_to_host_topology</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_forward_comm</span><span class="p">:</span> <span class="n">StageCommunicationHandler</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comm</span><span class="p">:</span> <span class="n">StageCommunicationHandler</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_forward_comp</span> <span class="o">=</span> <span class="n">ForwardComputeHandler</span><span class="p">(</span><span class="n">stage_index</span><span class="o">=</span><span class="n">info</span><span class="o">.</span><span class="n">current_stage</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="n">module</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comp</span> <span class="o">=</span> <span class="n">BackwardComputeHandler</span><span class="p">(</span><span class="n">stage_index</span><span class="o">=</span><span class="n">info</span><span class="o">.</span><span class="n">current_stage</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="n">module</span><span class="p">)</span>
</code></pre></div></td></tr></table></div></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="d9d.pipelining.infra.stage.PipelineStage.backward_one_chunk" class="doc doc-heading">
            <code class=" language-python"><span class="n">backward_one_chunk</span><span class="p">(</span><span class="n">microbatch_index</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">full_backward</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Executes a backward pass for a single microbatch chunk.</p>
<p>Can perform either a full backward or just the input gradients (if <code>full_backward=False</code>).
It fetches required data from forward cache and communication buffers.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <div class="table-wrapper"><table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>microbatch_index</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The microbatch index.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>loss</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span> | None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The loss tensor (only used if this is the last stage).</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>full_backward</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, computes grads for inputs and weights. If False, only for inputs.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>d9d/pipelining/infra/stage/stage.py</code></summary>
              <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">backward_one_chunk</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">full_backward</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Executes a backward pass for a single microbatch chunk.</span>

<span class="sd">    Can perform either a full backward or just the input gradients (if `full_backward=False`).</span>
<span class="sd">    It fetches required data from forward cache and communication buffers.</span>

<span class="sd">    Args:</span>
<span class="sd">        microbatch_index: The microbatch index.</span>
<span class="sd">        loss: The loss tensor (only used if this is the last stage).</span>
<span class="sd">        full_backward: If True, computes grads for inputs and weights. If False, only for inputs.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">()</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You must configure stage buffers first&quot;</span><span class="p">)</span>

    <span class="n">inputs</span><span class="p">,</span> <span class="n">fwd_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_comp</span><span class="o">.</span><span class="n">pop_inputs_outputs</span><span class="p">(</span><span class="n">microbatch_index</span><span class="p">)</span>

    <span class="n">outputs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span>
    <span class="n">outputs_grad</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">is_current_stage_last</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">loss</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Cannot perform backward on last stage without loss specified&quot;</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="n">loss</span><span class="p">}</span>
        <span class="n">outputs_grad</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">fwd_outputs</span>
        <span class="n">outputs_grad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comm</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">(</span><span class="n">microbatch_index</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">full_backward</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comp</span><span class="o">.</span><span class="n">backward_full</span><span class="p">(</span>
            <span class="n">microbatch_index</span><span class="o">=</span><span class="n">microbatch_index</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">outputs_grad</span><span class="o">=</span><span class="n">outputs_grad</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comp</span><span class="o">.</span><span class="n">backward_input</span><span class="p">(</span>
            <span class="n">microbatch_index</span><span class="o">=</span><span class="n">microbatch_index</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span> <span class="n">outputs_grad</span><span class="o">=</span><span class="n">outputs_grad</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">is_current_stage_last</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">is_current_stage_first</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">fwd_outputs</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">t</span><span class="o">.</span><span class="n">_is_view</span><span class="p">():</span>  <span class="c1"># noqa: SLF001</span>
                <span class="n">t</span><span class="o">.</span><span class="n">detach_</span><span class="p">()</span>
</code></pre></div></td></tr></table></div></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="d9d.pipelining.infra.stage.PipelineStage.backward_weight_one_chunk" class="doc doc-heading">
            <code class=" language-python"><span class="n">backward_weight_one_chunk</span><span class="p">(</span><span class="n">microbatch_index</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Executes the weight gradient accumulation part of the backward pass.</p>
<p>This assumes <code>backward_one_chunk(..., full_backward=False)</code> was already called
for this microbatch.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <div class="table-wrapper"><table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>microbatch_index</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The microbatch index.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>d9d/pipelining/infra/stage/stage.py</code></summary>
              <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">backward_weight_one_chunk</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Executes the weight gradient accumulation part of the backward pass.</span>

<span class="sd">    This assumes `backward_one_chunk(..., full_backward=False)` was already called</span>
<span class="sd">    for this microbatch.</span>

<span class="sd">    Args:</span>
<span class="sd">        microbatch_index: The microbatch index.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comp</span><span class="o">.</span><span class="n">backward_weight</span><span class="p">(</span><span class="n">microbatch_index</span><span class="o">=</span><span class="n">microbatch_index</span><span class="p">)</span>
</code></pre></div></td></tr></table></div></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="d9d.pipelining.infra.stage.PipelineStage.configure_buffers" class="doc doc-heading">
            <code class=" language-python"><span class="n">configure_buffers</span><span class="p">(</span><span class="n">num_microbatches</span><span class="p">,</span> <span class="n">has_backward</span><span class="p">,</span> <span class="n">pipeline_inputs</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Initializes the communication handlers and buffers for the stage.</p>
<p>This must be called before execution to establish P2P buffer sizes and directions.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <div class="table-wrapper"><table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>num_microbatches</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Total number of microbatches to process.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>has_backward</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Does this pipeline stage should store info for a backward pass</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pipeline_inputs</code>
            </td>
            <td>
                  <code><span title="dict">dict</span>[<span title="str">str</span>, <span title="torch.Tensor">Tensor</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Pipeline input data.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>d9d/pipelining/infra/stage/stage.py</code></summary>
              <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">configure_buffers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_microbatches</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">has_backward</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">pipeline_inputs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initializes the communication handlers and buffers for the stage.</span>

<span class="sd">    This must be called before execution to establish P2P buffer sizes and directions.</span>

<span class="sd">    Args:</span>
<span class="sd">        num_microbatches: Total number of microbatches to process.</span>
<span class="sd">        has_backward: Does this pipeline stage should store info for a backward pass</span>
<span class="sd">        pipeline_inputs: Pipeline input data.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span> <span class="o">=</span> <span class="n">has_backward</span>

    <span class="n">prev_stage_idx</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">is_current_stage_first</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">current_stage</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">next_stage_idx</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">is_current_stage_last</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">current_stage</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;meta&quot;</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_module</span><span class="p">,</span> <span class="n">ModuleSupportsPipelining</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Module does not implement ModuleSupportsPipelining protocol&quot;</span><span class="p">)</span>
        <span class="n">inputs_meta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_module</span><span class="o">.</span><span class="n">infer_stage_inputs_from_pipeline_inputs</span><span class="p">(</span>
            <span class="n">inputs</span><span class="o">=</span><span class="n">pipeline_inputs</span><span class="p">,</span> <span class="n">n_microbatches</span><span class="o">=</span><span class="n">num_microbatches</span>
        <span class="p">)</span>
        <span class="n">outputs_meta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_module</span><span class="o">.</span><span class="n">infer_stage_outputs_from_pipeline_inputs</span><span class="p">(</span>
            <span class="n">inputs</span><span class="o">=</span><span class="n">pipeline_inputs</span><span class="p">,</span> <span class="n">n_microbatches</span><span class="o">=</span><span class="n">num_microbatches</span>
        <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_forward_comm</span> <span class="o">=</span> <span class="n">StageCommunicationHandler</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;fwd&quot;</span><span class="p">,</span>
        <span class="n">stage_index</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">current_stage</span><span class="p">,</span>
        <span class="n">num_microbatches</span><span class="o">=</span><span class="n">num_microbatches</span><span class="p">,</span>
        <span class="n">input_stage_index</span><span class="o">=</span><span class="n">prev_stage_idx</span><span class="p">,</span>
        <span class="n">input_args</span><span class="o">=</span><span class="n">inputs_meta</span><span class="p">,</span>
        <span class="n">output_stage_index</span><span class="o">=</span><span class="n">next_stage_idx</span><span class="p">,</span>
        <span class="n">output_args</span><span class="o">=</span><span class="n">outputs_meta</span><span class="p">,</span>
        <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_group</span><span class="p">,</span>
        <span class="n">stage_idx_to_host_rank</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_stage_to_host_topology</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_forward_comm</span><span class="o">.</span><span class="n">set_input_requires_grad_</span><span class="p">(</span><span class="n">requires_grad</span><span class="o">=</span><span class="n">has_backward</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">has_backward</span><span class="p">:</span>
        <span class="c1"># for grad - current stage receives OUTPUTS as inputs and sends INPUTS as outputs</span>
        <span class="c1"># because it is reversed forward</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comm</span> <span class="o">=</span> <span class="n">StageCommunicationHandler</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;bwd&quot;</span><span class="p">,</span>
            <span class="n">stage_index</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">current_stage</span><span class="p">,</span>
            <span class="n">num_microbatches</span><span class="o">=</span><span class="n">num_microbatches</span><span class="p">,</span>
            <span class="n">input_stage_index</span><span class="o">=</span><span class="n">next_stage_idx</span><span class="p">,</span>
            <span class="n">input_args</span><span class="o">=</span><span class="n">outputs_meta</span><span class="p">,</span>
            <span class="n">output_stage_index</span><span class="o">=</span><span class="n">prev_stage_idx</span><span class="p">,</span>
            <span class="n">output_args</span><span class="o">=</span><span class="n">inputs_meta</span><span class="p">,</span>
            <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_group</span><span class="p">,</span>
            <span class="n">stage_idx_to_host_rank</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_stage_to_host_topology</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comm</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="d9d.pipelining.infra.stage.PipelineStage.forward_one_chunk" class="doc doc-heading">
            <code class=" language-python"><span class="n">forward_one_chunk</span><span class="p">(</span><span class="n">microbatch_index</span><span class="p">,</span> <span class="n">pipeline_inputs</span><span class="p">,</span> <span class="n">pipeline_kwargs</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Executes a forward pass for a single microbatch chunk.</p>
<p>Fetches inputs from the communication buffer (or <code>pipeline_inputs</code> if first stage),
runs the computation, and caches the result.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <div class="table-wrapper"><table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>microbatch_index</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The microbatch index.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pipeline_inputs</code>
            </td>
            <td>
                  <code><span title="dict">dict</span>[<span title="str">str</span>, <span title="torch.Tensor">Tensor</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Inputs provided locally (only used if this is the first stage).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pipeline_kwargs</code>
            </td>
            <td>
                  <code><span title="dict">dict</span>[<span title="str">str</span>, <span title="typing.Any">Any</span>] | None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Additional arguments for the module.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table></div>


    <p><span class="doc-section-title">Returns:</span></p>
    <div class="table-wrapper"><table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The output tensors of the forward pass.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>d9d/pipelining/infra/stage/stage.py</code></summary>
              <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">forward_one_chunk</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">microbatch_index</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">pipeline_inputs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
    <span class="n">pipeline_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Executes a forward pass for a single microbatch chunk.</span>

<span class="sd">    Fetches inputs from the communication buffer (or `pipeline_inputs` if first stage),</span>
<span class="sd">    runs the computation, and caches the result.</span>

<span class="sd">    Args:</span>
<span class="sd">        microbatch_index: The microbatch index.</span>
<span class="sd">        pipeline_inputs: Inputs provided locally (only used if this is the first stage).</span>
<span class="sd">        pipeline_kwargs: Additional arguments for the module.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The output tensors of the forward pass.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_comm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You must configure stage buffers first&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info</span><span class="o">.</span><span class="n">is_current_stage_first</span><span class="p">:</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">pipeline_inputs</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_comm</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">(</span><span class="n">microbatch_index</span><span class="p">)</span>

    <span class="n">kwargs</span> <span class="o">=</span> <span class="n">pipeline_kwargs</span> <span class="ow">or</span> <span class="p">{}</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_forward_comp</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">microbatch_index</span><span class="o">=</span><span class="n">microbatch_index</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">kwargs</span><span class="o">=</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div></td></tr></table></div></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="d9d.pipelining.infra.stage.PipelineStage.get_bwd_recv_ops" class="doc doc-heading">
            <code class=" language-python"><span class="n">get_bwd_recv_ops</span><span class="p">(</span><span class="n">microbatch_index</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Returns P2P ops to receive backward gradients for the given microbatch.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>d9d/pipelining/infra/stage/stage.py</code></summary>
              <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">get_bwd_recv_ops</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">dist</span><span class="o">.</span><span class="n">P2POp</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns P2P ops to receive backward gradients for the given microbatch.&quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[]</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You must configure stage buffers first&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comm</span><span class="o">.</span><span class="n">create_receive_ops</span><span class="p">(</span><span class="n">microbatch_index</span><span class="p">)</span>
</code></pre></div></td></tr></table></div></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="d9d.pipelining.infra.stage.PipelineStage.get_bwd_send_ops" class="doc doc-heading">
            <code class=" language-python"><span class="n">get_bwd_send_ops</span><span class="p">(</span><span class="n">microbatch_index</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Returns P2P ops to send backward gradients for the given microbatch.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>d9d/pipelining/infra/stage/stage.py</code></summary>
              <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">get_bwd_send_ops</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">dist</span><span class="o">.</span><span class="n">P2POp</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns P2P ops to send backward gradients for the given microbatch.&quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[]</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You must configure stage buffers first&quot;</span><span class="p">)</span>

    <span class="n">bwd_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comp</span><span class="o">.</span><span class="n">pop_for_sending</span><span class="p">(</span><span class="n">microbatch_index</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comm</span><span class="o">.</span><span class="n">create_send_ops</span><span class="p">(</span><span class="n">bwd_result</span><span class="p">)</span>
</code></pre></div></td></tr></table></div></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="d9d.pipelining.infra.stage.PipelineStage.get_fwd_recv_ops" class="doc doc-heading">
            <code class=" language-python"><span class="n">get_fwd_recv_ops</span><span class="p">(</span><span class="n">microbatch_index</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Returns P2P ops to receive forward inputs for the given microbatch.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>d9d/pipelining/infra/stage/stage.py</code></summary>
              <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">get_fwd_recv_ops</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">dist</span><span class="o">.</span><span class="n">P2POp</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns P2P ops to receive forward inputs for the given microbatch.&quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_comm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You must configure stage buffers first&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_comm</span><span class="o">.</span><span class="n">create_receive_ops</span><span class="p">(</span><span class="n">microbatch_index</span><span class="p">)</span>
</code></pre></div></td></tr></table></div></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="d9d.pipelining.infra.stage.PipelineStage.get_fwd_send_ops" class="doc doc-heading">
            <code class=" language-python"><span class="n">get_fwd_send_ops</span><span class="p">(</span><span class="n">microbatch_index</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Returns P2P ops to send forward outputs for the given microbatch.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>d9d/pipelining/infra/stage/stage.py</code></summary>
              <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">get_fwd_send_ops</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">dist</span><span class="o">.</span><span class="n">P2POp</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns P2P ops to send forward outputs for the given microbatch.&quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_comm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You must configure stage buffers first&quot;</span><span class="p">)</span>

    <span class="n">fwd_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_comp</span><span class="o">.</span><span class="n">get_outputs</span><span class="p">(</span><span class="n">microbatch_index</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_comm</span><span class="o">.</span><span class="n">create_send_ops</span><span class="p">(</span><span class="n">fwd_result</span><span class="p">)</span>
</code></pre></div></td></tr></table></div></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="d9d.pipelining.infra.stage.PipelineStage.pop_local_bwd_output" class="doc doc-heading">
            <code class=" language-python"><span class="n">pop_local_bwd_output</span><span class="p">(</span><span class="n">microbatch_index</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Retrieves local backward outputs (gradients).</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>d9d/pipelining/infra/stage/stage.py</code></summary>
              <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">pop_local_bwd_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Retrieves local backward outputs (gradients).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">()</span>

    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comp</span><span class="o">.</span><span class="n">pop_for_sending</span><span class="p">(</span><span class="n">microbatch_index</span><span class="p">)</span>
</code></pre></div></td></tr></table></div></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="d9d.pipelining.infra.stage.PipelineStage.reset" class="doc doc-heading">
            <code class=" language-python"><span class="n">reset</span><span class="p">()</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Resets the internal state of communication handlers, clearing gradients on buffers.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>d9d/pipelining/infra/stage/stage.py</code></summary>
              <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Resets the internal state of communication handlers, clearing gradients on buffers.&quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_forward_comm</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comm</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
</code></pre></div></td></tr></table></div></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="d9d.pipelining.infra.stage.PipelineStage.set_local_bwd_input" class="doc doc-heading">
            <code class=" language-python"><span class="n">set_local_bwd_input</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Sets local backward inputs (output gradients) manually.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>d9d/pipelining/infra/stage/stage.py</code></summary>
              <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">set_local_bwd_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">microbatch_index</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sets local backward inputs (output gradients) manually.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">()</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You must configure stage buffers first&quot;</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_backward_comm</span><span class="o">.</span><span class="n">set_inputs_local</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="p">)</span>
</code></pre></div></td></tr></table></div></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="d9d.pipelining.infra.stage.PipelineStage.set_local_fwd_input" class="doc doc-heading">
            <code class=" language-python"><span class="n">set_local_fwd_input</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Sets local forward inputs manually.</p>
<p>Used for the V-shape schedulers.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>d9d/pipelining/infra/stage/stage.py</code></summary>
              <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">set_local_fwd_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">microbatch_index</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sets local forward inputs manually.</span>

<span class="sd">    Used for the V-shape schedulers.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_comm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;You must configure stage buffers first&quot;</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_forward_comm</span><span class="o">.</span><span class="n">set_inputs_local</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="p">)</span>
</code></pre></div></td></tr></table></div></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="d9d.pipelining.infra.schedule.component.runtime" class="doc doc-heading">
            <code>d9d.pipelining.infra.schedule.component.runtime</code>


</h2>

    <div class="doc doc-contents first">

        <p>Pipelining Runtime Package.</p>










<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="d9d.pipelining.infra.schedule.component.runtime.ActionBase" class="doc doc-heading">
            <code>ActionBase</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="abc.ABC">ABC</span></code></p>



        <p>Abstract base class for all pipeline schedule actions.</p>
<p>An action represents an atomic unit of work in a pipeline schedule,
such as computing a microbatch or sending/receiving a tensor.</p>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>d9d/pipelining/infra/schedule/component/runtime/action.py</code></summary>
                <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">ActionBase</span><span class="p">(</span><span class="n">abc</span><span class="o">.</span><span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Abstract base class for all pipeline schedule actions.</span>

<span class="sd">    An action represents an atomic unit of work in a pipeline schedule,</span>
<span class="sd">    such as computing a microbatch or sending/receiving a tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ctx</span><span class="p">:</span> <span class="n">ActionContext</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Executes the action logic using the provided context.</span>

<span class="sd">        Args:</span>
<span class="sd">            ctx: The runtime context containing stages, data, and communication handlers.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="o">...</span>

    <span class="nd">@property</span>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">work_type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ActionWorkType</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the classification of work this action performs.&quot;&quot;&quot;</span>
        <span class="o">...</span>

    <span class="nd">@property</span>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">has_backward_work</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns True if this action involves backward pass computations.&quot;&quot;&quot;</span>
        <span class="o">...</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns a short string representation of the action for logging/visualization.&quot;&quot;&quot;</span>
        <span class="o">...</span>
</code></pre></div></td></tr></table></div></div>
              </details>



<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="d9d.pipelining.infra.schedule.component.runtime.ActionBase.has_backward_work" class="doc doc-heading">
            <code class=" language-python"><span class="n">has_backward_work</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Returns True if this action involves backward pass computations.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="d9d.pipelining.infra.schedule.component.runtime.ActionBase.work_type" class="doc doc-heading">
            <code class=" language-python"><span class="n">work_type</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Returns the classification of work this action performs.</p>

    </div>

</div>




<div class="doc doc-object doc-function">


<h4 id="d9d.pipelining.infra.schedule.component.runtime.ActionBase.__str__" class="doc doc-heading">
            <code class=" language-python"><span class="fm">__str__</span><span class="p">()</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Returns a short string representation of the action for logging/visualization.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>d9d/pipelining/infra/schedule/component/runtime/action.py</code></summary>
              <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
<span class="k">def</span><span class="w"> </span><span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns a short string representation of the action for logging/visualization.&quot;&quot;&quot;</span>
    <span class="o">...</span>
</code></pre></div></td></tr></table></div></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="d9d.pipelining.infra.schedule.component.runtime.ActionBase.apply" class="doc doc-heading">
            <code class=" language-python"><span class="n">apply</span><span class="p">(</span><span class="n">ctx</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Executes the action logic using the provided context.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <div class="table-wrapper"><table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>ctx</code>
            </td>
            <td>
                  <code><span title="d9d.pipelining.infra.schedule.component.runtime.action.ActionContext">ActionContext</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The runtime context containing stages, data, and communication handlers.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>d9d/pipelining/infra/schedule/component/runtime/action.py</code></summary>
              <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ctx</span><span class="p">:</span> <span class="n">ActionContext</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Executes the action logic using the provided context.</span>

<span class="sd">    Args:</span>
<span class="sd">        ctx: The runtime context containing stages, data, and communication handlers.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="o">...</span>
</code></pre></div></td></tr></table></div></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="d9d.pipelining.infra.schedule.component.runtime.BackwardFullInputComputeAction" class="doc doc-heading">
            <code>BackwardFullInputComputeAction</code>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-dataclass"><code>dataclass</code></small>
  </span>

</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="ActionBase (d9d.pipelining.infra.schedule.component.runtime.action.ActionBase)" href="#d9d.pipelining.infra.schedule.component.runtime.ActionBase">ActionBase</a></code></p>



        <p>Action to perform backward computation with respect to inputs.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <div class="table-wrapper"><table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="d9d.pipelining.infra.schedule.component.runtime.BackwardFullInputComputeAction.stage_idx">stage_idx</span></code></td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The integer index of the pipeline stage.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="d9d.pipelining.infra.schedule.component.runtime.BackwardFullInputComputeAction.microbatch_idx">microbatch_idx</span></code></td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The integer index of the microbatch to compute.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="d9d.pipelining.infra.schedule.component.runtime.BackwardFullInputComputeAction.full_backward">full_backward</span></code></td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, performs a full backward pass including inputs
and weights. If False, may only compute gradients w.r.t inputs
(depending on schedule implementation).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table></div>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>d9d/pipelining/infra/schedule/component/runtime/action.py</code></summary>
                <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@dataclasses</span><span class="o">.</span><span class="n">dataclass</span><span class="p">(</span><span class="n">frozen</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">slots</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">BackwardFullInputComputeAction</span><span class="p">(</span><span class="n">ActionBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Action to perform backward computation with respect to inputs.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        stage_idx: The integer index of the pipeline stage.</span>
<span class="sd">        microbatch_idx: The integer index of the microbatch to compute.</span>
<span class="sd">        full_backward: If True, performs a full backward pass including inputs</span>
<span class="sd">            and weights. If False, may only compute gradients w.r.t inputs</span>
<span class="sd">            (depending on schedule implementation).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">stage_idx</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">microbatch_idx</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">full_backward</span><span class="p">:</span> <span class="nb">bool</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ctx</span><span class="p">:</span> <span class="n">ActionContext</span><span class="p">):</span>
        <span class="n">stage</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">stages</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">stage_idx</span><span class="p">]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">stage</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">is_current_stage_last</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">stage_idx</span> <span class="o">+</span> <span class="mi">1</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ctx</span><span class="o">.</span><span class="n">stages</span><span class="p">:</span>
            <span class="n">ctx</span><span class="o">.</span><span class="n">communications</span><span class="o">.</span><span class="n">wait_bwd_recv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stage_idx</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">microbatch_idx</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">stage</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">is_current_stage_last</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ctx</span><span class="o">.</span><span class="n">callback</span><span class="p">,</span> <span class="n">PipelineLossHandler</span><span class="p">):</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">acquire_loss</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">microbatch_idx</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">stage</span><span class="o">.</span><span class="n">backward_one_chunk</span><span class="p">(</span><span class="n">microbatch_index</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">microbatch_idx</span><span class="p">,</span> <span class="n">full_backward</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">full_backward</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">stage</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">is_current_stage_first</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">stage_idx</span> <span class="o">-</span> <span class="mi">1</span> <span class="ow">in</span> <span class="n">ctx</span><span class="o">.</span><span class="n">stages</span><span class="p">:</span>
            <span class="n">ctx</span><span class="o">.</span><span class="n">stages</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">stage_idx</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_local_bwd_input</span><span class="p">(</span>
                <span class="n">microbatch_index</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">microbatch_idx</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">stage</span><span class="o">.</span><span class="n">pop_local_bwd_output</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">microbatch_idx</span><span class="p">)</span>
            <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">work_type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ActionWorkType</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ActionWorkType</span><span class="o">.</span><span class="n">compute</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">has_backward_work</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="n">letter</span> <span class="o">=</span> <span class="s2">&quot;B&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">full_backward</span> <span class="k">else</span> <span class="s2">&quot;I&quot;</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">stage_idx</span><span class="si">}{</span><span class="n">letter</span><span class="si">}{</span><span class="bp">self</span><span class="o">.</span><span class="n">microbatch_idx</span><span class="si">}</span><span class="s2">&quot;</span>
</code></pre></div></td></tr></table></div></div>
              </details>



<div class="doc doc-children">












  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="d9d.pipelining.infra.schedule.component.runtime.BackwardReceiveAction" class="doc doc-heading">
            <code>BackwardReceiveAction</code>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-dataclass"><code>dataclass</code></small>
  </span>

</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="ActionBase (d9d.pipelining.infra.schedule.component.runtime.action.ActionBase)" href="#d9d.pipelining.infra.schedule.component.runtime.ActionBase">ActionBase</a></code></p>



        <p>Action to schedule a backward pass gradient receive operation.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <div class="table-wrapper"><table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="d9d.pipelining.infra.schedule.component.runtime.BackwardReceiveAction.stage_idx">stage_idx</span></code></td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The integer index of the pipeline stage expecting the receive operation.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="d9d.pipelining.infra.schedule.component.runtime.BackwardReceiveAction.microbatch_idx">microbatch_idx</span></code></td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The integer index of the microbatch being received.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table></div>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>d9d/pipelining/infra/schedule/component/runtime/action.py</code></summary>
                <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@dataclasses</span><span class="o">.</span><span class="n">dataclass</span><span class="p">(</span><span class="n">frozen</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">slots</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">BackwardReceiveAction</span><span class="p">(</span><span class="n">ActionBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Action to schedule a backward pass gradient receive operation.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        stage_idx: The integer index of the pipeline stage expecting the receive operation.</span>
<span class="sd">        microbatch_idx: The integer index of the microbatch being received.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">stage_idx</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">microbatch_idx</span><span class="p">:</span> <span class="nb">int</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ctx</span><span class="p">:</span> <span class="n">ActionContext</span><span class="p">):</span>
        <span class="n">ctx</span><span class="o">.</span><span class="n">communications</span><span class="o">.</span><span class="n">schedule_bwd_recv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stage_idx</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">microbatch_idx</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">work_type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ActionWorkType</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ActionWorkType</span><span class="o">.</span><span class="n">communicate</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">has_backward_work</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">stage_idx</span><span class="si">}</span><span class="s2">RECV_B</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">microbatch_idx</span><span class="si">}</span><span class="s2">&quot;</span>
</code></pre></div></td></tr></table></div></div>
              </details>



<div class="doc doc-children">












  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="d9d.pipelining.infra.schedule.component.runtime.BackwardSendAction" class="doc doc-heading">
            <code>BackwardSendAction</code>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-dataclass"><code>dataclass</code></small>
  </span>

</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="ActionBase (d9d.pipelining.infra.schedule.component.runtime.action.ActionBase)" href="#d9d.pipelining.infra.schedule.component.runtime.ActionBase">ActionBase</a></code></p>



        <p>Action to schedule a backward pass gradient send operation.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <div class="table-wrapper"><table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="d9d.pipelining.infra.schedule.component.runtime.BackwardSendAction.stage_idx">stage_idx</span></code></td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The integer index of the pipeline stage initiating the send operation.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="d9d.pipelining.infra.schedule.component.runtime.BackwardSendAction.microbatch_idx">microbatch_idx</span></code></td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The integer index of the microbatch being sent.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table></div>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>d9d/pipelining/infra/schedule/component/runtime/action.py</code></summary>
                <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@dataclasses</span><span class="o">.</span><span class="n">dataclass</span><span class="p">(</span><span class="n">frozen</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">slots</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">BackwardSendAction</span><span class="p">(</span><span class="n">ActionBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Action to schedule a backward pass gradient send operation.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        stage_idx: The integer index of the pipeline stage initiating the send operation.</span>
<span class="sd">        microbatch_idx: The integer index of the microbatch being sent.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">stage_idx</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">microbatch_idx</span><span class="p">:</span> <span class="nb">int</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ctx</span><span class="p">:</span> <span class="n">ActionContext</span><span class="p">):</span>
        <span class="n">ctx</span><span class="o">.</span><span class="n">communications</span><span class="o">.</span><span class="n">schedule_bwd_send</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stage_idx</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">microbatch_idx</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">work_type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ActionWorkType</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ActionWorkType</span><span class="o">.</span><span class="n">communicate</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">has_backward_work</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">stage_idx</span><span class="si">}</span><span class="s2">SEND_B</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">microbatch_idx</span><span class="si">}</span><span class="s2">&quot;</span>
</code></pre></div></td></tr></table></div></div>
              </details>



<div class="doc doc-children">












  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="d9d.pipelining.infra.schedule.component.runtime.BackwardWeightComputeAction" class="doc doc-heading">
            <code>BackwardWeightComputeAction</code>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-dataclass"><code>dataclass</code></small>
  </span>

</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="ActionBase (d9d.pipelining.infra.schedule.component.runtime.action.ActionBase)" href="#d9d.pipelining.infra.schedule.component.runtime.ActionBase">ActionBase</a></code></p>



        <p>Action to perform gradient accumulation on weights.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <div class="table-wrapper"><table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="d9d.pipelining.infra.schedule.component.runtime.BackwardWeightComputeAction.stage_idx">stage_idx</span></code></td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The integer index of the pipeline stage.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="d9d.pipelining.infra.schedule.component.runtime.BackwardWeightComputeAction.microbatch_idx">microbatch_idx</span></code></td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The integer index of the microbatch to compute.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table></div>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>d9d/pipelining/infra/schedule/component/runtime/action.py</code></summary>
                <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@dataclasses</span><span class="o">.</span><span class="n">dataclass</span><span class="p">(</span><span class="n">frozen</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">slots</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">BackwardWeightComputeAction</span><span class="p">(</span><span class="n">ActionBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Action to perform gradient accumulation on weights.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        stage_idx: The integer index of the pipeline stage.</span>
<span class="sd">        microbatch_idx: The integer index of the microbatch to compute.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">stage_idx</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">microbatch_idx</span><span class="p">:</span> <span class="nb">int</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ctx</span><span class="p">:</span> <span class="n">ActionContext</span><span class="p">):</span>
        <span class="n">stage</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">stages</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">stage_idx</span><span class="p">]</span>

        <span class="n">stage</span><span class="o">.</span><span class="n">backward_weight_one_chunk</span><span class="p">(</span><span class="n">microbatch_index</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">microbatch_idx</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">work_type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ActionWorkType</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ActionWorkType</span><span class="o">.</span><span class="n">compute</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">has_backward_work</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">stage_idx</span><span class="si">}</span><span class="s2">W</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">microbatch_idx</span><span class="si">}</span><span class="s2">&quot;</span>
</code></pre></div></td></tr></table></div></div>
              </details>



<div class="doc doc-children">












  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="d9d.pipelining.infra.schedule.component.runtime.ComposeAction" class="doc doc-heading">
            <code>ComposeAction</code>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-dataclass"><code>dataclass</code></small>
  </span>

</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="ActionBase (d9d.pipelining.infra.schedule.component.runtime.action.ActionBase)" href="#d9d.pipelining.infra.schedule.component.runtime.ActionBase">ActionBase</a></code></p>



        <p>Composite action scheduling multiple sub-actions sequentially.</p>
<p>Used for forward/backward overlapping.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <div class="table-wrapper"><table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="d9d.pipelining.infra.schedule.component.runtime.ComposeAction.actions">actions</span></code></td>
            <td>
                  <code><span title="tuple">tuple</span>[<a class="autorefs autorefs-internal" title="ActionBase (d9d.pipelining.infra.schedule.component.runtime.action.ActionBase)" href="#d9d.pipelining.infra.schedule.component.runtime.ActionBase">ActionBase</a>, ...]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A tuple of sub-actions to be executed sequentially.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table></div>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>d9d/pipelining/infra/schedule/component/runtime/action.py</code></summary>
                <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@dataclasses</span><span class="o">.</span><span class="n">dataclass</span><span class="p">(</span><span class="n">frozen</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">slots</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">ComposeAction</span><span class="p">(</span><span class="n">ActionBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Composite action scheduling multiple sub-actions sequentially.</span>

<span class="sd">    Used for forward/backward overlapping.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        actions: A tuple of sub-actions to be executed sequentially.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">actions</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">ActionBase</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ctx</span><span class="p">:</span> <span class="n">ActionContext</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">act</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">:</span>
            <span class="n">act</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">ctx</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">work_type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ActionWorkType</span><span class="p">:</span>
        <span class="n">sub_work_types</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span><span class="o">.</span><span class="n">work_type</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">}</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sub_work_types</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">sub_work_types</span><span class="p">))</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">has_backward_work</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">any</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">has_backward_work</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&quot;|&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">))</span>
</code></pre></div></td></tr></table></div></div>
              </details>



<div class="doc doc-children">












  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="d9d.pipelining.infra.schedule.component.runtime.ForwardComputeAction" class="doc doc-heading">
            <code>ForwardComputeAction</code>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-dataclass"><code>dataclass</code></small>
  </span>

</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="ActionBase (d9d.pipelining.infra.schedule.component.runtime.action.ActionBase)" href="#d9d.pipelining.infra.schedule.component.runtime.ActionBase">ActionBase</a></code></p>



        <p>Action to perform forward computation for a specific microbatch.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <div class="table-wrapper"><table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="d9d.pipelining.infra.schedule.component.runtime.ForwardComputeAction.stage_idx">stage_idx</span></code></td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The integer index of the pipeline stage.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="d9d.pipelining.infra.schedule.component.runtime.ForwardComputeAction.microbatch_idx">microbatch_idx</span></code></td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The integer index of the microbatch to compute.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table></div>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>d9d/pipelining/infra/schedule/component/runtime/action.py</code></summary>
                <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@dataclasses</span><span class="o">.</span><span class="n">dataclass</span><span class="p">(</span><span class="n">frozen</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">slots</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">ForwardComputeAction</span><span class="p">(</span><span class="n">ActionBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Action to perform forward computation for a specific microbatch.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        stage_idx: The integer index of the pipeline stage.</span>
<span class="sd">        microbatch_idx: The integer index of the microbatch to compute.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">stage_idx</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">microbatch_idx</span><span class="p">:</span> <span class="nb">int</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ctx</span><span class="p">:</span> <span class="n">ActionContext</span><span class="p">):</span>
        <span class="n">stage</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">stages</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">stage_idx</span><span class="p">]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">stage</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">is_current_stage_first</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">stage_idx</span> <span class="o">-</span> <span class="mi">1</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ctx</span><span class="o">.</span><span class="n">stages</span><span class="p">:</span>
            <span class="n">ctx</span><span class="o">.</span><span class="n">communications</span><span class="o">.</span><span class="n">wait_fwd_recv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stage_idx</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">microbatch_idx</span><span class="p">)</span>

        <span class="n">stage</span><span class="o">.</span><span class="n">forward_one_chunk</span><span class="p">(</span>
            <span class="n">microbatch_index</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">microbatch_idx</span><span class="p">,</span>
            <span class="n">pipeline_inputs</span><span class="o">=</span><span class="n">ctx</span><span class="o">.</span><span class="n">pipeline_inputs_microbatches</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">microbatch_idx</span><span class="p">],</span>
            <span class="n">pipeline_kwargs</span><span class="o">=</span><span class="n">ctx</span><span class="o">.</span><span class="n">pipeline_kwargs_microbatches</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">microbatch_idx</span><span class="p">],</span>
        <span class="p">)</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">stage</span><span class="o">.</span><span class="n">get_local_fwd_output</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">microbatch_idx</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">stage</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">is_current_stage_last</span><span class="p">:</span>
            <span class="n">ctx</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">trigger</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">microbatch_idx</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">stage</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">is_current_stage_last</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">stage_idx</span> <span class="o">+</span> <span class="mi">1</span> <span class="ow">in</span> <span class="n">ctx</span><span class="o">.</span><span class="n">stages</span><span class="p">:</span>
            <span class="n">ctx</span><span class="o">.</span><span class="n">stages</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">stage_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_local_fwd_input</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">result</span><span class="p">,</span> <span class="n">microbatch_index</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">microbatch_idx</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">work_type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ActionWorkType</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ActionWorkType</span><span class="o">.</span><span class="n">compute</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">has_backward_work</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">stage_idx</span><span class="si">}</span><span class="s2">F</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">microbatch_idx</span><span class="si">}</span><span class="s2">&quot;</span>
</code></pre></div></td></tr></table></div></div>
              </details>



<div class="doc doc-children">












  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="d9d.pipelining.infra.schedule.component.runtime.ForwardReceiveAction" class="doc doc-heading">
            <code>ForwardReceiveAction</code>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-dataclass"><code>dataclass</code></small>
  </span>

</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="ActionBase (d9d.pipelining.infra.schedule.component.runtime.action.ActionBase)" href="#d9d.pipelining.infra.schedule.component.runtime.ActionBase">ActionBase</a></code></p>



        <p>Action to schedule a forward pass tensor receive operation.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <div class="table-wrapper"><table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="d9d.pipelining.infra.schedule.component.runtime.ForwardReceiveAction.stage_idx">stage_idx</span></code></td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The integer index of the pipeline stage expecting the receive operation.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="d9d.pipelining.infra.schedule.component.runtime.ForwardReceiveAction.microbatch_idx">microbatch_idx</span></code></td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The integer index of the microbatch being received.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table></div>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>d9d/pipelining/infra/schedule/component/runtime/action.py</code></summary>
                <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@dataclasses</span><span class="o">.</span><span class="n">dataclass</span><span class="p">(</span><span class="n">frozen</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">slots</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">ForwardReceiveAction</span><span class="p">(</span><span class="n">ActionBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Action to schedule a forward pass tensor receive operation.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        stage_idx: The integer index of the pipeline stage expecting the receive operation.</span>
<span class="sd">        microbatch_idx: The integer index of the microbatch being received.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">stage_idx</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">microbatch_idx</span><span class="p">:</span> <span class="nb">int</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ctx</span><span class="p">:</span> <span class="n">ActionContext</span><span class="p">):</span>
        <span class="n">ctx</span><span class="o">.</span><span class="n">communications</span><span class="o">.</span><span class="n">schedule_fwd_recv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stage_idx</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">microbatch_idx</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">work_type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ActionWorkType</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ActionWorkType</span><span class="o">.</span><span class="n">communicate</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">has_backward_work</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">stage_idx</span><span class="si">}</span><span class="s2">RECV_F</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">microbatch_idx</span><span class="si">}</span><span class="s2">&quot;</span>
</code></pre></div></td></tr></table></div></div>
              </details>



<div class="doc doc-children">












  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="d9d.pipelining.infra.schedule.component.runtime.ForwardSendAction" class="doc doc-heading">
            <code>ForwardSendAction</code>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-dataclass"><code>dataclass</code></small>
  </span>

</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="ActionBase (d9d.pipelining.infra.schedule.component.runtime.action.ActionBase)" href="#d9d.pipelining.infra.schedule.component.runtime.ActionBase">ActionBase</a></code></p>



        <p>Action to schedule a forward pass tensor send operation.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <div class="table-wrapper"><table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="d9d.pipelining.infra.schedule.component.runtime.ForwardSendAction.stage_idx">stage_idx</span></code></td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The integer index of the pipeline stage initiating the send operation.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="d9d.pipelining.infra.schedule.component.runtime.ForwardSendAction.microbatch_idx">microbatch_idx</span></code></td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The integer index of the microbatch being sent.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table></div>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>d9d/pipelining/infra/schedule/component/runtime/action.py</code></summary>
                <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@dataclasses</span><span class="o">.</span><span class="n">dataclass</span><span class="p">(</span><span class="n">frozen</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">slots</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">ForwardSendAction</span><span class="p">(</span><span class="n">ActionBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Action to schedule a forward pass tensor send operation.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        stage_idx: The integer index of the pipeline stage initiating the send operation.</span>
<span class="sd">        microbatch_idx: The integer index of the microbatch being sent.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">stage_idx</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">microbatch_idx</span><span class="p">:</span> <span class="nb">int</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ctx</span><span class="p">:</span> <span class="n">ActionContext</span><span class="p">):</span>
        <span class="n">ctx</span><span class="o">.</span><span class="n">communications</span><span class="o">.</span><span class="n">schedule_fwd_send</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stage_idx</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">microbatch_idx</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">work_type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ActionWorkType</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ActionWorkType</span><span class="o">.</span><span class="n">communicate</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">has_backward_work</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">stage_idx</span><span class="si">}</span><span class="s2">SEND_F</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">microbatch_idx</span><span class="si">}</span><span class="s2">&quot;</span>
</code></pre></div></td></tr></table></div></div>
              </details>



<div class="doc doc-children">












  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="d9d.pipelining.infra.schedule.component.runtime.OfflinePipelineExecutor" class="doc doc-heading">
            <code>OfflinePipelineExecutor</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="PipelineSchedule (d9d.pipelining.api.PipelineSchedule)" href="../../models/3_pipeline_parallelism/#d9d.pipelining.api.PipelineSchedule">PipelineSchedule</a></code></p>



        <p>Executes the model immediately without pipeline parallelism.</p>
<p>This schedule treats the execution as a single stage with a single microbatch,
running the forward and optionally backward pass directly. This is primarily
used for single-device execution within the pipeline abstraction.</p>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>d9d/pipelining/infra/schedule/component/runtime/offline.py</code></summary>
                <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">OfflinePipelineExecutor</span><span class="p">(</span><span class="n">PipelineSchedule</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Executes the model immediately without pipeline parallelism.</span>

<span class="sd">    This schedule treats the execution as a single stage with a single microbatch,</span>
<span class="sd">    running the forward and optionally backward pass directly. This is primarily</span>
<span class="sd">    used for single-device execution within the pipeline abstraction.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">callback</span><span class="p">:</span> <span class="n">PipelineLossFn</span> <span class="o">|</span> <span class="n">PipelineResultFn</span><span class="p">,</span> <span class="n">do_backward</span><span class="p">:</span> <span class="nb">bool</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Constructs the offline pipeline executor.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: The PyTorch module to execute.</span>
<span class="sd">            callback: Function to compute loss or process pipeline results.</span>
<span class="sd">            do_backward: Whether to execute the backward pass.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_callback</span> <span class="o">=</span> <span class="n">callback</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_do_backward</span> <span class="o">=</span> <span class="n">do_backward</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">configure_buffers</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">sharding_spec</span><span class="p">:</span> <span class="n">PipelineShardingSpec</span> <span class="o">|</span> <span class="kc">None</span>
    <span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_forward_only</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_callback</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># microbatch=0</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_forward_backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_callback</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># microbatch=0</span>
        <span class="k">del</span> <span class="n">result</span>  <span class="c1"># do not peak memory</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">processing_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_callback</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_do_backward</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">processing_result</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Loss should be torch.Tensor&quot;</span><span class="p">)</span>
            <span class="k">del</span> <span class="n">result</span>  <span class="c1"># do not peak memory</span>
            <span class="n">processing_result</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</code></pre></div></td></tr></table></div></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="d9d.pipelining.infra.schedule.component.runtime.OfflinePipelineExecutor.__init__" class="doc doc-heading">
            <code class=" language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">callback</span><span class="p">,</span> <span class="n">do_backward</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Constructs the offline pipeline executor.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <div class="table-wrapper"><table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>model</code>
            </td>
            <td>
                  <code><span title="torch.nn.Module">Module</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The PyTorch module to execute.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>callback</code>
            </td>
            <td>
                  <code><a class="autorefs autorefs-internal" title="PipelineLossFn = Callable[[dict[str, torch.Tensor], int], torch.Tensor]

  
      module-attribute
   (d9d.pipelining.api.PipelineLossFn)" href="../../models/3_pipeline_parallelism/#d9d.pipelining.api.PipelineLossFn">PipelineLossFn</a> | <a class="autorefs autorefs-internal" title="PipelineResultFn = Callable[[dict[str, torch.Tensor], int], Any]

  
      module-attribute
   (d9d.pipelining.api.PipelineResultFn)" href="../../models/3_pipeline_parallelism/#d9d.pipelining.api.PipelineResultFn">PipelineResultFn</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Function to compute loss or process pipeline results.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>do_backward</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to execute the backward pass.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>d9d/pipelining/infra/schedule/component/runtime/offline.py</code></summary>
              <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">callback</span><span class="p">:</span> <span class="n">PipelineLossFn</span> <span class="o">|</span> <span class="n">PipelineResultFn</span><span class="p">,</span> <span class="n">do_backward</span><span class="p">:</span> <span class="nb">bool</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Constructs the offline pipeline executor.</span>

<span class="sd">    Args:</span>
<span class="sd">        model: The PyTorch module to execute.</span>
<span class="sd">        callback: Function to compute loss or process pipeline results.</span>
<span class="sd">        do_backward: Whether to execute the backward pass.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_model</span> <span class="o">=</span> <span class="n">model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_callback</span> <span class="o">=</span> <span class="n">callback</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_do_backward</span> <span class="o">=</span> <span class="n">do_backward</span>
</code></pre></div></td></tr></table></div></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="d9d.pipelining.infra.schedule.component.runtime.PipelineScheduleExecutor" class="doc doc-heading">
            <code>PipelineScheduleExecutor</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="PipelineSchedule (d9d.pipelining.api.PipelineSchedule)" href="../../models/3_pipeline_parallelism/#d9d.pipelining.api.PipelineSchedule">PipelineSchedule</a></code></p>



        <p>Executes a defined pipeline schedule by interpreting a sequence of actions.</p>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>d9d/pipelining/infra/schedule/component/runtime/executor.py</code></summary>
                <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">PipelineScheduleExecutor</span><span class="p">(</span><span class="n">PipelineSchedule</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Executes a defined pipeline schedule by interpreting a sequence of actions.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dist_context</span><span class="p">:</span> <span class="n">DistributedContext</span><span class="p">,</span>
        <span class="n">stages</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">PipelineStage</span><span class="p">],</span>
        <span class="n">num_microbatches</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">callback</span><span class="p">:</span> <span class="n">PipelineLossFn</span> <span class="o">|</span> <span class="n">PipelineResultFn</span><span class="p">,</span>
        <span class="n">program</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">ActionBase</span><span class="p">]],</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Constructs the schedule executor.</span>

<span class="sd">        Args:</span>
<span class="sd">            dist_context: The distributed context.</span>
<span class="sd">            stages: List of stages managed by this executor.</span>
<span class="sd">            num_microbatches: Number of microbatches the global batch is split.</span>
<span class="sd">            callback: Function to compute loss or process pipeline results.</span>
<span class="sd">            program: The execution plan mapping rank ID to a list of actions.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_dist_ctx</span> <span class="o">=</span> <span class="n">dist_context</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stages</span> <span class="o">=</span> <span class="p">{</span><span class="n">stage</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">current_stage</span><span class="p">:</span> <span class="n">stage</span> <span class="k">for</span> <span class="n">stage</span> <span class="ow">in</span> <span class="n">stages</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_num_microbatches</span> <span class="o">=</span> <span class="n">num_microbatches</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_program</span> <span class="o">=</span> <span class="n">program</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span>
            <span class="nb">any</span><span class="p">(</span><span class="n">action</span><span class="o">.</span><span class="n">has_backward_work</span> <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">sub_program</span><span class="p">)</span> <span class="k">for</span> <span class="n">sub_program</span> <span class="ow">in</span> <span class="n">program</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_comm_handler</span> <span class="o">=</span> <span class="n">PipelineCommunicationHandler</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stages</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_callback</span><span class="p">:</span> <span class="n">PipelineLossHandler</span> <span class="o">|</span> <span class="n">PipelineResultHandler</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_callback</span> <span class="o">=</span> <span class="n">PipelineLossHandler</span><span class="p">(</span><span class="n">callback</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_callback</span> <span class="o">=</span> <span class="n">PipelineResultHandler</span><span class="p">(</span><span class="n">callback</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_input_data_sharding_spec</span><span class="p">:</span> <span class="n">ShardingSpec</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs_sharding_spec</span><span class="p">:</span> <span class="n">ShardingSpec</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">configure_buffers</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">sharding_spec</span><span class="p">:</span> <span class="n">PipelineShardingSpec</span> <span class="o">|</span> <span class="kc">None</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">sharding_spec</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">sharding_spec</span><span class="o">.</span><span class="n">input_data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_input_data_sharding_spec</span> <span class="o">=</span> <span class="n">shard_spec_on_dim</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">sharding_spec</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">sharding_spec</span><span class="o">.</span><span class="n">input_kwargs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs_sharding_spec</span> <span class="o">=</span> <span class="n">shard_spec_on_dim</span><span class="p">(</span><span class="n">kwargs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">stage</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stages</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="n">stage</span><span class="o">.</span><span class="n">configure_buffers</span><span class="p">(</span>
                <span class="n">num_microbatches</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_microbatches</span><span class="p">,</span> <span class="n">pipeline_inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">has_backward</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span>
            <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_data_sharding_spec</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs_sharding_spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Please configure sharding specs first&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_dist_ctx</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Begin pipeline step&quot;</span><span class="p">)</span>
        <span class="n">pp_group</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dist_ctx</span><span class="o">.</span><span class="n">mesh_for</span><span class="p">(</span><span class="n">REGULAR_DOMAIN</span><span class="p">)</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="s2">&quot;pp&quot;</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">stage</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stages</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="n">stage</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

        <span class="c1"># Shard inputs and kwargs to microbatches</span>
        <span class="n">inputs_shard</span> <span class="o">=</span> <span class="n">shard_tree</span><span class="p">(</span>
            <span class="n">inputs</span><span class="p">,</span>
            <span class="n">num_shards</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_microbatches</span><span class="p">,</span>
            <span class="n">sharding_spec</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_input_data_sharding_spec</span><span class="p">,</span>
            <span class="n">enforce_even_split</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">kwargs_shard</span> <span class="o">=</span> <span class="n">shard_tree</span><span class="p">(</span>
            <span class="n">kwargs</span><span class="p">,</span>
            <span class="n">num_shards</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_microbatches</span><span class="p">,</span>
            <span class="n">sharding_spec</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs_sharding_spec</span><span class="p">,</span>
            <span class="n">enforce_even_split</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">my_program</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_program</span><span class="p">[</span><span class="n">pp_group</span><span class="o">.</span><span class="n">rank</span><span class="p">()]</span>

        <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">my_program</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">record_function</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">action</span><span class="p">)):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_dist_ctx</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Running pipeline action </span><span class="si">{</span><span class="n">action</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">action</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
                    <span class="n">ActionContext</span><span class="p">(</span>
                        <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_callback</span><span class="p">,</span>
                        <span class="n">stages</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_stages</span><span class="p">,</span>
                        <span class="n">communications</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_comm_handler</span><span class="p">,</span>
                        <span class="n">pipeline_inputs_microbatches</span><span class="o">=</span><span class="n">inputs_shard</span><span class="p">,</span>
                        <span class="n">pipeline_kwargs_microbatches</span><span class="o">=</span><span class="n">kwargs_shard</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_dist_ctx</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Waiting for potentially hanging PP send comms&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_comm_handler</span><span class="o">.</span><span class="n">wait_send_all</span><span class="p">()</span>  <span class="c1"># finalize just in case</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dist_ctx</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;End pipeline step&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="d9d.pipelining.infra.schedule.component.runtime.PipelineScheduleExecutor.__init__" class="doc doc-heading">
            <code class=" language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">dist_context</span><span class="p">,</span> <span class="n">stages</span><span class="p">,</span> <span class="n">num_microbatches</span><span class="p">,</span> <span class="n">callback</span><span class="p">,</span> <span class="n">program</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Constructs the schedule executor.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <div class="table-wrapper"><table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>dist_context</code>
            </td>
            <td>
                  <code><a class="autorefs autorefs-internal" title="DistributedContext (d9d.core.dist_context.DistributedContext)" href="../../core/dist_context/#d9d.core.dist_context.DistributedContext">DistributedContext</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The distributed context.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>stages</code>
            </td>
            <td>
                  <code><span title="list">list</span>[<a class="autorefs autorefs-internal" title="PipelineStage (d9d.pipelining.infra.stage.PipelineStage)" href="#d9d.pipelining.infra.stage.PipelineStage">PipelineStage</a>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List of stages managed by this executor.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_microbatches</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of microbatches the global batch is split.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>callback</code>
            </td>
            <td>
                  <code><a class="autorefs autorefs-internal" title="PipelineLossFn = Callable[[dict[str, torch.Tensor], int], torch.Tensor]

  
      module-attribute
   (d9d.pipelining.api.PipelineLossFn)" href="../../models/3_pipeline_parallelism/#d9d.pipelining.api.PipelineLossFn">PipelineLossFn</a> | <a class="autorefs autorefs-internal" title="PipelineResultFn = Callable[[dict[str, torch.Tensor], int], Any]

  
      module-attribute
   (d9d.pipelining.api.PipelineResultFn)" href="../../models/3_pipeline_parallelism/#d9d.pipelining.api.PipelineResultFn">PipelineResultFn</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Function to compute loss or process pipeline results.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>program</code>
            </td>
            <td>
                  <code><span title="dict">dict</span>[<span title="int">int</span>, <span title="list">list</span>[<a class="autorefs autorefs-internal" title="ActionBase (d9d.pipelining.infra.schedule.component.runtime.action.ActionBase)" href="#d9d.pipelining.infra.schedule.component.runtime.ActionBase">ActionBase</a>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The execution plan mapping rank ID to a list of actions.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>d9d/pipelining/infra/schedule/component/runtime/executor.py</code></summary>
              <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">dist_context</span><span class="p">:</span> <span class="n">DistributedContext</span><span class="p">,</span>
    <span class="n">stages</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">PipelineStage</span><span class="p">],</span>
    <span class="n">num_microbatches</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">callback</span><span class="p">:</span> <span class="n">PipelineLossFn</span> <span class="o">|</span> <span class="n">PipelineResultFn</span><span class="p">,</span>
    <span class="n">program</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">ActionBase</span><span class="p">]],</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Constructs the schedule executor.</span>

<span class="sd">    Args:</span>
<span class="sd">        dist_context: The distributed context.</span>
<span class="sd">        stages: List of stages managed by this executor.</span>
<span class="sd">        num_microbatches: Number of microbatches the global batch is split.</span>
<span class="sd">        callback: Function to compute loss or process pipeline results.</span>
<span class="sd">        program: The execution plan mapping rank ID to a list of actions.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_dist_ctx</span> <span class="o">=</span> <span class="n">dist_context</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_stages</span> <span class="o">=</span> <span class="p">{</span><span class="n">stage</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">current_stage</span><span class="p">:</span> <span class="n">stage</span> <span class="k">for</span> <span class="n">stage</span> <span class="ow">in</span> <span class="n">stages</span><span class="p">}</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_num_microbatches</span> <span class="o">=</span> <span class="n">num_microbatches</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_program</span> <span class="o">=</span> <span class="n">program</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span>
        <span class="nb">any</span><span class="p">(</span><span class="n">action</span><span class="o">.</span><span class="n">has_backward_work</span> <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">sub_program</span><span class="p">)</span> <span class="k">for</span> <span class="n">sub_program</span> <span class="ow">in</span> <span class="n">program</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
    <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_comm_handler</span> <span class="o">=</span> <span class="n">PipelineCommunicationHandler</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stages</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_callback</span><span class="p">:</span> <span class="n">PipelineLossHandler</span> <span class="o">|</span> <span class="n">PipelineResultHandler</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_callback</span> <span class="o">=</span> <span class="n">PipelineLossHandler</span><span class="p">(</span><span class="n">callback</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_callback</span> <span class="o">=</span> <span class="n">PipelineResultHandler</span><span class="p">(</span><span class="n">callback</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_input_data_sharding_spec</span><span class="p">:</span> <span class="n">ShardingSpec</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_input_kwargs_sharding_spec</span><span class="p">:</span> <span class="n">ShardingSpec</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="d9d.pipelining.infra.schedule.component.program" class="doc doc-heading">
            <code>d9d.pipelining.infra.schedule.component.program</code>


</h2>

    <div class="doc doc-contents first">

        <p>Pipeline Schedule Building Components.</p>
<p>This package provides the core building blocks and compiler passes used to generate
execution schedules for distributed pipelines.</p>










<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="d9d.pipelining.infra.schedule.component.program.PipelineProgramBuilder" class="doc doc-heading">
            <code>PipelineProgramBuilder</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="abc.ABC">ABC</span></code></p>



        <p>Abstract interface for building pipeline execution schedules.</p>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>d9d/pipelining/infra/schedule/component/program/base.py</code></summary>
                <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">PipelineProgramBuilder</span><span class="p">(</span><span class="n">abc</span><span class="o">.</span><span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Abstract interface for building pipeline execution schedules.&quot;&quot;&quot;</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">compose</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_microbatches</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">pp_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">ActionBase</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generates the execution program for all ranks in the pipeline.</span>

<span class="sd">        Args:</span>
<span class="sd">            num_microbatches: Number of microbatches per step.</span>
<span class="sd">            pp_size: Number of pipeline parallel ranks.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A dictionary mapping rank indices to their list of sequential actions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="o">...</span>

    <span class="nd">@property</span>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">num_stages_per_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the number of model stages designated for each rank.&quot;&quot;&quot;</span>

        <span class="o">...</span>

    <span class="nd">@property</span>
    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">topology_style</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ScheduleStyle</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the topology style strategy used to assign stages to ranks.&quot;&quot;&quot;</span>
        <span class="o">...</span>
</code></pre></div></td></tr></table></div></div>
              </details>



<div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="d9d.pipelining.infra.schedule.component.program.PipelineProgramBuilder.num_stages_per_rank" class="doc doc-heading">
            <code class=" language-python"><span class="n">num_stages_per_rank</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Returns the number of model stages designated for each rank.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="d9d.pipelining.infra.schedule.component.program.PipelineProgramBuilder.topology_style" class="doc doc-heading">
            <code class=" language-python"><span class="n">topology_style</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Returns the topology style strategy used to assign stages to ranks.</p>

    </div>

</div>




<div class="doc doc-object doc-function">


<h4 id="d9d.pipelining.infra.schedule.component.program.PipelineProgramBuilder.compose" class="doc doc-heading">
            <code class=" language-python"><span class="n">compose</span><span class="p">(</span><span class="n">num_microbatches</span><span class="p">,</span> <span class="n">pp_size</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Generates the execution program for all ranks in the pipeline.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <div class="table-wrapper"><table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>num_microbatches</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of microbatches per step.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pp_size</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of pipeline parallel ranks.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table></div>


    <p><span class="doc-section-title">Returns:</span></p>
    <div class="table-wrapper"><table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="dict">dict</span>[<span title="int">int</span>, <span title="list">list</span>[<a class="autorefs autorefs-internal" title="ActionBase (d9d.pipelining.infra.schedule.component.runtime.ActionBase)" href="#d9d.pipelining.infra.schedule.component.runtime.ActionBase">ActionBase</a>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A dictionary mapping rank indices to their list of sequential actions.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>d9d/pipelining/infra/schedule/component/program/base.py</code></summary>
              <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">compose</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_microbatches</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">pp_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">ActionBase</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generates the execution program for all ranks in the pipeline.</span>

<span class="sd">    Args:</span>
<span class="sd">        num_microbatches: Number of microbatches per step.</span>
<span class="sd">        pp_size: Number of pipeline parallel ranks.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A dictionary mapping rank indices to their list of sequential actions.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="o">...</span>
</code></pre></div></td></tr></table></div></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="d9d.pipelining.infra.schedule.component.program.ScheduleStyle" class="doc doc-heading">
            <code>ScheduleStyle</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="enum.StrEnum">StrEnum</span></code></p>



        <p>Defines the strategy for mapping logical stages to physical ranks.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <div class="table-wrapper"><table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="d9d.pipelining.infra.schedule.component.program.ScheduleStyle.loop">loop</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Assigns stages in a round-robin circular fashion (mod pp_size).</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="d9d.pipelining.infra.schedule.component.program.ScheduleStyle.v">v</span></code></td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Assigns stages in a zig-zag V-shape pattern. Useful for interleaved 1F1B schedules.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table></div>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>d9d/pipelining/infra/schedule/component/program/topology.py</code></summary>
                <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">ScheduleStyle</span><span class="p">(</span><span class="n">StrEnum</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Defines the strategy for mapping logical stages to physical ranks.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        loop: Assigns stages in a round-robin circular fashion (mod pp_size).</span>
<span class="sd">        v: Assigns stages in a zig-zag V-shape pattern. Useful for interleaved 1F1B schedules.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">loop</span> <span class="o">=</span> <span class="s2">&quot;loop&quot;</span>
    <span class="n">v</span> <span class="o">=</span> <span class="s2">&quot;v&quot;</span>
</code></pre></div></td></tr></table></div></div>
              </details>



<div class="doc doc-children">












  </div>

    </div>

</div>


<div class="doc doc-object doc-function">


<h3 id="d9d.pipelining.infra.schedule.component.program.add_communication_ops" class="doc doc-heading">
            <code class=" language-python"><span class="n">add_communication_ops</span><span class="p">(</span><span class="n">compute_actions</span><span class="p">,</span> <span class="n">stage_to_rank</span><span class="p">,</span> <span class="n">num_stages</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Injects communication actions into a computation-only schedule.</p>
<p>This function iterates through the provided compute schedule and simulates execution.
When a compute action produces a result needed by a different rank, it injects
Send/Receive pairs. It also reorders actions to ensure that Receive
operations occur before the Computes that depend on them, preventing deadlocks.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <div class="table-wrapper"><table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>compute_actions</code>
            </td>
            <td>
                  <code><span title="dict">dict</span>[<span title="int">int</span>, <span title="list">list</span>[<a class="autorefs autorefs-internal" title="ActionBase (d9d.pipelining.infra.schedule.component.runtime.action.ActionBase)" href="#d9d.pipelining.infra.schedule.component.runtime.ActionBase">ActionBase</a>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Initial schedule containing only compute operations.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>stage_to_rank</code>
            </td>
            <td>
                  <code><span title="dict">dict</span>[<span title="int">int</span>, <span title="int">int</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Mapping from stage index to rank index.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_stages</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Total number of pipeline stages.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table></div>


    <p><span class="doc-section-title">Returns:</span></p>
    <div class="table-wrapper"><table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="dict">dict</span>[<span title="int">int</span>, <span title="list">list</span>[<a class="autorefs autorefs-internal" title="ActionBase (d9d.pipelining.infra.schedule.component.runtime.action.ActionBase)" href="#d9d.pipelining.infra.schedule.component.runtime.ActionBase">ActionBase</a>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A new schedule dictionary including both compute and communication actions.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table></div>


<p><span class="doc-section-title">Raises:</span></p>
    <div class="table-wrapper"><table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="RuntimeError">RuntimeError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If the schedule simulation enters a deadlock state.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>d9d/pipelining/infra/schedule/component/program/communications.py</code></summary>
              <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">add_communication_ops</span><span class="p">(</span>
    <span class="n">compute_actions</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">ActionBase</span><span class="p">]],</span>
    <span class="n">stage_to_rank</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
    <span class="n">num_stages</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">ActionBase</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Injects communication actions into a computation-only schedule.</span>

<span class="sd">    This function iterates through the provided compute schedule and simulates execution.</span>
<span class="sd">    When a compute action produces a result needed by a different rank, it injects</span>
<span class="sd">    Send/Receive pairs. It also reorders actions to ensure that Receive</span>
<span class="sd">    operations occur before the Computes that depend on them, preventing deadlocks.</span>

<span class="sd">    Args:</span>
<span class="sd">        compute_actions: Initial schedule containing only compute operations.</span>
<span class="sd">        stage_to_rank: Mapping from stage index to rank index.</span>
<span class="sd">        num_stages: Total number of pipeline stages.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A new schedule dictionary including both compute and communication actions.</span>

<span class="sd">    Raises:</span>
<span class="sd">        RuntimeError: If the schedule simulation enters a deadlock state.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">compute_actions</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">compute_actions</span><span class="p">)</span>

    <span class="n">full_actions</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">ActionBase</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{</span><span class="n">rank</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="n">compute_actions</span><span class="p">}</span>
    <span class="n">completed_events</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">set</span><span class="p">[</span><span class="n">ActionBase</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{</span><span class="n">rank</span><span class="p">:</span> <span class="nb">set</span><span class="p">()</span> <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="n">compute_actions</span><span class="p">}</span>

    <span class="k">while</span> <span class="n">compute_actions</span><span class="p">:</span>
        <span class="n">progress</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">compute_actions</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">compute_actions</span><span class="p">[</span><span class="n">rank</span><span class="p">]:</span>
                <span class="k">del</span> <span class="n">compute_actions</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span>
                <span class="k">continue</span>

            <span class="n">current_action</span> <span class="o">=</span> <span class="n">compute_actions</span><span class="p">[</span><span class="n">rank</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">sub_actions</span> <span class="o">=</span> <span class="n">_get_sub_actions</span><span class="p">(</span><span class="n">current_action</span><span class="p">)</span>

            <span class="c1"># Check readiness</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">check_action_communication_dependencies_fulfilled</span><span class="p">(</span>
                <span class="n">current_action</span><span class="p">,</span> <span class="n">completed_events</span><span class="p">[</span><span class="n">rank</span><span class="p">],</span> <span class="n">num_stages</span>
            <span class="p">):</span>
                <span class="k">continue</span>

            <span class="c1"># Execute</span>
            <span class="n">full_actions</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_action</span><span class="p">)</span>
            <span class="n">compute_actions</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">progress</span> <span class="o">=</span> <span class="kc">True</span>

            <span class="k">for</span> <span class="n">sub_action</span> <span class="ow">in</span> <span class="n">sub_actions</span><span class="p">:</span>
                <span class="n">completed_events</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">sub_action</span><span class="p">)</span>

                <span class="n">comm_pkg</span> <span class="o">=</span> <span class="n">_create_communications_for_action</span><span class="p">(</span>
                    <span class="n">sub_action</span><span class="p">,</span> <span class="n">num_stages</span><span class="o">=</span><span class="n">num_stages</span><span class="p">,</span> <span class="n">stage_to_rank</span><span class="o">=</span><span class="n">stage_to_rank</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">comm_pkg</span><span class="p">:</span>
                    <span class="c1"># Add Send locally</span>
                    <span class="n">full_actions</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">comm_pkg</span><span class="o">.</span><span class="n">send</span><span class="p">)</span>
                    <span class="n">completed_events</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">comm_pkg</span><span class="o">.</span><span class="n">send</span><span class="p">)</span>

                    <span class="c1"># Add Recv remotely and unblock target</span>
                    <span class="n">full_actions</span><span class="p">[</span><span class="n">comm_pkg</span><span class="o">.</span><span class="n">sends_to_rank</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">comm_pkg</span><span class="o">.</span><span class="n">recv</span><span class="p">)</span>
                    <span class="n">completed_events</span><span class="p">[</span><span class="n">comm_pkg</span><span class="o">.</span><span class="n">sends_to_rank</span><span class="p">]</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">comm_pkg</span><span class="o">.</span><span class="n">recv</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">progress</span> <span class="ow">and</span> <span class="n">compute_actions</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Deadlock in schedule simulation&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">full_actions</span>
</code></pre></div></td></tr></table></div></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="d9d.pipelining.infra.schedule.component.program.build_stage_to_host_rank_topology" class="doc doc-heading">
            <code class=" language-python"><span class="n">build_stage_to_host_rank_topology</span><span class="p">(</span><span class="n">pp_size</span><span class="p">,</span> <span class="n">num_stages</span><span class="p">,</span> <span class="n">style</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Constructs the mapping from stage index to rank index.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <div class="table-wrapper"><table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>pp_size</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of pipeline parallel ranks.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_stages</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Total number of model stages.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>style</code>
            </td>
            <td>
                  <code><a class="autorefs autorefs-internal" title="ScheduleStyle (d9d.pipelining.infra.schedule.component.program.topology.ScheduleStyle)" href="#d9d.pipelining.infra.schedule.component.program.ScheduleStyle">ScheduleStyle</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The topology style to use for assignment.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table></div>


    <p><span class="doc-section-title">Returns:</span></p>
    <div class="table-wrapper"><table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="dict">dict</span>[<span title="int">int</span>, <span title="int">int</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A dictionary mapping stage IDs to Rank IDs.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table></div>


<p><span class="doc-section-title">Raises:</span></p>
    <div class="table-wrapper"><table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="ValueError">ValueError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If the style is unknown or if V-style parameters are invalid
(num_stages must be divisible by pp_size).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>d9d/pipelining/infra/schedule/component/program/topology.py</code></summary>
              <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">build_stage_to_host_rank_topology</span><span class="p">(</span><span class="n">pp_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">num_stages</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">style</span><span class="p">:</span> <span class="n">ScheduleStyle</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Constructs the mapping from stage index to rank index.</span>

<span class="sd">    Args:</span>
<span class="sd">        pp_size: Number of pipeline parallel ranks.</span>
<span class="sd">        num_stages: Total number of model stages.</span>
<span class="sd">        style: The topology style to use for assignment.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A dictionary mapping stage IDs to Rank IDs.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If the style is unknown or if V-style parameters are invalid</span>
<span class="sd">            (num_stages must be divisible by pp_size).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">match</span> <span class="n">style</span><span class="p">:</span>
        <span class="k">case</span> <span class="n">ScheduleStyle</span><span class="o">.</span><span class="n">loop</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{</span><span class="n">stage_index</span><span class="p">:</span> <span class="n">stage_index</span> <span class="o">%</span> <span class="n">pp_size</span> <span class="k">for</span> <span class="n">stage_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_stages</span><span class="p">)}</span>
        <span class="k">case</span> <span class="n">ScheduleStyle</span><span class="o">.</span><span class="n">v</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">num_stages</span> <span class="o">%</span> <span class="n">pp_size</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;num_stages </span><span class="si">{</span><span class="n">num_stages</span><span class="si">}</span><span class="s2"> must be evenly divisible by pp_size </span><span class="si">{</span><span class="n">pp_size</span><span class="si">}</span><span class="s2"> for V schedules&quot;</span>
                <span class="p">)</span>

            <span class="n">result</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="n">rank_index</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">stage_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_stages</span><span class="p">):</span>
                <span class="n">result</span><span class="p">[</span><span class="n">stage_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">rank_index</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">stage_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">pp_size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">continue</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">stage_index</span> <span class="o">//</span> <span class="n">pp_size</span><span class="p">)</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">rank_index</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">rank_index</span> <span class="o">-=</span> <span class="mi">1</span>
            <span class="k">return</span> <span class="n">result</span>
        <span class="k">case</span><span class="w"> </span><span class="k">_</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">()</span>
</code></pre></div></td></tr></table></div></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="d9d.pipelining.infra.schedule.component.program.invert_stage_to_host_rank_topology" class="doc doc-heading">
            <code class=" language-python"><span class="n">invert_stage_to_host_rank_topology</span><span class="p">(</span><span class="n">stage_to_host</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Inverts the topology mapping to list execution stages per rank.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <div class="table-wrapper"><table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>stage_to_host</code>
            </td>
            <td>
                  <code><span title="dict">dict</span>[<span title="int">int</span>, <span title="int">int</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Mapping from stage index to rank index.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table></div>


    <p><span class="doc-section-title">Returns:</span></p>
    <div class="table-wrapper"><table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="dict">dict</span>[<span title="int">int</span>, <span title="list">list</span>[<span title="int">int</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A dictionary where keys are Rank IDs and values are lists of Stage IDs</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><span title="dict">dict</span>[<span title="int">int</span>, <span title="list">list</span>[<span title="int">int</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>managed by that rank.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>d9d/pipelining/infra/schedule/component/program/topology.py</code></summary>
              <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">invert_stage_to_host_rank_topology</span><span class="p">(</span><span class="n">stage_to_host</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Inverts the topology mapping to list execution stages per rank.</span>

<span class="sd">    Args:</span>
<span class="sd">        stage_to_host: Mapping from stage index to rank index.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A dictionary where keys are Rank IDs and values are lists of Stage IDs</span>
<span class="sd">        managed by that rank.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">host_to_stage</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">stage_idx</span><span class="p">,</span> <span class="n">host</span> <span class="ow">in</span> <span class="n">stage_to_host</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">host_to_stage</span><span class="p">[</span><span class="n">host</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">stage_idx</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">host_to_stage</span><span class="p">)</span>
</code></pre></div></td></tr></table></div></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="d9d.pipelining.infra.schedule.program" class="doc doc-heading">
            <code>d9d.pipelining.infra.schedule.program</code>


</h2>

    <div class="doc doc-contents first">

        <p>Pipeline Schedule Implementations</p>










<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="d9d.pipelining.infra.schedule.program.DualPipeVPipelineProgramBuilder" class="doc doc-heading">
            <code>DualPipeVPipelineProgramBuilder</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="PipelineProgramBuilder (d9d.pipelining.infra.schedule.component.program.PipelineProgramBuilder)" href="#d9d.pipelining.infra.schedule.component.program.PipelineProgramBuilder">PipelineProgramBuilder</a></code></p>



        <p>Builder for the DualPipeV Pipeline Parallelism schedule.</p>
<p>DualPipeV is a specialized bi-directional pipeline schedule designed for high
throughput training. It requires exactly 2 stages per pipeline rank (V-shape)
and utilizes split backward passes (Input gradients vs Weight gradients)
to fill pipeline bubbles.</p>


<details class="references" open>
  <summary>References</summary>
  <p>https://github.com/deepseek-ai/DualPipe
https://hackmd.io/@ufotalent/r1lVXsa9Jg</p>
</details>







              <details class="mkdocstrings-source">
                <summary>Source code in <code>d9d/pipelining/infra/schedule/program/dualpipev.py</code></summary>
                <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">DualPipeVPipelineProgramBuilder</span><span class="p">(</span><span class="n">PipelineProgramBuilder</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Builder for the DualPipeV Pipeline Parallelism schedule.</span>

<span class="sd">    DualPipeV is a specialized bi-directional pipeline schedule designed for high</span>
<span class="sd">    throughput training. It requires exactly 2 stages per pipeline rank (V-shape)</span>
<span class="sd">    and utilizes split backward passes (Input gradients vs Weight gradients)</span>
<span class="sd">    to fill pipeline bubbles.</span>

<span class="sd">    References:</span>
<span class="sd">        https://github.com/deepseek-ai/DualPipe</span>
<span class="sd">        https://hackmd.io/@ufotalent/r1lVXsa9Jg</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Constructs the DualPipeV builder.</span>
<span class="sd">        &quot;&quot;&quot;</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_build_for_rank</span><span class="p">(</span>  <span class="c1"># noqa: C901</span>
        <span class="n">rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">stage_to_rank</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">num_microbatches</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">pp_size</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">ActionBase</span><span class="p">]:</span>
        <span class="n">compute_actions</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">ActionBase</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Identify local stages: s0 is Phase 0, s1 is Phase 1</span>
        <span class="n">my_stages</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">([</span><span class="n">s</span> <span class="k">for</span> <span class="n">s</span><span class="p">,</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">stage_to_rank</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">r</span> <span class="o">==</span> <span class="n">rank</span><span class="p">])</span>
        <span class="n">s0</span><span class="p">,</span> <span class="n">s1</span> <span class="o">=</span> <span class="n">my_stages</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">my_stages</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># Track microbatch indices for each stage and operation type</span>
        <span class="c1"># f_idx: Next Forward microbatch</span>
        <span class="c1"># b_idx: Next Backward microbatch (Input or Full)</span>
        <span class="n">f_idx</span> <span class="o">=</span> <span class="p">{</span><span class="n">s0</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="n">s1</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>
        <span class="n">b_idx</span> <span class="o">=</span> <span class="p">{</span><span class="n">s0</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="n">s1</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>

        <span class="c1"># Queue for Zero Bubble optimization: stores (stage, mb_idx) for deferred weight grads</span>
        <span class="n">weight_queue</span><span class="p">:</span> <span class="n">deque</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="n">deque</span><span class="p">()</span>

        <span class="c1"># --- Helper Functions for Action Emission ---</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">_add_f</span><span class="p">(</span><span class="n">stage</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">compute_actions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ForwardComputeAction</span><span class="p">(</span><span class="n">stage_idx</span><span class="o">=</span><span class="n">stage</span><span class="p">,</span> <span class="n">microbatch_idx</span><span class="o">=</span><span class="n">f_idx</span><span class="p">[</span><span class="n">stage</span><span class="p">]))</span>
            <span class="n">f_idx</span><span class="p">[</span><span class="n">stage</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">_add_b_full</span><span class="p">(</span><span class="n">stage</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">compute_actions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">BackwardFullInputComputeAction</span><span class="p">(</span>
                    <span class="n">stage_idx</span><span class="o">=</span><span class="n">stage</span><span class="p">,</span>
                    <span class="n">microbatch_idx</span><span class="o">=</span><span class="n">b_idx</span><span class="p">[</span><span class="n">stage</span><span class="p">],</span>
                    <span class="n">full_backward</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="n">b_idx</span><span class="p">[</span><span class="n">stage</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">_add_b_input</span><span class="p">(</span><span class="n">stage</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">mb</span> <span class="o">=</span> <span class="n">b_idx</span><span class="p">[</span><span class="n">stage</span><span class="p">]</span>
            <span class="n">compute_actions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">BackwardFullInputComputeAction</span><span class="p">(</span>
                    <span class="n">stage_idx</span><span class="o">=</span><span class="n">stage</span><span class="p">,</span>
                    <span class="n">microbatch_idx</span><span class="o">=</span><span class="n">mb</span><span class="p">,</span>
                    <span class="n">full_backward</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="n">weight_queue</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">stage</span><span class="p">,</span> <span class="n">mb</span><span class="p">))</span>
            <span class="n">b_idx</span><span class="p">[</span><span class="n">stage</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">_pop_w</span><span class="p">():</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">weight_queue</span><span class="p">:</span>
                <span class="k">return</span>
            <span class="n">s</span><span class="p">,</span> <span class="n">mb</span> <span class="o">=</span> <span class="n">weight_queue</span><span class="o">.</span><span class="n">popleft</span><span class="p">()</span>
            <span class="n">compute_actions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">BackwardWeightComputeAction</span><span class="p">(</span><span class="n">stage_idx</span><span class="o">=</span><span class="n">s</span><span class="p">,</span> <span class="n">microbatch_idx</span><span class="o">=</span><span class="n">mb</span><span class="p">))</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">_add_overlap_f_b</span><span class="p">(</span><span class="n">stage_f</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">stage_b</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">b_is_full</span><span class="p">:</span> <span class="nb">bool</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Emit overlapped Forward and Backward actions.&quot;&quot;&quot;</span>
            <span class="n">mb_f</span> <span class="o">=</span> <span class="n">f_idx</span><span class="p">[</span><span class="n">stage_f</span><span class="p">]</span>
            <span class="n">mb_b</span> <span class="o">=</span> <span class="n">b_idx</span><span class="p">[</span><span class="n">stage_b</span><span class="p">]</span>

            <span class="n">act_f</span> <span class="o">=</span> <span class="n">ForwardComputeAction</span><span class="p">(</span><span class="n">stage_idx</span><span class="o">=</span><span class="n">stage_f</span><span class="p">,</span> <span class="n">microbatch_idx</span><span class="o">=</span><span class="n">mb_f</span><span class="p">)</span>

            <span class="n">act_b</span> <span class="o">=</span> <span class="n">BackwardFullInputComputeAction</span><span class="p">(</span><span class="n">stage_idx</span><span class="o">=</span><span class="n">stage_b</span><span class="p">,</span> <span class="n">microbatch_idx</span><span class="o">=</span><span class="n">mb_b</span><span class="p">,</span> <span class="n">full_backward</span><span class="o">=</span><span class="n">b_is_full</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">b_is_full</span><span class="p">:</span>
                <span class="n">weight_queue</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">stage_b</span><span class="p">,</span> <span class="n">mb_b</span><span class="p">))</span>

            <span class="n">f_idx</span><span class="p">[</span><span class="n">stage_f</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">b_idx</span><span class="p">[</span><span class="n">stage_b</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="c1"># Note: d9d infra treats ComposeAction sequentially in simulation,</span>
            <span class="c1"># but runtime may overlap them.</span>
            <span class="n">compute_actions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ComposeAction</span><span class="p">(</span><span class="n">actions</span><span class="o">=</span><span class="p">(</span><span class="n">act_f</span><span class="p">,</span> <span class="n">act_b</span><span class="p">)))</span>

        <span class="c1"># Step 1: nF0 (Startup Phase 0)</span>
        <span class="n">step_1</span> <span class="o">=</span> <span class="p">(</span><span class="n">pp_size</span> <span class="o">-</span> <span class="n">rank</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">step_1</span><span class="p">):</span>
            <span class="n">_add_f</span><span class="p">(</span><span class="n">s0</span><span class="p">)</span>

        <span class="c1"># Step 2: nF0F1 (Forward fill)</span>
        <span class="n">step_2</span> <span class="o">=</span> <span class="n">rank</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">step_2</span><span class="p">):</span>
            <span class="n">_add_f</span><span class="p">(</span><span class="n">s0</span><span class="p">)</span>
            <span class="n">_add_f</span><span class="p">(</span><span class="n">s1</span><span class="p">)</span>

        <span class="c1"># Step 3: nI1W1F1 (Mixed Phase with Zero Bubble)</span>
        <span class="n">step_3</span> <span class="o">=</span> <span class="n">pp_size</span> <span class="o">-</span> <span class="n">rank</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">step_3</span><span class="p">):</span>
            <span class="n">_add_b_input</span><span class="p">(</span><span class="n">s1</span><span class="p">)</span>  <span class="c1"># Backward Input Phase 1</span>
            <span class="n">_pop_w</span><span class="p">()</span>  <span class="c1"># Weight Phase (accumulated from prev)</span>
            <span class="n">_add_f</span><span class="p">(</span><span class="n">s1</span><span class="p">)</span>  <span class="c1"># Forward Phase 1</span>

        <span class="c1"># Step 4: The Main Loop (Interleaved Forward/Backward)</span>
        <span class="n">step_4</span> <span class="o">=</span> <span class="n">num_microbatches</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">pp_size</span> <span class="o">+</span> <span class="n">rank</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">step_4</span><span class="p">):</span>
            <span class="c1"># Sub-step A: F0 &amp; B1</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">rank</span> <span class="o">==</span> <span class="n">pp_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                <span class="c1"># Specific case for last rank on first iter: do not overlap</span>
                <span class="n">_add_f</span><span class="p">(</span><span class="n">s0</span><span class="p">)</span>
                <span class="n">_add_b_full</span><span class="p">(</span><span class="n">s1</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Overlap F0 and B1 (usually full backward unless we were in ZB mode,</span>
                <span class="c1"># but DualPipeV main loop defaults to full for simplicity unless tuned)</span>
                <span class="c1"># DeepSeek impl uses standard backward here (zb=False).</span>
                <span class="n">_add_overlap_f_b</span><span class="p">(</span><span class="n">stage_f</span><span class="o">=</span><span class="n">s0</span><span class="p">,</span> <span class="n">stage_b</span><span class="o">=</span><span class="n">s1</span><span class="p">,</span> <span class="n">b_is_full</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="c1"># Sub-step B: F1 &amp; B0</span>
            <span class="c1"># Overlap F1 and B0 (Full)</span>
            <span class="n">_add_overlap_f_b</span><span class="p">(</span><span class="n">stage_f</span><span class="o">=</span><span class="n">s1</span><span class="p">,</span> <span class="n">stage_b</span><span class="o">=</span><span class="n">s0</span><span class="p">,</span> <span class="n">b_is_full</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Step 5: Cooldown F1/B0</span>
        <span class="n">step_5</span> <span class="o">=</span> <span class="n">pp_size</span> <span class="o">-</span> <span class="n">rank</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">step_5</span><span class="p">):</span>
            <span class="n">_add_b_full</span><span class="p">(</span><span class="n">s1</span><span class="p">)</span>
            <span class="n">_add_overlap_f_b</span><span class="p">(</span><span class="n">stage_f</span><span class="o">=</span><span class="n">s1</span><span class="p">,</span> <span class="n">stage_b</span><span class="o">=</span><span class="n">s0</span><span class="p">,</span> <span class="n">b_is_full</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Step 6: Cooldown B1/B0 with Zero Bubble ramp-up</span>
        <span class="n">step_6</span> <span class="o">=</span> <span class="n">rank</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">enable_zb</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">step_6</span><span class="p">):</span>
            <span class="c1"># Phase 1 Backward</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">step_6</span> <span class="o">//</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">rank</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">enable_zb</span> <span class="o">=</span> <span class="kc">True</span>

            <span class="k">if</span> <span class="n">enable_zb</span><span class="p">:</span>
                <span class="n">_add_b_input</span><span class="p">(</span><span class="n">s1</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">_add_b_full</span><span class="p">(</span><span class="n">s1</span><span class="p">)</span>

            <span class="c1"># Phase 0 Backward</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">step_6</span> <span class="o">//</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">rank</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">enable_zb</span> <span class="o">=</span> <span class="kc">True</span>

            <span class="k">if</span> <span class="n">enable_zb</span><span class="p">:</span>
                <span class="n">_add_b_input</span><span class="p">(</span><span class="n">s0</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">_add_b_full</span><span class="p">(</span><span class="n">s0</span><span class="p">)</span>

        <span class="c1"># Step 7: Zero Bubble Weights + B0</span>
        <span class="n">step_7</span> <span class="o">=</span> <span class="n">pp_size</span> <span class="o">-</span> <span class="n">rank</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">step_7</span><span class="p">):</span>
            <span class="n">_pop_w</span><span class="p">()</span>
            <span class="c1"># DeepSeek source explicitly uses enable_zb=True here for chunk 0</span>
            <span class="n">_add_b_input</span><span class="p">(</span><span class="n">s0</span><span class="p">)</span>

        <span class="c1"># Step 8: Flush Weights</span>
        <span class="n">step_8</span> <span class="o">=</span> <span class="n">rank</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">step_8</span><span class="p">):</span>
            <span class="n">_pop_w</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">compute_actions</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">compose</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_microbatches</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">pp_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">ActionBase</span><span class="p">]]:</span>
        <span class="n">num_stages</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_stages_per_rank</span> <span class="o">*</span> <span class="n">pp_size</span>

        <span class="k">if</span> <span class="n">num_microbatches</span> <span class="o">&lt;</span> <span class="n">num_stages</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;DualPipeV requires num_microbatches (</span><span class="si">{</span><span class="n">num_microbatches</span><span class="si">}</span><span class="s2">) &gt;= num_stages (</span><span class="si">{</span><span class="n">num_stages</span><span class="si">}</span><span class="s2">).&quot;</span><span class="p">)</span>

        <span class="c1"># Ranks hold stages in a V pattern (e.g., Rank 0 holds Stage 0 and Stage N-1).</span>
        <span class="c1"># We rely on the sorted order of local steps to determine Phase 0 (Forward-going)</span>
        <span class="c1"># and Phase 1 (Backward-coming).</span>
        <span class="n">stage_to_rank</span> <span class="o">=</span> <span class="n">build_stage_to_host_rank_topology</span><span class="p">(</span><span class="n">pp_size</span><span class="o">=</span><span class="n">pp_size</span><span class="p">,</span> <span class="n">num_stages</span><span class="o">=</span><span class="n">num_stages</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="n">ScheduleStyle</span><span class="o">.</span><span class="n">v</span><span class="p">)</span>

        <span class="n">compute_actions</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">ActionBase</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{</span><span class="n">r</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">pp_size</span><span class="p">)}</span>

        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">pp_size</span><span class="p">):</span>
            <span class="n">compute_actions</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_for_rank</span><span class="p">(</span>
                <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span> <span class="n">pp_size</span><span class="o">=</span><span class="n">pp_size</span><span class="p">,</span> <span class="n">num_microbatches</span><span class="o">=</span><span class="n">num_microbatches</span><span class="p">,</span> <span class="n">stage_to_rank</span><span class="o">=</span><span class="n">stage_to_rank</span>
            <span class="p">)</span>

        <span class="c1"># 4. Inject Communication Operations</span>
        <span class="c1"># This wrapper handles dependency analysis and inserts Send/Recv/Wait ops.</span>
        <span class="k">return</span> <span class="n">add_communication_ops</span><span class="p">(</span>
            <span class="n">compute_actions</span><span class="o">=</span><span class="n">compute_actions</span><span class="p">,</span> <span class="n">stage_to_rank</span><span class="o">=</span><span class="n">stage_to_rank</span><span class="p">,</span> <span class="n">num_stages</span><span class="o">=</span><span class="n">num_stages</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">num_stages_per_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">2</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">topology_style</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ScheduleStyle</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ScheduleStyle</span><span class="o">.</span><span class="n">v</span>
</code></pre></div></td></tr></table></div></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="d9d.pipelining.infra.schedule.program.DualPipeVPipelineProgramBuilder.__init__" class="doc doc-heading">
            <code class=" language-python"><span class="fm">__init__</span><span class="p">()</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Constructs the DualPipeV builder.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>d9d/pipelining/infra/schedule/program/dualpipev.py</code></summary>
              <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Constructs the DualPipeV builder.</span>
<span class="sd">    &quot;&quot;&quot;</span>
</code></pre></div></td></tr></table></div></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="d9d.pipelining.infra.schedule.program.Interleaved1F1BPipelineProgramBuilder" class="doc doc-heading">
            <code>Interleaved1F1BPipelineProgramBuilder</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="PipelineProgramBuilder (d9d.pipelining.infra.schedule.component.program.PipelineProgramBuilder)" href="#d9d.pipelining.infra.schedule.component.program.PipelineProgramBuilder">PipelineProgramBuilder</a></code></p>



        <p>Builder for Interleaved Pipeline Parallelism schedules.</p>
<p>This builder supports:</p>
<ol>
<li><strong>Standard Interleaved 1F1B</strong>: Assigns multiple stages per rank and prioritizes
    depth-first execution. (See https://arxiv.org/pdf/2104.04473)</li>
<li><strong>Interleaved Zero Bubble (ZB1P)</strong>: Extends 1F1B by splitting backward passes
    into Input Gradients and Weight Gradients. Weight gradients are delayed
    to fill pipeline bubbles. (See https://arxiv.org/pdf/2401.10241)</li>
</ol>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>d9d/pipelining/infra/schedule/program/interleaved.py</code></summary>
                <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">Interleaved1F1BPipelineProgramBuilder</span><span class="p">(</span><span class="n">PipelineProgramBuilder</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Builder for Interleaved Pipeline Parallelism schedules.</span>

<span class="sd">    This builder supports:</span>

<span class="sd">    1.  **Standard Interleaved 1F1B**: Assigns multiple stages per rank and prioritizes</span>
<span class="sd">        depth-first execution. (See https://arxiv.org/pdf/2104.04473)</span>
<span class="sd">    2.  **Interleaved Zero Bubble (ZB1P)**: Extends 1F1B by splitting backward passes</span>
<span class="sd">        into Input Gradients and Weight Gradients. Weight gradients are delayed</span>
<span class="sd">        to fill pipeline bubbles. (See https://arxiv.org/pdf/2401.10241)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_stages_per_rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">enable_zero_bubble</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Constructs the Interleaved 1F1B builder.</span>

<span class="sd">        Args:</span>
<span class="sd">            num_stages_per_rank: Number of stages per rank.</span>
<span class="sd">            enable_zero_bubble: If True, uses the ZB1P schedule variant which</span>
<span class="sd">                splits backward passes to reduce bubble size.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_num_stages_per_rank</span> <span class="o">=</span> <span class="n">num_stages_per_rank</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_enable_zero_bubble</span> <span class="o">=</span> <span class="n">enable_zero_bubble</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_warmup_ops</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">microbatches_per_round</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">pp_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">n_microbatches</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">multiply_factor</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the number of warmup steps required before entering steady state.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">warmups_ops_last_stage</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_num_stages_per_rank</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">microbatches_per_round</span>
        <span class="n">warmup_ops</span> <span class="o">=</span> <span class="n">warmups_ops_last_stage</span> <span class="o">+</span> <span class="n">multiply_factor</span> <span class="o">*</span> <span class="p">((</span><span class="n">pp_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">rank</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">min</span><span class="p">(</span><span class="n">warmup_ops</span><span class="p">,</span> <span class="n">n_microbatches</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_stages_per_rank</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">compose</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_microbatches</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">pp_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">ActionBase</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generates the execution program for all ranks.</span>

<span class="sd">        Args:</span>
<span class="sd">            num_microbatches: Total microbatches. Must be divisible by the derived</span>
<span class="sd">                number of rounds.</span>
<span class="sd">            pp_size: Number of pipeline ranks.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A dictionary mapping rank indices to their list of sequential actions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">num_stages</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_stages_per_rank</span> <span class="o">*</span> <span class="n">pp_size</span>

        <span class="k">if</span> <span class="n">num_stages</span> <span class="o">%</span> <span class="n">pp_size</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;num_stages (</span><span class="si">{</span><span class="n">num_stages</span><span class="si">}</span><span class="s2">) must be divisible by pp_size (</span><span class="si">{</span><span class="n">pp_size</span><span class="si">}</span><span class="s2">) for interleaved schedules.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># 1. Topology Setup</span>
        <span class="c1"># Use Loop/Round-Robin assignment: Rank 0 gets Stage 0, PP, 2*PP...</span>
        <span class="n">stage_to_rank</span> <span class="o">=</span> <span class="n">build_stage_to_host_rank_topology</span><span class="p">(</span>
            <span class="n">pp_size</span><span class="o">=</span><span class="n">pp_size</span><span class="p">,</span> <span class="n">num_stages</span><span class="o">=</span><span class="n">num_stages</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="n">ScheduleStyle</span><span class="o">.</span><span class="n">loop</span>
        <span class="p">)</span>

        <span class="n">num_rounds</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_microbatches</span> <span class="o">//</span> <span class="n">pp_size</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">num_microbatches</span> <span class="o">%</span> <span class="n">num_rounds</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;microbatches (</span><span class="si">{</span><span class="n">num_microbatches</span><span class="si">}</span><span class="s2">) must be divisible by rounds (</span><span class="si">{</span><span class="n">num_rounds</span><span class="si">}</span><span class="s2">).&quot;</span><span class="p">)</span>

        <span class="n">microbatches_per_round</span> <span class="o">=</span> <span class="n">num_microbatches</span> <span class="o">//</span> <span class="n">num_rounds</span>

        <span class="c1"># 2. Schedule Generation</span>
        <span class="n">actions</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">ActionBase</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># Zero Bubble 1f1b uses a shorter warmup heuristic (factor 1) than Standard (factor 2)</span>
        <span class="n">warmup_multiplier</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_enable_zero_bubble</span> <span class="k">else</span> <span class="mi">2</span>

        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">pp_size</span><span class="p">):</span>
            <span class="n">actions</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_rank_schedule</span><span class="p">(</span>
                <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span>
                <span class="n">pp_size</span><span class="o">=</span><span class="n">pp_size</span><span class="p">,</span>
                <span class="n">n_microbatches</span><span class="o">=</span><span class="n">num_microbatches</span><span class="p">,</span>
                <span class="n">microbatches_per_round</span><span class="o">=</span><span class="n">microbatches_per_round</span><span class="p">,</span>
                <span class="n">multiply_factor</span><span class="o">=</span><span class="n">warmup_multiplier</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># 3. Communication Injection</span>
        <span class="k">return</span> <span class="n">add_communication_ops</span><span class="p">(</span>
            <span class="n">compute_actions</span><span class="o">=</span><span class="n">actions</span><span class="p">,</span>
            <span class="n">stage_to_rank</span><span class="o">=</span><span class="n">stage_to_rank</span><span class="p">,</span>
            <span class="n">num_stages</span><span class="o">=</span><span class="n">num_stages</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_generate_rank_schedule</span><span class="p">(</span>  <span class="c1"># noqa: C901</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">pp_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">n_microbatches</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">microbatches_per_round</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">multiply_factor</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">ActionBase</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generates the sequential list of compute actions for a specific rank.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">rank_actions</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">ActionBase</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># -- State Tracking --</span>
        <span class="c1"># Map: stage_idx -&gt; next_microbatch_idx</span>
        <span class="n">fwd_counters</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="n">bwd_counters</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

        <span class="c1"># FIFO Queue for deferred weight gradients in Zero Bubble</span>
        <span class="c1"># Stores: (stage_idx, microbatch_idx)</span>
        <span class="n">pending_weights</span><span class="p">:</span> <span class="n">deque</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="n">deque</span><span class="p">()</span>

        <span class="c1"># -- Helpers --</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">get_global_stage</span><span class="p">(</span><span class="n">local_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Converts a local virtual stage index (0..N) to global stage ID.&quot;&quot;&quot;</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">local_idx</span> <span class="o">*</span> <span class="n">pp_size</span><span class="p">)</span> <span class="o">+</span> <span class="n">rank</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">get_fwd_local_idx</span><span class="p">(</span><span class="n">op_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">op_idx</span> <span class="o">//</span> <span class="n">microbatches_per_round</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_stages_per_rank</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">get_bwd_local_idx</span><span class="p">(</span><span class="n">op_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">warmup_offset</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_num_stages_per_rank</span>
                <span class="o">-</span> <span class="mi">1</span>
                <span class="o">-</span> <span class="p">((</span><span class="n">op_idx</span> <span class="o">-</span> <span class="n">warmup_offset</span><span class="p">)</span> <span class="o">//</span> <span class="n">microbatches_per_round</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_stages_per_rank</span>
            <span class="p">)</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">emit_forward</span><span class="p">(</span><span class="n">op_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">local_idx</span> <span class="o">=</span> <span class="n">get_fwd_local_idx</span><span class="p">(</span><span class="n">op_idx</span><span class="p">)</span>
            <span class="n">stage</span> <span class="o">=</span> <span class="n">get_global_stage</span><span class="p">(</span><span class="n">local_idx</span><span class="p">)</span>
            <span class="n">mb</span> <span class="o">=</span> <span class="n">fwd_counters</span><span class="p">[</span><span class="n">stage</span><span class="p">]</span>

            <span class="n">rank_actions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ForwardComputeAction</span><span class="p">(</span><span class="n">stage_idx</span><span class="o">=</span><span class="n">stage</span><span class="p">,</span> <span class="n">microbatch_idx</span><span class="o">=</span><span class="n">mb</span><span class="p">))</span>
            <span class="n">fwd_counters</span><span class="p">[</span><span class="n">stage</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">emit_backward</span><span class="p">(</span><span class="n">op_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">warmup_offset</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">local_idx</span> <span class="o">=</span> <span class="n">get_bwd_local_idx</span><span class="p">(</span><span class="n">op_idx</span><span class="p">,</span> <span class="n">warmup_offset</span><span class="p">)</span>
            <span class="n">stage</span> <span class="o">=</span> <span class="n">get_global_stage</span><span class="p">(</span><span class="n">local_idx</span><span class="p">)</span>
            <span class="n">mb</span> <span class="o">=</span> <span class="n">bwd_counters</span><span class="p">[</span><span class="n">stage</span><span class="p">]</span>

            <span class="c1"># In Zero Bubble, we split: Backward Input (Now) + Backward Weight (Later)</span>
            <span class="c1"># In Standard 1F1B, we do full backward now.</span>
            <span class="n">is_full</span> <span class="o">=</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_enable_zero_bubble</span>

            <span class="n">rank_actions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">BackwardFullInputComputeAction</span><span class="p">(</span><span class="n">stage_idx</span><span class="o">=</span><span class="n">stage</span><span class="p">,</span> <span class="n">microbatch_idx</span><span class="o">=</span><span class="n">mb</span><span class="p">,</span> <span class="n">full_backward</span><span class="o">=</span><span class="n">is_full</span><span class="p">)</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_enable_zero_bubble</span><span class="p">:</span>
                <span class="n">pending_weights</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">stage</span><span class="p">,</span> <span class="n">mb</span><span class="p">))</span>

            <span class="n">bwd_counters</span><span class="p">[</span><span class="n">stage</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">try_emit_weight_zb</span><span class="p">(</span><span class="n">op_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">warmup_offset</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_enable_zero_bubble</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">pending_weights</span><span class="p">:</span>
                <span class="k">return</span>

            <span class="n">steps_into_1f1b</span> <span class="o">=</span> <span class="n">op_idx</span> <span class="o">-</span> <span class="n">warmup_offset</span>
            <span class="c1"># The earliest reasonable time to start weaving in weights is proportional to rank depth</span>
            <span class="k">if</span> <span class="n">steps_into_1f1b</span> <span class="o">&gt;=</span> <span class="n">rank</span><span class="p">:</span>
                <span class="n">w_stage</span><span class="p">,</span> <span class="n">w_mb</span> <span class="o">=</span> <span class="n">pending_weights</span><span class="o">.</span><span class="n">popleft</span><span class="p">()</span>
                <span class="n">rank_actions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">BackwardWeightComputeAction</span><span class="p">(</span><span class="n">stage_idx</span><span class="o">=</span><span class="n">w_stage</span><span class="p">,</span> <span class="n">microbatch_idx</span><span class="o">=</span><span class="n">w_mb</span><span class="p">))</span>

        <span class="c1"># -- Execution Phase Math --</span>

        <span class="n">warmup_ops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_warmup_ops</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">microbatches_per_round</span><span class="p">,</span> <span class="n">pp_size</span><span class="p">,</span> <span class="n">n_microbatches</span><span class="p">,</span> <span class="n">multiply_factor</span><span class="p">)</span>
        <span class="n">total_microbatch_ops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_stages_per_rank</span> <span class="o">*</span> <span class="n">n_microbatches</span>
        <span class="n">fwd_bwd_ops</span> <span class="o">=</span> <span class="n">total_microbatch_ops</span> <span class="o">-</span> <span class="n">warmup_ops</span>
        <span class="n">cooldown_ops</span> <span class="o">=</span> <span class="n">total_microbatch_ops</span> <span class="o">-</span> <span class="n">fwd_bwd_ops</span>

        <span class="c1"># Combine into one sequence for iteration, but handle logic per phase</span>
        <span class="n">total_ops</span> <span class="o">=</span> <span class="n">warmup_ops</span> <span class="o">+</span> <span class="n">fwd_bwd_ops</span> <span class="o">+</span> <span class="n">cooldown_ops</span>

        <span class="c1"># -- Main Schedule Loop --</span>

        <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">total_ops</span><span class="p">):</span>
            <span class="c1"># Phase 1: Warmup (Forward Only)</span>
            <span class="k">if</span> <span class="n">op</span> <span class="o">&lt;</span> <span class="n">warmup_ops</span><span class="p">:</span>
                <span class="n">emit_forward</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>

            <span class="c1"># Phase 2: Steady State (1F1B)</span>
            <span class="k">elif</span> <span class="n">op</span> <span class="o">&lt;</span> <span class="n">warmup_ops</span> <span class="o">+</span> <span class="n">fwd_bwd_ops</span><span class="p">:</span>
                <span class="n">emit_forward</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
                <span class="n">emit_backward</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">warmup_offset</span><span class="o">=</span><span class="n">warmup_ops</span><span class="p">)</span>
                <span class="n">try_emit_weight_zb</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">warmup_offset</span><span class="o">=</span><span class="n">warmup_ops</span><span class="p">)</span>

            <span class="c1"># Phase 3: Cooldown (Backward Only)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">emit_backward</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">warmup_offset</span><span class="o">=</span><span class="n">warmup_ops</span><span class="p">)</span>
                <span class="n">try_emit_weight_zb</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">warmup_offset</span><span class="o">=</span><span class="n">warmup_ops</span><span class="p">)</span>

        <span class="c1"># -- Post-Loop: Flush Remaining Weights (ZB only) --</span>
        <span class="k">while</span> <span class="n">pending_weights</span><span class="p">:</span>
            <span class="n">w_stage</span><span class="p">,</span> <span class="n">w_mb</span> <span class="o">=</span> <span class="n">pending_weights</span><span class="o">.</span><span class="n">popleft</span><span class="p">()</span>
            <span class="n">rank_actions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">BackwardWeightComputeAction</span><span class="p">(</span><span class="n">stage_idx</span><span class="o">=</span><span class="n">w_stage</span><span class="p">,</span> <span class="n">microbatch_idx</span><span class="o">=</span><span class="n">w_mb</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">rank_actions</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">num_stages_per_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_stages_per_rank</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">topology_style</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ScheduleStyle</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ScheduleStyle</span><span class="o">.</span><span class="n">loop</span>
</code></pre></div></td></tr></table></div></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="d9d.pipelining.infra.schedule.program.Interleaved1F1BPipelineProgramBuilder.__init__" class="doc doc-heading">
            <code class=" language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">num_stages_per_rank</span><span class="p">,</span> <span class="n">enable_zero_bubble</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Constructs the Interleaved 1F1B builder.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <div class="table-wrapper"><table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>num_stages_per_rank</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of stages per rank.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>enable_zero_bubble</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, uses the ZB1P schedule variant which
splits backward passes to reduce bubble size.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>d9d/pipelining/infra/schedule/program/interleaved.py</code></summary>
              <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_stages_per_rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">enable_zero_bubble</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Constructs the Interleaved 1F1B builder.</span>

<span class="sd">    Args:</span>
<span class="sd">        num_stages_per_rank: Number of stages per rank.</span>
<span class="sd">        enable_zero_bubble: If True, uses the ZB1P schedule variant which</span>
<span class="sd">            splits backward passes to reduce bubble size.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_num_stages_per_rank</span> <span class="o">=</span> <span class="n">num_stages_per_rank</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_enable_zero_bubble</span> <span class="o">=</span> <span class="n">enable_zero_bubble</span>
</code></pre></div></td></tr></table></div></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="d9d.pipelining.infra.schedule.program.Interleaved1F1BPipelineProgramBuilder.compose" class="doc doc-heading">
            <code class=" language-python"><span class="n">compose</span><span class="p">(</span><span class="n">num_microbatches</span><span class="p">,</span> <span class="n">pp_size</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Generates the execution program for all ranks.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <div class="table-wrapper"><table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>num_microbatches</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Total microbatches. Must be divisible by the derived
number of rounds.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pp_size</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of pipeline ranks.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table></div>


    <p><span class="doc-section-title">Returns:</span></p>
    <div class="table-wrapper"><table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="dict">dict</span>[<span title="int">int</span>, <span title="list">list</span>[<a class="autorefs autorefs-internal" title="ActionBase (d9d.pipelining.infra.schedule.component.runtime.ActionBase)" href="#d9d.pipelining.infra.schedule.component.runtime.ActionBase">ActionBase</a>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A dictionary mapping rank indices to their list of sequential actions.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>d9d/pipelining/infra/schedule/program/interleaved.py</code></summary>
              <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">compose</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_microbatches</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">pp_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">ActionBase</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generates the execution program for all ranks.</span>

<span class="sd">    Args:</span>
<span class="sd">        num_microbatches: Total microbatches. Must be divisible by the derived</span>
<span class="sd">            number of rounds.</span>
<span class="sd">        pp_size: Number of pipeline ranks.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A dictionary mapping rank indices to their list of sequential actions.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">num_stages</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_stages_per_rank</span> <span class="o">*</span> <span class="n">pp_size</span>

    <span class="k">if</span> <span class="n">num_stages</span> <span class="o">%</span> <span class="n">pp_size</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;num_stages (</span><span class="si">{</span><span class="n">num_stages</span><span class="si">}</span><span class="s2">) must be divisible by pp_size (</span><span class="si">{</span><span class="n">pp_size</span><span class="si">}</span><span class="s2">) for interleaved schedules.&quot;</span>
        <span class="p">)</span>

    <span class="c1"># 1. Topology Setup</span>
    <span class="c1"># Use Loop/Round-Robin assignment: Rank 0 gets Stage 0, PP, 2*PP...</span>
    <span class="n">stage_to_rank</span> <span class="o">=</span> <span class="n">build_stage_to_host_rank_topology</span><span class="p">(</span>
        <span class="n">pp_size</span><span class="o">=</span><span class="n">pp_size</span><span class="p">,</span> <span class="n">num_stages</span><span class="o">=</span><span class="n">num_stages</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="n">ScheduleStyle</span><span class="o">.</span><span class="n">loop</span>
    <span class="p">)</span>

    <span class="n">num_rounds</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_microbatches</span> <span class="o">//</span> <span class="n">pp_size</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">num_microbatches</span> <span class="o">%</span> <span class="n">num_rounds</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;microbatches (</span><span class="si">{</span><span class="n">num_microbatches</span><span class="si">}</span><span class="s2">) must be divisible by rounds (</span><span class="si">{</span><span class="n">num_rounds</span><span class="si">}</span><span class="s2">).&quot;</span><span class="p">)</span>

    <span class="n">microbatches_per_round</span> <span class="o">=</span> <span class="n">num_microbatches</span> <span class="o">//</span> <span class="n">num_rounds</span>

    <span class="c1"># 2. Schedule Generation</span>
    <span class="n">actions</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">ActionBase</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="c1"># Zero Bubble 1f1b uses a shorter warmup heuristic (factor 1) than Standard (factor 2)</span>
    <span class="n">warmup_multiplier</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_enable_zero_bubble</span> <span class="k">else</span> <span class="mi">2</span>

    <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">pp_size</span><span class="p">):</span>
        <span class="n">actions</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_rank_schedule</span><span class="p">(</span>
            <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span>
            <span class="n">pp_size</span><span class="o">=</span><span class="n">pp_size</span><span class="p">,</span>
            <span class="n">n_microbatches</span><span class="o">=</span><span class="n">num_microbatches</span><span class="p">,</span>
            <span class="n">microbatches_per_round</span><span class="o">=</span><span class="n">microbatches_per_round</span><span class="p">,</span>
            <span class="n">multiply_factor</span><span class="o">=</span><span class="n">warmup_multiplier</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1"># 3. Communication Injection</span>
    <span class="k">return</span> <span class="n">add_communication_ops</span><span class="p">(</span>
        <span class="n">compute_actions</span><span class="o">=</span><span class="n">actions</span><span class="p">,</span>
        <span class="n">stage_to_rank</span><span class="o">=</span><span class="n">stage_to_rank</span><span class="p">,</span>
        <span class="n">num_stages</span><span class="o">=</span><span class="n">num_stages</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="d9d.pipelining.infra.schedule.program.LoopedBFSPipelineProgramBuilder" class="doc doc-heading">
            <code>LoopedBFSPipelineProgramBuilder</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="PipelineProgramBuilder (d9d.pipelining.infra.schedule.component.program.PipelineProgramBuilder)" href="#d9d.pipelining.infra.schedule.component.program.PipelineProgramBuilder">PipelineProgramBuilder</a></code></p>



        <p>Builder for the Breadth-First Pipeline Parallelism schedule.</p>
<p>This schedule runs all available forward microbatches for local stages first.
If configured for training, it then runs backwards in reverse topological order.</p>


<details class="references" open>
  <summary>References</summary>
  <p>https://arxiv.org/pdf/2211.05953</p>
</details>







              <details class="mkdocstrings-source">
                <summary>Source code in <code>d9d/pipelining/infra/schedule/program/bfs.py</code></summary>
                <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">LoopedBFSPipelineProgramBuilder</span><span class="p">(</span><span class="n">PipelineProgramBuilder</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Builder for the Breadth-First Pipeline Parallelism schedule.</span>

<span class="sd">    This schedule runs all available forward microbatches for local stages first.</span>
<span class="sd">    If configured for training, it then runs backwards in reverse topological order.</span>

<span class="sd">    References:</span>
<span class="sd">        https://arxiv.org/pdf/2211.05953</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_stages_per_rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">inference_mode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Constructs the LoopedBFS builder.</span>

<span class="sd">        Args:</span>
<span class="sd">            num_stages_per_rank: Number of stages per rank.</span>
<span class="sd">            inference_mode: If True, only forward passes are scheduled. If False,</span>
<span class="sd">                both forward and backward passes are scheduled.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_num_stages_per_rank</span> <span class="o">=</span> <span class="n">num_stages_per_rank</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_inference_mode</span> <span class="o">=</span> <span class="n">inference_mode</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">compose</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_microbatches</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">pp_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">ActionBase</span><span class="p">]]:</span>
        <span class="n">num_stages</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_stages_per_rank</span> <span class="o">*</span> <span class="n">pp_size</span>
        <span class="n">stage_to_rank</span> <span class="o">=</span> <span class="n">build_stage_to_host_rank_topology</span><span class="p">(</span>
            <span class="n">pp_size</span><span class="o">=</span><span class="n">pp_size</span><span class="p">,</span> <span class="n">num_stages</span><span class="o">=</span><span class="n">num_stages</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="n">ScheduleStyle</span><span class="o">.</span><span class="n">loop</span>
        <span class="p">)</span>

        <span class="n">compute_actions</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">ActionBase</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{</span><span class="n">r</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">pp_size</span><span class="p">)}</span>

        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">pp_size</span><span class="p">):</span>
            <span class="n">my_stages</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_stages</span><span class="p">)</span> <span class="k">if</span> <span class="n">stage_to_rank</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">==</span> <span class="n">rank</span><span class="p">]</span>

            <span class="c1"># Schedule all Forwards</span>
            <span class="c1"># In Breadth-First loops, we finish all microbatches for the current stage</span>
            <span class="c1"># before moving to the next stage assigned to this rank.</span>
            <span class="k">for</span> <span class="n">stage_idx</span> <span class="ow">in</span> <span class="n">my_stages</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">mb_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_microbatches</span><span class="p">):</span>
                    <span class="n">compute_actions</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ForwardComputeAction</span><span class="p">(</span><span class="n">stage_idx</span><span class="o">=</span><span class="n">stage_idx</span><span class="p">,</span> <span class="n">microbatch_idx</span><span class="o">=</span><span class="n">mb_idx</span><span class="p">))</span>

            <span class="c1"># Schedule all Backwards (Reverse order) - Only if training</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inference_mode</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">stage_idx</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">my_stages</span><span class="p">):</span>
                    <span class="k">for</span> <span class="n">mb_idx</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_microbatches</span><span class="p">)):</span>
                        <span class="n">compute_actions</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                            <span class="n">BackwardFullInputComputeAction</span><span class="p">(</span>
                                <span class="n">stage_idx</span><span class="o">=</span><span class="n">stage_idx</span><span class="p">,</span> <span class="n">microbatch_idx</span><span class="o">=</span><span class="n">mb_idx</span><span class="p">,</span> <span class="n">full_backward</span><span class="o">=</span><span class="kc">True</span>
                            <span class="p">)</span>
                        <span class="p">)</span>

        <span class="k">return</span> <span class="n">add_communication_ops</span><span class="p">(</span>
            <span class="n">compute_actions</span><span class="o">=</span><span class="n">compute_actions</span><span class="p">,</span> <span class="n">stage_to_rank</span><span class="o">=</span><span class="n">stage_to_rank</span><span class="p">,</span> <span class="n">num_stages</span><span class="o">=</span><span class="n">num_stages</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">num_stages_per_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_stages_per_rank</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">topology_style</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ScheduleStyle</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ScheduleStyle</span><span class="o">.</span><span class="n">loop</span>
</code></pre></div></td></tr></table></div></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="d9d.pipelining.infra.schedule.program.LoopedBFSPipelineProgramBuilder.__init__" class="doc doc-heading">
            <code class=" language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">num_stages_per_rank</span><span class="p">,</span> <span class="n">inference_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Constructs the LoopedBFS builder.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <div class="table-wrapper"><table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>num_stages_per_rank</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of stages per rank.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>inference_mode</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, only forward passes are scheduled. If False,
both forward and backward passes are scheduled.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table></div>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>d9d/pipelining/infra/schedule/program/bfs.py</code></summary>
              <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_stages_per_rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">inference_mode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Constructs the LoopedBFS builder.</span>

<span class="sd">    Args:</span>
<span class="sd">        num_stages_per_rank: Number of stages per rank.</span>
<span class="sd">        inference_mode: If True, only forward passes are scheduled. If False,</span>
<span class="sd">            both forward and backward passes are scheduled.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_num_stages_per_rank</span> <span class="o">=</span> <span class="n">num_stages_per_rank</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_inference_mode</span> <span class="o">=</span> <span class="n">inference_mode</span>
</code></pre></div></td></tr></table></div></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="d9d.pipelining.infra.schedule.program.ZeroBubbleVPipelineProgramBuilder" class="doc doc-heading">
            <code>ZeroBubbleVPipelineProgramBuilder</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="PipelineProgramBuilder (d9d.pipelining.infra.schedule.component.program.PipelineProgramBuilder)" href="#d9d.pipelining.infra.schedule.component.program.PipelineProgramBuilder">PipelineProgramBuilder</a></code></p>



        <p>Builder for the Zero Bubble V (ZBV) Pipeline Schedule.</p>
<p>This schedule is designed for V-shape topologies (2 stages per rank) and
utilizes the Zero Bubble optimizations by splitting backward passes.</p>
<p>It requires exactly two stages
per rank organized in a V-shape topology and splits backward passes into
Input and Weight gradients to optimize pipeline throughput.</p>


<details class="references" open>
  <summary>References</summary>
  <p>https://arxiv.org/pdf/2401.10241, Section 6</p>
</details>







              <details class="mkdocstrings-source">
                <summary>Source code in <code>d9d/pipelining/infra/schedule/program/zerobubblev.py</code></summary>
                <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">ZeroBubbleVPipelineProgramBuilder</span><span class="p">(</span><span class="n">PipelineProgramBuilder</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Builder for the Zero Bubble V (ZBV) Pipeline Schedule.</span>

<span class="sd">    This schedule is designed for V-shape topologies (2 stages per rank) and</span>
<span class="sd">    utilizes the Zero Bubble optimizations by splitting backward passes.</span>

<span class="sd">    It requires exactly two stages</span>
<span class="sd">    per rank organized in a V-shape topology and splits backward passes into</span>
<span class="sd">    Input and Weight gradients to optimize pipeline throughput.</span>

<span class="sd">    References:</span>
<span class="sd">        https://arxiv.org/pdf/2401.10241, Section 6</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructs the ZBV builder.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">compose</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_microbatches</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">pp_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">ActionBase</span><span class="p">]]:</span>
        <span class="n">num_stages</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_stages_per_rank</span> <span class="o">*</span> <span class="n">pp_size</span>

        <span class="c1"># 1. Topology</span>
        <span class="c1"># V-style: Rank 0 gets Stage 0 &amp; Stage N-1. Rank 1 gets Stage 1 &amp; Stage N-2...</span>
        <span class="n">stage_to_rank</span> <span class="o">=</span> <span class="n">build_stage_to_host_rank_topology</span><span class="p">(</span><span class="n">pp_size</span><span class="o">=</span><span class="n">pp_size</span><span class="p">,</span> <span class="n">num_stages</span><span class="o">=</span><span class="n">num_stages</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="n">ScheduleStyle</span><span class="o">.</span><span class="n">v</span><span class="p">)</span>

        <span class="n">actions</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="n">ActionBase</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">pp_size</span><span class="p">):</span>
            <span class="n">actions</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_rank_schedule</span><span class="p">(</span>
                <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span>
                <span class="n">pp_size</span><span class="o">=</span><span class="n">pp_size</span><span class="p">,</span>
                <span class="n">num_stages</span><span class="o">=</span><span class="n">num_stages</span><span class="p">,</span>
                <span class="n">target_microbatches</span><span class="o">=</span><span class="n">num_microbatches</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># 2. Inject Communications</span>
        <span class="k">return</span> <span class="n">add_communication_ops</span><span class="p">(</span><span class="n">compute_actions</span><span class="o">=</span><span class="n">actions</span><span class="p">,</span> <span class="n">stage_to_rank</span><span class="o">=</span><span class="n">stage_to_rank</span><span class="p">,</span> <span class="n">num_stages</span><span class="o">=</span><span class="n">num_stages</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_generate_rank_schedule</span><span class="p">(</span>  <span class="c1"># noqa: C901</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">pp_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">num_stages</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">target_microbatches</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">ActionBase</span><span class="p">]:</span>
        <span class="c1"># ZBV logic assumes the pipeline is fully saturated to define the loop bounds.</span>
        <span class="c1"># We simulate enough steps to cover the topology startup, then filter</span>
        <span class="c1"># down to the user&#39;s requested microbatches at the end.</span>
        <span class="n">simulated_n_micro</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">pp_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">target_microbatches</span><span class="p">)</span>

        <span class="n">rank_ops</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">ActionBase</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># -- Stage Identification (V-Shape) --</span>
        <span class="c1"># s0: The &quot;Forward-going&quot; chunk (e.g., Stage 0 for Rank 0)</span>
        <span class="c1"># s1: The &quot;Backward-coming&quot; chunk (e.g., Stage N-1 for Rank 0)</span>
        <span class="n">s0</span> <span class="o">=</span> <span class="n">rank</span>
        <span class="n">s1</span> <span class="o">=</span> <span class="n">num_stages</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">rank</span>

        <span class="c1"># -- Counters --</span>
        <span class="c1"># Track next microbatch index for each operation type on each chunk.</span>
        <span class="c1"># F: Forward, I: Backward Input, W: Backward Weight</span>
        <span class="n">f0_cnt</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">b0_cnt</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Input Grad Counter (Chunk 0)</span>
        <span class="n">w0_cnt</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Weight Grad Counter (Chunk 0)</span>

        <span class="n">f1_cnt</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">b1_cnt</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Input Grad Counter (Chunk 1)</span>
        <span class="n">w1_cnt</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Weight Grad Counter (Chunk 1)</span>

        <span class="c1"># -- Helpers --</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">emit_f</span><span class="p">(</span><span class="n">stage</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ForwardComputeAction</span><span class="p">(</span><span class="n">stage_idx</span><span class="o">=</span><span class="n">stage</span><span class="p">,</span> <span class="n">microbatch_idx</span><span class="o">=</span><span class="n">idx</span><span class="p">))</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">emit_i_and_w</span><span class="p">(</span><span class="n">stage</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">BackwardFullInputComputeAction</span><span class="p">(</span><span class="n">stage_idx</span><span class="o">=</span><span class="n">stage</span><span class="p">,</span> <span class="n">microbatch_idx</span><span class="o">=</span><span class="n">idx</span><span class="p">,</span> <span class="n">full_backward</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
            <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">BackwardWeightComputeAction</span><span class="p">(</span><span class="n">stage_idx</span><span class="o">=</span><span class="n">stage</span><span class="p">,</span> <span class="n">microbatch_idx</span><span class="o">=</span><span class="n">idx</span><span class="p">))</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">emit_i</span><span class="p">(</span><span class="n">stage</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">BackwardFullInputComputeAction</span><span class="p">(</span><span class="n">stage_idx</span><span class="o">=</span><span class="n">stage</span><span class="p">,</span> <span class="n">microbatch_idx</span><span class="o">=</span><span class="n">idx</span><span class="p">,</span> <span class="n">full_backward</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">emit_w</span><span class="p">(</span><span class="n">stage</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">BackwardWeightComputeAction</span><span class="p">(</span><span class="n">stage_idx</span><span class="o">=</span><span class="n">stage</span><span class="p">,</span> <span class="n">microbatch_idx</span><span class="o">=</span><span class="n">idx</span><span class="p">))</span>

        <span class="c1"># -- Phase 1: Warmup 1 (Chunk 0 Forwards) --</span>
        <span class="n">warmup_n1</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">pp_size</span> <span class="o">-</span> <span class="n">rank</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">warmup_n1</span><span class="p">):</span>
            <span class="n">emit_f</span><span class="p">(</span><span class="n">s0</span><span class="p">,</span> <span class="n">f0_cnt</span><span class="p">)</span>
            <span class="n">f0_cnt</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># -- Phase 2: Warmup 2 (Interleave F1, F0) --</span>
        <span class="n">warmup_n2</span> <span class="o">=</span> <span class="n">rank</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">warmup_n2</span><span class="p">):</span>
            <span class="n">emit_f</span><span class="p">(</span><span class="n">s1</span><span class="p">,</span> <span class="n">f1_cnt</span><span class="p">)</span>
            <span class="n">f1_cnt</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">emit_f</span><span class="p">(</span><span class="n">s0</span><span class="p">,</span> <span class="n">f0_cnt</span><span class="p">)</span>
            <span class="n">f0_cnt</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># -- Phase 3: Warmup 3 (F1, then B1 I+W) --</span>
        <span class="n">warmup_n3</span> <span class="o">=</span> <span class="n">pp_size</span> <span class="o">-</span> <span class="n">rank</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">warmup_n3</span><span class="p">):</span>
            <span class="n">emit_f</span><span class="p">(</span><span class="n">s1</span><span class="p">,</span> <span class="n">f1_cnt</span><span class="p">)</span>
            <span class="n">f1_cnt</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="n">emit_i_and_w</span><span class="p">(</span><span class="n">s1</span><span class="p">,</span> <span class="n">b1_cnt</span><span class="p">)</span>
            <span class="n">b1_cnt</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">w1_cnt</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># -- Phase 4: Stable State --</span>
        <span class="k">while</span> <span class="n">f1_cnt</span> <span class="o">&lt;</span> <span class="n">f0_cnt</span> <span class="ow">or</span> <span class="n">f0_cnt</span> <span class="o">&lt;</span> <span class="n">simulated_n_micro</span><span class="p">:</span>
            <span class="c1"># Emit F0 if within bounds</span>
            <span class="k">if</span> <span class="n">f0_cnt</span> <span class="o">&lt;</span> <span class="n">simulated_n_micro</span><span class="p">:</span>
                <span class="n">emit_f</span><span class="p">(</span><span class="n">s0</span><span class="p">,</span> <span class="n">f0_cnt</span><span class="p">)</span>
                <span class="n">f0_cnt</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="c1"># Emit B0 (I+W)</span>
            <span class="n">emit_i_and_w</span><span class="p">(</span><span class="n">s0</span><span class="p">,</span> <span class="n">b0_cnt</span><span class="p">)</span>
            <span class="n">b0_cnt</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">w0_cnt</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="c1"># Emit F1</span>
            <span class="n">emit_f</span><span class="p">(</span><span class="n">s1</span><span class="p">,</span> <span class="n">f1_cnt</span><span class="p">)</span>
            <span class="n">f1_cnt</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="c1"># Emit B1 (I+W)</span>
            <span class="n">emit_i_and_w</span><span class="p">(</span><span class="n">s1</span><span class="p">,</span> <span class="n">b1_cnt</span><span class="p">)</span>
            <span class="n">b1_cnt</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">w1_cnt</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># -- Phase 5: Cooldown 1 (Splitting I and W) --</span>
        <span class="c1"># In cooldown, the I and W streams diverge to fill bubbles.</span>
        <span class="n">cooldown_n1</span> <span class="o">=</span> <span class="n">rank</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">cooldown_n1</span><span class="p">):</span>
            <span class="n">emit_i</span><span class="p">(</span><span class="n">s0</span><span class="p">,</span> <span class="n">b0_cnt</span><span class="p">)</span>
            <span class="n">b0_cnt</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="n">emit_i</span><span class="p">(</span><span class="n">s1</span><span class="p">,</span> <span class="n">b1_cnt</span><span class="p">)</span>
            <span class="n">b1_cnt</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># -- Phase 6: Cooldown 2 (I0, then W0) --</span>
        <span class="n">cooldown_n2</span> <span class="o">=</span> <span class="n">pp_size</span> <span class="o">-</span> <span class="n">rank</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">cooldown_n2</span><span class="p">):</span>
            <span class="c1"># Input Grad Chunk 0</span>
            <span class="n">emit_i</span><span class="p">(</span><span class="n">s0</span><span class="p">,</span> <span class="n">b0_cnt</span><span class="p">)</span>
            <span class="n">b0_cnt</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="c1"># Weight Grad Chunk 0 (delayed from previous steps)</span>
            <span class="n">emit_w</span><span class="p">(</span><span class="n">s0</span><span class="p">,</span> <span class="n">w0_cnt</span><span class="p">)</span>
            <span class="n">w0_cnt</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># -- Phase 7: Flush Remaining Weights --</span>

        <span class="c1"># Flush W1</span>
        <span class="k">while</span> <span class="n">w1_cnt</span> <span class="o">&lt;</span> <span class="n">b1_cnt</span><span class="p">:</span>
            <span class="n">emit_w</span><span class="p">(</span><span class="n">s1</span><span class="p">,</span> <span class="n">w1_cnt</span><span class="p">)</span>
            <span class="n">w1_cnt</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Flush W0</span>
        <span class="k">while</span> <span class="n">w0_cnt</span> <span class="o">&lt;</span> <span class="n">b0_cnt</span><span class="p">:</span>
            <span class="n">emit_w</span><span class="p">(</span><span class="n">s0</span><span class="p">,</span> <span class="n">w0_cnt</span><span class="p">)</span>
            <span class="n">w0_cnt</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># -- Integrity Check --</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">w0_cnt</span> <span class="o">==</span> <span class="n">b0_cnt</span> <span class="o">==</span> <span class="n">f0_cnt</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ZBV Schedule Failed (Chunk 0): F=</span><span class="si">{</span><span class="n">f0_cnt</span><span class="si">}</span><span class="s2">, I=</span><span class="si">{</span><span class="n">b0_cnt</span><span class="si">}</span><span class="s2">, W=</span><span class="si">{</span><span class="n">w0_cnt</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">w1_cnt</span> <span class="o">==</span> <span class="n">b1_cnt</span> <span class="o">==</span> <span class="n">f1_cnt</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ZBV Schedule Failed (Chunk 1): F=</span><span class="si">{</span><span class="n">f1_cnt</span><span class="si">}</span><span class="s2">, I=</span><span class="si">{</span><span class="n">b1_cnt</span><span class="si">}</span><span class="s2">, W=</span><span class="si">{</span><span class="n">w1_cnt</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># -- Post-Process: Filter to Target Microbatches --</span>
        <span class="c1"># Remove any actions involving simulated microbatches beyond the user&#39;s request.</span>
        <span class="n">final_ops</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">ActionBase</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">rank_ops</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">action</span><span class="p">,</span> <span class="p">(</span><span class="n">ForwardComputeAction</span><span class="p">,</span> <span class="n">BackwardFullInputComputeAction</span><span class="p">,</span> <span class="n">BackwardWeightComputeAction</span><span class="p">)):</span>
                <span class="k">if</span> <span class="n">action</span><span class="o">.</span><span class="n">microbatch_idx</span> <span class="o">&lt;</span> <span class="n">target_microbatches</span><span class="p">:</span>
                    <span class="n">final_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">final_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">final_ops</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">num_stages_per_rank</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">2</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">topology_style</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ScheduleStyle</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ScheduleStyle</span><span class="o">.</span><span class="n">v</span>
</code></pre></div></td></tr></table></div></div>
              </details>



<div class="doc doc-children">










<div class="doc doc-object doc-function">


<h4 id="d9d.pipelining.infra.schedule.program.ZeroBubbleVPipelineProgramBuilder.__init__" class="doc doc-heading">
            <code class=" language-python"><span class="fm">__init__</span><span class="p">()</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Constructs the ZBV builder.</p>


            <details class="mkdocstrings-source">
              <summary>Source code in <code>d9d/pipelining/infra/schedule/program/zerobubblev.py</code></summary>
              <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">30</span>
<span class="normal">31</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructs the ZBV builder.&quot;&quot;&quot;</span>
</code></pre></div></td></tr></table></div></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>

<div class="doc doc-object doc-module">



<h2 id="d9d.pipelining.training" class="doc doc-heading">
            <code>d9d.pipelining.training</code>


</h2>

    <div class="doc doc-contents first">










<div class="doc doc-children">









<div class="doc doc-object doc-class">



<h3 id="d9d.pipelining.training.PipelinedLRScheduler" class="doc doc-heading">
            <code>PipelinedLRScheduler</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="LRSchedulerProtocol (d9d.core.protocol.LRSchedulerProtocol)" href="../../core/types/#d9d.core.protocol.LRSchedulerProtocol">LRSchedulerProtocol</a></code></p>



        <p>Wrapper that manages multiple LR schedulers for a pipeline parallel rank.</p>
<p>Similar to <code>PipelinedOptimizer</code>, this aggregates schedulers corresponding to
multiple model stages hosted on the current rank.</p>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>d9d/pipelining/training/scheduler.py</code></summary>
                <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">PipelinedLRScheduler</span><span class="p">(</span><span class="n">LRSchedulerProtocol</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Wrapper that manages multiple LR schedulers for a pipeline parallel rank.</span>

<span class="sd">    Similar to `PipelinedOptimizer`, this aggregates schedulers corresponding to</span>
<span class="sd">    multiple model stages hosted on the current rank.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mesh_pp</span><span class="p">:</span> <span class="n">DeviceMesh</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span> <span class="n">schedulers</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">LRSchedulerProtocol</span><span class="p">]):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_pp_rank</span> <span class="o">=</span> <span class="n">mesh_pp</span><span class="o">.</span><span class="n">get_local_rank</span><span class="p">()</span> <span class="k">if</span> <span class="n">mesh_pp</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_schedulers</span> <span class="o">=</span> <span class="n">schedulers</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="k">return</span> <span class="p">{</span><span class="sa">f</span><span class="s2">&quot;pp_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_pp_rank</span><span class="si">}</span><span class="s2">_stage_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">scheduler</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">scheduler</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_schedulers</span><span class="p">)}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">scheduler</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_schedulers</span><span class="p">):</span>
            <span class="n">scheduler</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;pp_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_pp_rank</span><span class="si">}</span><span class="s2">_stage_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">])</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">scheduler</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_schedulers</span><span class="p">:</span>
            <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</code></pre></div></td></tr></table></div></div>
              </details>



<div class="doc doc-children">












  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h3 id="d9d.pipelining.training.PipelinedOptimizer" class="doc doc-heading">
            <code>PipelinedOptimizer</code>


</h3>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="OptimizerProtocol (d9d.core.protocol.OptimizerProtocol)" href="../../core/types/#d9d.core.protocol.OptimizerProtocol">OptimizerProtocol</a></code></p>



        <p>Wrapper that manages multiple optimizers for a pipeline parallel rank.</p>
<p>In a pipeline parallel setup, a single rank might host multiple stages, each having its own parameters
and optimizer.
This class aggregates them into a single interface.</p>








              <details class="mkdocstrings-source">
                <summary>Source code in <code>d9d/pipelining/training/optimizer.py</code></summary>
                <div class="codehilite"><div class="table-wrapper"><table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">PipelinedOptimizer</span><span class="p">(</span><span class="n">OptimizerProtocol</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Wrapper that manages multiple optimizers for a pipeline parallel rank.</span>

<span class="sd">    In a pipeline parallel setup, a single rank might host multiple stages, each having its own parameters</span>
<span class="sd">    and optimizer.</span>
<span class="sd">    This class aggregates them into a single interface.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mesh_pp</span><span class="p">:</span> <span class="n">DeviceMesh</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span> <span class="n">optimizers</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">OptimizerProtocol</span><span class="p">]):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_pp_rank</span> <span class="o">=</span> <span class="n">mesh_pp</span><span class="o">.</span><span class="n">get_local_rank</span><span class="p">()</span> <span class="k">if</span> <span class="n">mesh_pp</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_optimizers</span> <span class="o">=</span> <span class="n">optimizers</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="n">pp_rank</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pp_rank</span>
        <span class="k">return</span> <span class="p">{</span><span class="sa">f</span><span class="s2">&quot;pp_</span><span class="si">{</span><span class="n">pp_rank</span><span class="si">}</span><span class="s2">_stage_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">optimizer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_optimizers</span><span class="p">)}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">pp_rank</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pp_rank</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">optimizer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_optimizers</span><span class="p">):</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;pp_</span><span class="si">{</span><span class="n">pp_rank</span><span class="si">}</span><span class="s2">_stage_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">])</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">optimizer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimizers</span><span class="p">:</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">zero_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">optimizer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimizers</span><span class="p">:</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</code></pre></div></td></tr></table></div></div>
              </details>



<div class="doc doc-children">












  </div>

    </div>

</div>




  </div>

    </div>

</div>
  </div>
</article>
                                <div class="mx-auto flex flex-wrap h-16 w-full max-w-2xl items-center gap-2 px-4 md:px-0">
    
    <a data-slot="button"
        class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*='size-'])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive bg-secondary text-secondary-foreground hover:bg-secondary/80 h-8 rounded-md gap-1.5 px-3 has-[&gt;svg]:px-2.5 shadow-none"
        href="/d9d/internals/pipeline_state/">
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
            stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
            class="tabler-icon tabler-icon-arrow-left ">
            <path d="M5 12l14 0"></path>
            <path d="M5 12l6 6"></path>
            <path d="M5 12l6 -6"></path>
        </svg>
        <span class="max-[500px]:hidden">Pipeline State Management</span>
    </a>
    
    
    <a data-slot="button"
        class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*='size-'])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive bg-secondary text-secondary-foreground hover:bg-secondary/80 h-8 rounded-md gap-1.5 px-3 has-[&gt;svg]:px-2.5 ml-auto shadow-none"
        href="/d9d/internals/profiling/">
        <span class="max-[500px]:hidden">Distributed Profiling</span>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
            stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
            class="tabler-icon tabler-icon-arrow-right ">
            <path d="M5 12l14 0"></path>
            <path d="M13 18l6 -6"></path>
            <path d="M13 6l6 6"></path>
        </svg>
    </a>
    
</div>
                                <dialog id="bottom-sidebar" onclick="onBottomSidebarDialogClick(event)" class="bg-transparent"
    style="position: fixed; left: 0px; top: 0px; transform: translate(0px, 58px); min-width: max-content; --radix-popper-transform-origin: 0% 0px; will-change: transform; z-index: 50; --radix-popper-available-width: 504px; --radix-popper-available-height: 857px; --radix-popper-anchor-width: 72.94999694824219px; --radix-popper-anchor-height: 32px;">
    <div data-side="bottom" data-align="start" data-state="open" role="dialog" data-slot="popover-content"
        class="text-popover-foreground data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2 z-50 origin-(--radix-popover-content-transform-origin) border outline-hidden bg-background/90 no-scrollbar h-(--radix-popper-available-height) w-(--radix-popper-available-width) overflow-y-auto rounded-none border-none p-0 shadow-none backdrop-blur duration-100"
        style="--radix-popover-content-transform-origin: var(--radix-popper-transform-origin); --radix-popover-content-available-width: var(--radix-popper-available-width); --radix-popover-content-available-height: var(--radix-popper-available-height); --radix-popover-trigger-width: var(--radix-popper-anchor-width); --radix-popover-trigger-height: var(--radix-popper-anchor-height);"
        tabindex="-1">
        <div class="flex flex-col gap-12 overflow-auto px-6 py-6">
            
            
            

            
            <div class="flex flex-col gap-4">
                <div class="text-muted-foreground text-sm font-medium">Menu</div>
                <div class="flex flex-col gap-3">
                    
                    <a class="text-2xl font-medium" href="../..">
                        
                        Home
                        
                    </a>
                    
                    <a class="text-2xl font-medium" href="../../toc/">
                        
                        Table of Contents
                        
                    </a>
                    
                </div>
            </div>
            

            
            <div class="flex flex-col gap-8">
                
                <div class="flex flex-col gap-4">
                    <div class="text-muted-foreground text-sm font-medium">Loop</div>
                    
                    <div class="flex flex-col gap-3">
                        
                        <a class="text-2xl font-medium" href="../../0_loop/0_index/">
                            
                            Training Loop
                            
                        </a>
                        
                        <a class="text-2xl font-medium" href="../../0_loop/1_inference_loop/">
                            
                            Inference Loop
                            
                        </a>
                        
                        <a class="text-2xl font-medium" href="../../0_loop/config/">
                            
                            Configuration
                            
                        </a>
                        
                        <a class="text-2xl font-medium" href="../../0_loop/interfaces/">
                            
                            Interfaces & Logic
                            
                        </a>
                        
                    </div>
                    
                </div>
                
                <div class="flex flex-col gap-4">
                    <div class="text-muted-foreground text-sm font-medium">Core</div>
                    
                    <div class="flex flex-col gap-3">
                        
                        <a class="text-2xl font-medium" href="../../core/autograd_extensions/">
                            
                            Autograd Extensions
                            
                        </a>
                        
                        <a class="text-2xl font-medium" href="../../core/dist_context/">
                            
                            Distributed Context
                            
                        </a>
                        
                        <a class="text-2xl font-medium" href="../../core/dist_ops/">
                            
                            Distributed Operations
                            
                        </a>
                        
                        <a class="text-2xl font-medium" href="../../core/sharding/">
                            
                            PyTree Sharding
                            
                        </a>
                        
                        <a class="text-2xl font-medium" href="../../core/types/">
                            
                            Typing Extensions
                            
                        </a>
                        
                    </div>
                    
                </div>
                
                <div class="flex flex-col gap-4">
                    <div class="text-muted-foreground text-sm font-medium">Dataset</div>
                    
                    <div class="flex flex-col gap-3">
                        
                        <a class="text-2xl font-medium" href="../../dataset/">
                            
                            Datasets
                            
                        </a>
                        
                    </div>
                    
                </div>
                
                <div class="flex flex-col gap-4">
                    <div class="text-muted-foreground text-sm font-medium">Internals</div>
                    
                    <div class="flex flex-col gap-3">
                        
                        <a class="text-2xl font-medium" href="../determinism/">
                            
                            Determinism
                            
                        </a>
                        
                        <a class="text-2xl font-medium" href="../grad_norm/">
                            
                            Gradient Norm & Clipping
                            
                        </a>
                        
                        <a class="text-2xl font-medium" href="../grad_sync/">
                            
                            Gradient Synchronization
                            
                        </a>
                        
                        <a class="text-2xl font-medium" href="../metric_collector/">
                            
                            Metric Collection
                            
                        </a>
                        
                        <a class="text-2xl font-medium" href="../pipeline_state/">
                            
                            Pipeline State Management
                            
                        </a>
                        
                        <a class="text-2xl font-medium" href="./">
                            
                            Pipelining Internals
                            
                        </a>
                        
                        <a class="text-2xl font-medium" href="../profiling/">
                            
                            Distributed Profiling
                            
                        </a>
                        
                        <a class="text-2xl font-medium" href="../tracker_integration/">
                            
                            Experiment Tracking
                            
                        </a>
                        
                    </div>
                    
                </div>
                
                <div class="flex flex-col gap-4">
                    <div class="text-muted-foreground text-sm font-medium">Lr scheduler</div>
                    
                    <div class="flex flex-col gap-3">
                        
                        <a class="text-2xl font-medium" href="../../lr_scheduler/piecewise/">
                            
                            Piecewise Scheduler
                            
                        </a>
                        
                        <a class="text-2xl font-medium" href="../../lr_scheduler/visualization/">
                            
                            Visualization
                            
                        </a>
                        
                    </div>
                    
                </div>
                
                <div class="flex flex-col gap-4">
                    <div class="text-muted-foreground text-sm font-medium">Metric</div>
                    
                    <div class="flex flex-col gap-3">
                        
                        <a class="text-2xl font-medium" href="../../metric/0_index/">
                            
                            Metrics
                            
                        </a>
                        
                        <a class="text-2xl font-medium" href="../../metric/custom/">
                            
                            Custom Metrics
                            
                        </a>
                        
                        <a class="text-2xl font-medium" href="../../metric/implemented/">
                            
                            Implemented Metrics
                            
                        </a>
                        
                    </div>
                    
                </div>
                
                <div class="flex flex-col gap-4">
                    <div class="text-muted-foreground text-sm font-medium">Model states</div>
                    
                    <div class="flex flex-col gap-3">
                        
                        <a class="text-2xl font-medium" href="../../model_states/io/">
                            
                            Model State I/O
                            
                        </a>
                        
                        <a class="text-2xl font-medium" href="../../model_states/mapper/">
                            
                            Model State Mapper
                            
                        </a>
                        
                    </div>
                    
                </div>
                
                <div class="flex flex-col gap-4">
                    <div class="text-muted-foreground text-sm font-medium">Models</div>
                    
                    <div class="flex flex-col gap-3">
                        
                        <a class="text-2xl font-medium" href="../../models/1_model_design/">
                            
                            Model Design
                            
                        </a>
                        
                        <a class="text-2xl font-medium" href="../../models/2_horizontal_parallelism/">
                            
                            Horizontal Parallelism
                            
                        </a>
                        
                        <a class="text-2xl font-medium" href="../../models/3_pipeline_parallelism/">
                            
                            Pipeline Parallelism
                            
                        </a>
                        
                        <a class="text-2xl font-medium" href="../../models/4_model_catalogue/">
                            
                            Model Catalogue
                            
                        </a>
                        
                        <a class="text-2xl font-medium" href="../../models/qwen3_moe/">
                            
                            Qwen3 MoE
                            
                        </a>
                        
                    </div>
                    
                </div>
                
                <div class="flex flex-col gap-4">
                    <div class="text-muted-foreground text-sm font-medium">Modules</div>
                    
                    <div class="flex flex-col gap-3">
                        
                        <a class="text-2xl font-medium" href="../../modules/attention/">
                            
                            Attention Layers
                            
                        </a>
                        
                        <a class="text-2xl font-medium" href="../../modules/embedding/">
                            
                            Embeddings
                            
                        </a>
                        
                        <a class="text-2xl font-medium" href="../../modules/ffn/">
                            
                            Feed Forward Networks (FFN)
                            
                        </a>
                        
                        <a class="text-2xl font-medium" href="../../modules/head/">
                            
                            Model Heads
                            
                        </a>
                        
                        <a class="text-2xl font-medium" href="../../modules/hidden_states_aggregator/">
                            
                            Hidden States Aggregation
                            
                        </a>
                        
                        <a class="text-2xl font-medium" href="../../modules/moe/">
                            
                            Mixture of Experts (MoE)
                            
                        </a>
                        
                        <a class="text-2xl font-medium" href="../../modules/positional/">
                            
                            Positional Embeddings
                            
                        </a>
                        
                    </div>
                    
                </div>
                
                <div class="flex flex-col gap-4">
                    <div class="text-muted-foreground text-sm font-medium">Optimizer</div>
                    
                    <div class="flex flex-col gap-3">
                        
                        <a class="text-2xl font-medium" href="../../optimizer/stochastic/">
                            
                            Stochastic Optimizers
                            
                        </a>
                        
                    </div>
                    
                </div>
                
                <div class="flex flex-col gap-4">
                    <div class="text-muted-foreground text-sm font-medium">Peft</div>
                    
                    <div class="flex flex-col gap-3">
                        
                        <a class="text-2xl font-medium" href="../../peft/0_index/">
                            
                            PEFT Overview
                            
                        </a>
                        
                        <a class="text-2xl font-medium" href="../../peft/full_tune/">
                            
                            Full Fine-Tuning
                            
                        </a>
                        
                        <a class="text-2xl font-medium" href="../../peft/lora/">
                            
                            LoRA
                            
                        </a>
                        
                        <a class="text-2xl font-medium" href="../../peft/stack/">
                            
                            Method Stacking
                            
                        </a>
                        
                    </div>
                    
                </div>
                
            </div>
            
            

        </div>
    </div>
</dialog>
                            </div>
                            <div
                                class="sticky top-[calc(var(--header-height)+1px)] z-30 ml-auto hidden h-[calc(100svh-var(--header-height)-var(--footer-height))] w-72 flex-col gap-4 overflow-hidden overscroll-none pb-8 xl:flex">
                                <div class="h-(--top-spacing) shrink-0"></div>
                                <div view-transition-name="toc" class="no-scrollbar overflow-y-auto px-8">
    <div class="flex flex-col gap-2 p-4 pt-0 text-sm">
        <p class="text-muted-foreground bg-background sticky top-0 h-6 text-xs">On This Page</p>
        
        
        
        
        <a href="#architecture"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="2">
            Architecture
        </a>
        
        
        <a href="#the-idea"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            The Idea
        </a>
        
        <a href="#core-components"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            Core Components
        </a>
        
        <a href="#comparison-with-pytorch"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            Comparison with PyTorch
        </a>
        
        

        
        <a href="#building-custom-schedules"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="2">
            Building Custom Schedules
        </a>
        
        
        <a href="#implement-the-builder"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            Implement the Builder
        </a>
        
        <a href="#registering"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            Registering
        </a>
        
        

        
        <a href="#d9d.pipelining.infra.stage"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="2">
            stage
        </a>
        
        
        <a href="#d9d.pipelining.infra.stage.PipelineStage"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            PipelineStage
        </a>
        
        

        
        <a href="#d9d.pipelining.infra.schedule.component.runtime"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="2">
            runtime
        </a>
        
        
        <a href="#d9d.pipelining.infra.schedule.component.runtime.ActionBase"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            ActionBase
        </a>
        
        <a href="#d9d.pipelining.infra.schedule.component.runtime.BackwardFullInputComputeAction"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            BackwardFullInputComputeAction
        </a>
        
        <a href="#d9d.pipelining.infra.schedule.component.runtime.BackwardReceiveAction"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            BackwardReceiveAction
        </a>
        
        <a href="#d9d.pipelining.infra.schedule.component.runtime.BackwardSendAction"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            BackwardSendAction
        </a>
        
        <a href="#d9d.pipelining.infra.schedule.component.runtime.BackwardWeightComputeAction"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            BackwardWeightComputeAction
        </a>
        
        <a href="#d9d.pipelining.infra.schedule.component.runtime.ComposeAction"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            ComposeAction
        </a>
        
        <a href="#d9d.pipelining.infra.schedule.component.runtime.ForwardComputeAction"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            ForwardComputeAction
        </a>
        
        <a href="#d9d.pipelining.infra.schedule.component.runtime.ForwardReceiveAction"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            ForwardReceiveAction
        </a>
        
        <a href="#d9d.pipelining.infra.schedule.component.runtime.ForwardSendAction"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            ForwardSendAction
        </a>
        
        <a href="#d9d.pipelining.infra.schedule.component.runtime.OfflinePipelineExecutor"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            OfflinePipelineExecutor
        </a>
        
        <a href="#d9d.pipelining.infra.schedule.component.runtime.PipelineScheduleExecutor"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            PipelineScheduleExecutor
        </a>
        
        

        
        <a href="#d9d.pipelining.infra.schedule.component.program"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="2">
            program
        </a>
        
        
        <a href="#d9d.pipelining.infra.schedule.component.program.PipelineProgramBuilder"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            PipelineProgramBuilder
        </a>
        
        <a href="#d9d.pipelining.infra.schedule.component.program.ScheduleStyle"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            ScheduleStyle
        </a>
        
        <a href="#d9d.pipelining.infra.schedule.component.program.add_communication_ops"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            add_communication_ops
        </a>
        
        <a href="#d9d.pipelining.infra.schedule.component.program.build_stage_to_host_rank_topology"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            build_stage_to_host_rank_topology
        </a>
        
        <a href="#d9d.pipelining.infra.schedule.component.program.invert_stage_to_host_rank_topology"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            invert_stage_to_host_rank_topology
        </a>
        
        

        
        <a href="#d9d.pipelining.infra.schedule.program"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="2">
            program
        </a>
        
        
        <a href="#d9d.pipelining.infra.schedule.program.DualPipeVPipelineProgramBuilder"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            DualPipeVPipelineProgramBuilder
        </a>
        
        <a href="#d9d.pipelining.infra.schedule.program.Interleaved1F1BPipelineProgramBuilder"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            Interleaved1F1BPipelineProgramBuilder
        </a>
        
        <a href="#d9d.pipelining.infra.schedule.program.LoopedBFSPipelineProgramBuilder"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            LoopedBFSPipelineProgramBuilder
        </a>
        
        <a href="#d9d.pipelining.infra.schedule.program.ZeroBubbleVPipelineProgramBuilder"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            ZeroBubbleVPipelineProgramBuilder
        </a>
        
        

        
        <a href="#d9d.pipelining.training"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="2">
            training
        </a>
        
        
        <a href="#d9d.pipelining.training.PipelinedLRScheduler"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            PipelinedLRScheduler
        </a>
        
        <a href="#d9d.pipelining.training.PipelinedOptimizer"
            class="text-muted-foreground hover:text-foreground data-[active=true]:text-foreground text-[0.8rem] no-underline transition-colors data-[depth=3]:pl-4 data-[depth=4]:pl-6"
            data-active="false" data-depth="3">
            PipelinedOptimizer
        </a>
        
        

        
        
        
        

    </div>
    <div class="h-12"></div>
</div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </main>
        <footer view-transition-name="footer"
    class="group-has-[.section-soft]/body:bg-surface/40 3xl:fixed:bg-transparent dark:bg-transparent">
    <div class="container-wrapper px-4 xl:px-6">
        <div class="flex h-(--footer-height) items-center justify-between">
            <div class="text-muted-foreground w-full text-center text-xs leading-loose sm:text-sm">
                
                <a href="https://github.com/asiffer/mkdocs-shadcn">shadcn theme</a> provided by
                <a href="https://github.com/asiffer">@asiffer</a>
            </div>
        </div>
    </div>
</footer>
    </div>
     

<script src="../../search/main.js"></script>


    

    <script src="../../js/copy-button.js"></script>
    <script>updatePygmentsStylesheet();</script>
    
    <script>fetchStargazers("https://github.com/d9d-project/d9d");</script>
    
    
    <script>
    for (const el of document.querySelectorAll(
        ".typography .doc code.language-python",
    )) {
        el.classList.add("codehilite");
    }

    for (const el of document.querySelectorAll("article .doc .doc-contents")) {
        el.innerHTML = el.innerHTML.trim();
    }
</script>
    
    
    <script type="speculationrules">
{
  "prerender": [
    {
      "where": {
          "selector_matches": ["#next-button", "#previous-button"],
      }
    }
  ]
}
</script>
</body>

</html>